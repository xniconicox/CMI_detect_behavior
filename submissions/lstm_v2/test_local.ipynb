{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-09 11:28:30.832173: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-07-09 11:28:32.414279: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1752028113.002746  151768 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1752028113.165530  151768 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1752028114.445265  151768 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1752028114.445294  151768 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1752028114.445295  151768 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1752028114.445296  151768 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-07-09 11:28:34.574126: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "\n",
        "sys.path.append('../../data')\n",
        "import kaggle_evaluation.cmi_inference_server\n",
        "from preprocessing import CMIPreprocessor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU利用可能: 1台\n",
            "✅ センサーScaler読み込み完了\n",
            "✅ DemographicsScaler読み込み完了\n",
            "✅ PCA Transformer作成完了\n",
            "  元の次元数: 18\n",
            "  変換後次元数: 18\n",
            "  累積寄与率: 1.0000\n",
            "モデル読み込み中: /mnt/c/Users/ShunK/works/CMI_comp/submissions/lstm_v2/final_model_20250709_085324.keras\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1752028137.348308  151768 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5660 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ モデル読み込み完了\n",
            "✅ 前処理器の初期化が完了しました\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/mnt/c/Users/ShunK/works/CMI_comp/.venv/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 26 variables whereas the saved optimizer has 54 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ],
      "source": [
        "# 前処理器を初期化\n",
        "preprocessor = CMIPreprocessor()\n",
        "preprocessor.load_preprocessors()\n",
        "preprocessor.load_model()\n",
        "\n",
        "print(\"✅ 前処理器の初期化が完了しました\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:\n",
        "    \"\"\"\n",
        "    テスト用の予測関数\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    sequence : pl.DataFrame\n",
        "        センサーデータのシーケンス\n",
        "    demographics : pl.DataFrame\n",
        "        Demographics情報\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    str : 予測されたジェスチャー名\n",
        "    \"\"\"\n",
        "    # Polars DataFrameをPandas DataFrameに変換\n",
        "    sequence_df = sequence.to_pandas()\n",
        "    demographics_df = demographics.to_pandas()\n",
        "    \n",
        "    # 前処理器を使用して予測\n",
        "    return preprocessor.predict_gesture(sequence_df, demographics_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "推論開始: sequence_id=SEQ_000011\n",
            "  センサーデータ形状: (51, 332)\n",
            "  センサーカラム数: 332\n",
            "⚠️  シーケンスが短いため、パディングを追加します。\n",
            "  作成されたウィンドウ数: 1\n",
            "  ウィンドウ形状: (1, 64, 332)\n",
            "  正規化後センサーデータ形状: (1, 64, 332)\n",
            "  Demographics特徴量形状: (20,)\n",
            "  18特徴量に削減: (18,)\n",
            "  PCA変換後形状: (1, 18)\n",
            "  正規化後形状: (1, 18)\n",
            "  Demographics特徴量形状: (1, 18)\n",
            "  推論前センサーデータ統計:\n",
            "    - 最小値: -3.449285\n",
            "    - 最大値: 4.365560\n",
            "    - 平均値: -0.420792\n",
            "    - 標準偏差: 0.748877\n",
            "  推論前Demographics統計:\n",
            "    - 最小値: -4018.913574\n",
            "    - 最大値: 275120.812500\n",
            "    - 平均値: 16141.713867\n",
            "    - 標準偏差: 63000.281250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-09 11:29:00.692048: E tensorflow/core/util/util.cc:131] oneDNN supports DT_HALF only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n",
            "I0000 00:00:1752028141.486584  152098 cuda_dnn.cc:529] Loaded cuDNN version 90501\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️  予測結果にNaN/Infが含まれています\n",
            "  NaN数: 18\n",
            "  Inf数: 0\n",
            "  予測結果の形状: (1, 18)\n",
            "  予測結果の最初の値: [nan nan nan nan nan]\n",
            "  NaN対策: デフォルト予測を使用します\n",
            "  修正後予測結果: [0.05555556 0.05555556 0.05555556 0.05555556 0.05555556]\n",
            "  単一ウィンドウ予測信頼度: 0.0556\n",
            "  予測結果: Above ear - pull hair\n",
            "推論開始: sequence_id=SEQ_000001\n",
            "  センサーデータ形状: (56, 332)\n",
            "  センサーカラム数: 332\n",
            "⚠️  シーケンスが短いため、パディングを追加します。\n",
            "  作成されたウィンドウ数: 1\n",
            "  ウィンドウ形状: (1, 64, 332)\n",
            "  正規化後センサーデータ形状: (1, 64, 332)\n",
            "  Demographics特徴量形状: (20,)\n",
            "  18特徴量に削減: (18,)\n",
            "  PCA変換後形状: (1, 18)\n",
            "  正規化後形状: (1, 18)\n",
            "  Demographics特徴量形状: (1, 18)\n",
            "  推論前センサーデータ統計:\n",
            "    - 最小値: -3.449285\n",
            "    - 最大値: 3.667695\n",
            "    - 平均値: 0.231377\n",
            "    - 標準偏差: 1.132804\n",
            "  推論前Demographics統計:\n",
            "    - 最小値: -4407.560547\n",
            "    - 最大値: 358905.937500\n",
            "    - 平均値: 23975.339844\n",
            "    - 標準偏差: 83244.578125\n",
            "⚠️  予測結果にNaN/Infが含まれています\n",
            "  NaN数: 18\n",
            "  Inf数: 0\n",
            "  予測結果の形状: (1, 18)\n",
            "  予測結果の最初の値: [nan nan nan nan nan]\n",
            "  NaN対策: デフォルト予測を使用します\n",
            "  修正後予測結果: [0.05555556 0.05555556 0.05555556 0.05555556 0.05555556]\n",
            "  単一ウィンドウ予測信頼度: 0.0556\n",
            "  予測結果: Above ear - pull hair\n"
          ]
        }
      ],
      "source": [
        "inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n",
        "\n",
        "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
        "    inference_server.serve()\n",
        "else:\n",
        "    # ローカル環境用のパス設定\n",
        "    from pathlib import Path\n",
        "    \n",
        "    current_dir = Path(__file__).parent if '__file__' in globals() else Path('.')\n",
        "    data_dir = current_dir.parent.parent / 'data'\n",
        "    \n",
        "    inference_server.run_local_gateway(\n",
        "        data_paths=(\n",
        "            '../../data/test.csv',\n",
        "            '../../data/test_demographics.csv',\n",
        "        )\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "推論開始: sequence_id=SEQ_000001\n",
            "  センサーデータ形状: (56, 335)\n",
            "  センサーカラム数: 335\n",
            "⚠️  ウィンドウサイズが足りません。最後のウィンドウのみを使用します。\n",
            "❌ センサーデータ前処理エラー: could not convert string to float: 'SEQ_000001_000000'\n",
            "❌ 推論エラー: could not convert string to float: 'SEQ_000001_000000'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/mnt/c/Users/ShunK/works/CMI_comp/submissions/lstm_v2/preprocessing.py\", line 243, in predict_gesture\n",
            "    sensor_windows = self.preprocess_sensor_data(sequence_df, window_size=64, stride=16)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/mnt/c/Users/ShunK/works/CMI_comp/submissions/lstm_v2/preprocessing.py\", line 201, in preprocess_sensor_data\n",
            "    padded_data[:len(sensor_data)] = sensor_data\n",
            "    ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
            "ValueError: could not convert string to float: 'SEQ_000001_000000'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "推論開始: sequence_id=SEQ_000011\n",
            "  センサーデータ形状: (51, 335)\n",
            "  センサーカラム数: 335\n",
            "⚠️  ウィンドウサイズが足りません。最後のウィンドウのみを使用します。\n",
            "❌ センサーデータ前処理エラー: could not convert string to float: 'SEQ_000011_000000'\n",
            "❌ 推論エラー: could not convert string to float: 'SEQ_000011_000000'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/mnt/c/Users/ShunK/works/CMI_comp/submissions/lstm_v2/preprocessing.py\", line 243, in predict_gesture\n",
            "    sensor_windows = self.preprocess_sensor_data(sequence_df, window_size=64, stride=16)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/mnt/c/Users/ShunK/works/CMI_comp/submissions/lstm_v2/preprocessing.py\", line 201, in preprocess_sensor_data\n",
            "    padded_data[:len(sensor_data)] = sensor_data\n",
            "    ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
            "ValueError: could not convert string to float: 'SEQ_000011_000000'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "推論開始: sequence_id=SEQ_000011\n",
            "  センサーデータ形状: (51, 335)\n",
            "  センサーカラム数: 335\n",
            "⚠️  ウィンドウサイズが足りません。最後のウィンドウのみを使用します。\n",
            "❌ センサーデータ前処理エラー: could not convert string to float: 'SEQ_000011_000000'\n",
            "❌ 推論エラー: could not convert string to float: 'SEQ_000011_000000'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/mnt/c/Users/ShunK/works/CMI_comp/submissions/lstm_v2/preprocessing.py\", line 243, in predict_gesture\n",
            "    # センサーデータの前処理\n",
            "           ^^^^^^^\n",
            "  File \"/mnt/c/Users/ShunK/works/CMI_comp/submissions/lstm_v2/preprocessing.py\", line 201, in preprocess_sensor_data\n",
            "    if len(sensor_data) > 0:\n",
            "        ^^^^^^^^^^^^^^^^^^^^^\n",
            "ValueError: could not convert string to float: 'SEQ_000011_000000'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "推論開始: sequence_id=SEQ_000001\n",
            "  センサーデータ形状: (56, 335)\n",
            "  センサーカラム数: 335\n",
            "⚠️  ウィンドウサイズが足りません。最後のウィンドウのみを使用します。\n",
            "❌ センサーデータ前処理エラー: could not convert string to float: 'SEQ_000001_000000'\n",
            "❌ 推論エラー: could not convert string to float: 'SEQ_000001_000000'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/mnt/c/Users/ShunK/works/CMI_comp/submissions/lstm_v2/preprocessing.py\", line 243, in predict_gesture\n",
            "    # センサーデータの前処理\n",
            "           ^^^^^^^\n",
            "  File \"/mnt/c/Users/ShunK/works/CMI_comp/submissions/lstm_v2/preprocessing.py\", line 201, in preprocess_sensor_data\n",
            "    if len(sensor_data) > 0:\n",
            "        ^^^^^^^^^^^^^^^^^^^^^\n",
            "ValueError: could not convert string to float: 'SEQ_000001_000000'\n"
          ]
        }
      ],
      "source": [
        "inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n",
        "\n",
        "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
        "    inference_server.serve()\n",
        "else:\n",
        "    # ローカル環境用のパス設定\n",
        "    from pathlib import Path\n",
        "    \n",
        "    current_dir = Path(__file__).parent if '__file__' in globals() else Path('.')\n",
        "    data_dir = current_dir.parent.parent / 'data'\n",
        "    \n",
        "    inference_server.run_local_gateway(\n",
        "        data_paths=(\n",
        "            '../../data/test.csv',\n",
        "            '../../data/test_demographics.csv',\n",
        "        )\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape: (2, 2)\n",
            "Columns: ['sequence_id', 'gesture']\n",
            "First 10 rows:\n",
            "  sequence_id                gesture\n",
            "0  SEQ_000011  Above ear - pull hair\n",
            "1  SEQ_000001  Above ear - pull hair\n",
            "Value counts:\n",
            "gesture\n",
            "Above ear - pull hair    2\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_parquet('submission.parquet')\n",
        "print('Shape:', df.shape)\n",
        "print('Columns:', df.columns.tolist())\n",
        "print('First 10 rows:')\n",
        "print(df.head(10))\n",
        "print('Value counts:')\n",
        "print(df['gesture'].value_counts())"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
