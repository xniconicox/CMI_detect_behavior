{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# CMIã‚³ãƒ³ãƒš ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆç”¨ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯\n",
        "\n",
        "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ã€Kaggleã«æå‡ºã™ã‚‹å‰ã«ãƒ­ãƒ¼ã‚«ãƒ«ã§æ¨è«–ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ãŸã‚ã®ã‚‚ã®ã§ã™ã€‚\n",
        "\n",
        "## æ©Ÿèƒ½\n",
        "- å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿\n",
        "- ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®æ¨è«–å®Ÿè¡Œ\n",
        "- CMIè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ã£ãŸãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆ\n",
        "- çµæœã®ç¢ºèªã¨åˆ†æ\n",
        "\n",
        "## å‰ææ¡ä»¶\n",
        "- å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒ `../../output/experiments/baseline_lightgbm_v1/models/` ã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹\n",
        "- ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒ `../../data/test.csv` ã«é…ç½®ã•ã‚Œã¦ã„ã‚‹\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. ç’°å¢ƒè¨­å®šã¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "import lightgbm as lgb\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pickle\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ãƒ‘ã‚¹ã®è¨­å®š\n",
        "print(f\"ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {os.getcwd()}\")\n",
        "sys.path.append(os.getcwd())\n",
        "sys.path.append('../../data')\n",
        "\n",
        "print(\"ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã®åˆæœŸåŒ–\n",
        "global_models = None\n",
        "global_le = None\n",
        "global_feature_cols = None\n",
        "\n",
        "def load_saved_model():\n",
        "    \"\"\"\n",
        "    ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿\n",
        "    \"\"\"\n",
        "    global global_models, global_le, global_feature_cols\n",
        "    \n",
        "    # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’è¨­å®š\n",
        "    model_dir = '../../output/experiments/baseline_lightgbm_v1/models/'\n",
        "    \n",
        "    print(f\"ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {model_dir}\")\n",
        "    \n",
        "    try:\n",
        "        # ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿\n",
        "        with open(os.path.join(model_dir, 'trained_models.pkl'), 'rb') as f:\n",
        "            global_models = pickle.load(f)\n",
        "        \n",
        "        # ãƒ©ãƒ™ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’èª­ã¿è¾¼ã¿\n",
        "        with open(os.path.join(model_dir, 'label_encoder.pkl'), 'rb') as f:\n",
        "            global_le = pickle.load(f)\n",
        "        \n",
        "        # ç‰¹å¾´é‡ã‚«ãƒ©ãƒ ã‚’èª­ã¿è¾¼ã¿\n",
        "        with open(os.path.join(model_dir, 'feature_cols.pkl'), 'rb') as f:\n",
        "            global_feature_cols = pickle.load(f)\n",
        "        \n",
        "        print(\"ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿å®Œäº†\")\n",
        "        print(f\"ãƒ¢ãƒ‡ãƒ«æ•°: {len(global_models)}\")\n",
        "        print(f\"ã‚¯ãƒ©ã‚¹æ•°: {len(global_le.classes_)}\")\n",
        "        print(f\"ç‰¹å¾´é‡æ•°: {len(global_feature_cols)}\")\n",
        "        \n",
        "        # ã‚¯ãƒ©ã‚¹åã‚’è¡¨ç¤º\n",
        "        print(\"\\näºˆæ¸¬å¯èƒ½ãªã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼:\")\n",
        "        for i, class_name in enumerate(global_le.classes_):\n",
        "            print(f\"  {i:2d}: {class_name}\")\n",
        "        \n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}\")\n",
        "        print(\"äº‹å‰ã«ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ãƒ»ä¿å­˜ã—ã¦ãã ã•ã„\")\n",
        "        raise e\n",
        "\n",
        "# ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿\n",
        "load_saved_model()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. ç‰¹å¾´é‡æŠ½å‡ºé–¢æ•°ã®å®šç¾©\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_features(df):\n",
        "    \"\"\"\n",
        "    ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å˜ä½ã®ç‰¹å¾´é‡æŠ½å‡º\n",
        "    \"\"\"\n",
        "    # ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ã®ã‚«ãƒ©ãƒ ã‚’ç‰¹å®š\n",
        "    sensor_cols = [col for col in df.columns if any(sensor in col for sensor in ['acc_', 'rot_', 'tof_', 'thm_'])]\n",
        "    \n",
        "    # ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å˜ä½ã§çµ±è¨ˆé‡ã‚’è¨ˆç®—\n",
        "    features = {}\n",
        "    \n",
        "    for col in sensor_cols:\n",
        "        if df[col].dtype in ['float64', 'int64']:\n",
        "            # åŸºæœ¬çµ±è¨ˆé‡\n",
        "            features[f'{col}_mean'] = df[col].mean()\n",
        "            features[f'{col}_std'] = df[col].std()\n",
        "            features[f'{col}_min'] = df[col].min()\n",
        "            features[f'{col}_max'] = df[col].max()\n",
        "            features[f'{col}_median'] = df[col].median()\n",
        "            \n",
        "            # åˆ†ä½æ•°\n",
        "            features[f'{col}_q25'] = df[col].quantile(0.25)\n",
        "            features[f'{col}_q75'] = df[col].quantile(0.75)\n",
        "            \n",
        "            # ç¯„å›²\n",
        "            features[f'{col}_range'] = df[col].max() - df[col].min()\n",
        "            \n",
        "            # æ­ªåº¦ã¨å°–åº¦\n",
        "            features[f'{col}_skew'] = df[col].skew()\n",
        "            features[f'{col}_kurtosis'] = df[col].kurtosis()\n",
        "    \n",
        "    return features\n",
        "\n",
        "print(\"ç‰¹å¾´é‡æŠ½å‡ºé–¢æ•°ã®å®šç¾©å®Œäº†\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. æ¨è«–é–¢æ•°ã®å®šç¾©\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_gesture(sequence_df):\n",
        "    \"\"\"\n",
        "    ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼ã‚’äºˆæ¸¬\n",
        "    \"\"\"\n",
        "    global global_models, global_le, global_feature_cols\n",
        "    \n",
        "    # ãƒ¢ãƒ‡ãƒ«ãŒæ­£ã—ãèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯\n",
        "    if global_models is None or global_le is None or global_feature_cols is None:\n",
        "        raise ValueError(\"ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ\")\n",
        "    \n",
        "    # ç‰¹å¾´é‡æŠ½å‡º\n",
        "    features = extract_features(sequence_df)\n",
        "    \n",
        "    # ç‰¹å¾´é‡ã‚’DataFrameã«å¤‰æ›\n",
        "    feature_df = pd.DataFrame([features])\n",
        "    \n",
        "    # å¿…è¦ãªç‰¹å¾´é‡ã‚«ãƒ©ãƒ ã®ã¿é¸æŠ\n",
        "    feature_df = feature_df[global_feature_cols]\n",
        "    \n",
        "    # äºˆæ¸¬ï¼ˆã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼‰\n",
        "    predictions = []\n",
        "    for model in global_models:\n",
        "        pred = model.predict(feature_df, num_iteration=model.best_iteration)\n",
        "        predictions.append(pred)\n",
        "    \n",
        "    # å¹³å‡äºˆæ¸¬\n",
        "    avg_pred = np.mean(predictions, axis=0)\n",
        "    predicted_class = np.argmax(avg_pred)\n",
        "    \n",
        "    # ã‚¯ãƒ©ã‚¹åã«å¤‰æ›\n",
        "    predicted_gesture = global_le.inverse_transform([predicted_class])[0]\n",
        "    \n",
        "    return predicted_gesture, avg_pred\n",
        "\n",
        "print(\"æ¨è«–é–¢æ•°ã®å®šç¾©å®Œäº†\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿\n",
        "test_data = pd.read_csv('../../data/test.csv')\n",
        "test_demographics = pd.read_csv('../../data/test_demographics.csv')\n",
        "\n",
        "print(f\"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å½¢çŠ¶: {test_data.shape}\")\n",
        "print(f\"ãƒ†ã‚¹ãƒˆäººå£çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã®å½¢çŠ¶: {test_demographics.shape}\")\n",
        "\n",
        "# ã‚·ãƒ¼ã‚±ãƒ³ã‚¹IDã‚’ç¢ºèª\n",
        "test_sequence_ids = test_data['sequence_id'].unique()\n",
        "print(f\"ãƒ†ã‚¹ãƒˆã‚·ãƒ¼ã‚±ãƒ³ã‚¹æ•°: {len(test_sequence_ids)}\")\n",
        "print(f\"ãƒ†ã‚¹ãƒˆã‚·ãƒ¼ã‚±ãƒ³ã‚¹ID: {test_sequence_ids}\")\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬æƒ…å ±ã‚’è¡¨ç¤º\n",
        "print(\"\\nãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬æƒ…å ±:\")\n",
        "print(test_data.head())\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. å€‹åˆ¥ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã§ã®æ¨è«–ãƒ†ã‚¹ãƒˆ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å„ãƒ†ã‚¹ãƒˆã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã§æ¨è«–ã‚’ãƒ†ã‚¹ãƒˆ\n",
        "test_results = []\n",
        "\n",
        "for sequence_id in test_sequence_ids:\n",
        "    print(f\"\\n=== ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ {sequence_id} ã®æ¨è«–ãƒ†ã‚¹ãƒˆ ===\")\n",
        "    \n",
        "    # è©²å½“ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—\n",
        "    sequence_data = test_data[test_data['sequence_id'] == sequence_id]\n",
        "    \n",
        "    print(f\"ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿æ•°: {len(sequence_data)}\")\n",
        "    \n",
        "    # æ¨è«–å®Ÿè¡Œ\n",
        "    try:\n",
        "        predicted_gesture, prediction_probs = predict_gesture(sequence_data)\n",
        "        \n",
        "        print(f\"äºˆæ¸¬çµæœ: {predicted_gesture}\")\n",
        "        print(f\"äºˆæ¸¬ç¢ºç‡: {prediction_probs.max():.4f}\")\n",
        "        \n",
        "        # çµæœã‚’ä¿å­˜\n",
        "        test_results.append({\n",
        "            'sequence_id': sequence_id,\n",
        "            'predicted_gesture': predicted_gesture,\n",
        "            'confidence': prediction_probs.max(),\n",
        "            'prediction_probs': prediction_probs\n",
        "        })\n",
        "        \n",
        "        # ä¸Šä½3ã®äºˆæ¸¬ã‚’è¡¨ç¤º\n",
        "        top_3_indices = np.argsort(prediction_probs)[-3:][::-1]\n",
        "        print(\"äºˆæ¸¬ãƒˆãƒƒãƒ—3:\")\n",
        "        for i, idx in enumerate(top_3_indices):\n",
        "            gesture_name = global_le.inverse_transform([idx])[0]\n",
        "            prob = prediction_probs[idx]\n",
        "            print(f\"  {i+1}: {gesture_name} ({prob:.4f})\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}\")\n",
        "        test_results.append({\n",
        "            'sequence_id': sequence_id,\n",
        "            'predicted_gesture': 'ERROR',\n",
        "            'confidence': 0.0,\n",
        "            'error': str(e)\n",
        "        })\n",
        "\n",
        "print(\"\\n=== å…¨ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®æ¨è«–ãƒ†ã‚¹ãƒˆå®Œäº† ===\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 7. çµæœã®ç¢ºèªã¨åˆ†æ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# çµæœã‚’DataFrameã«å¤‰æ›\n",
        "results_df = pd.DataFrame(test_results)\n",
        "print(\"æ¨è«–çµæœã®æ¦‚è¦:\")\n",
        "print(results_df[['sequence_id', 'predicted_gesture', 'confidence']])\n",
        "\n",
        "# æå‡ºãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã®ä½œæˆ\n",
        "submission_df = results_df[['sequence_id', 'predicted_gesture']].copy()\n",
        "submission_df.columns = ['sequence_id', 'gesture']\n",
        "\n",
        "print(\"\\næå‡ºãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼:\")\n",
        "print(submission_df)\n",
        "\n",
        "# æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜\n",
        "submission_df.to_csv('local_test_submission.csv', index=False)\n",
        "print(\"\\næå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã‚’ 'local_test_submission.csv' ã«ä¿å­˜ã—ã¾ã—ãŸ\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 8. æœ€çµ‚ç¢ºèª\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆå®Œäº† ===\")\n",
        "print(f\"âœ… å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿: æˆåŠŸ ({len(global_models)}å€‹ã®ãƒ¢ãƒ‡ãƒ«)\")\n",
        "print(f\"âœ… ç‰¹å¾´é‡æŠ½å‡º: æˆåŠŸ ({len(global_feature_cols)}å€‹ã®ç‰¹å¾´é‡)\")\n",
        "print(f\"âœ… æ¨è«–ãƒ†ã‚¹ãƒˆ: æˆåŠŸ ({len(test_results)}å€‹ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹)\")\n",
        "print(f\"âœ… æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ: æˆåŠŸ (local_test_submission.csv)\")\n",
        "\n",
        "# ã‚¨ãƒ©ãƒ¼ãŒã‚ã£ãŸå ´åˆã®å ±å‘Š\n",
        "error_count = sum(1 for result in test_results if result['predicted_gesture'] == 'ERROR')\n",
        "if error_count > 0:\n",
        "    print(f\"âš ï¸  ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸã‚·ãƒ¼ã‚±ãƒ³ã‚¹: {error_count}å€‹\")\n",
        "else:\n",
        "    print(\"âœ… å…¨ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã§æ­£å¸¸ã«æ¨è«–å®Œäº†\")\n",
        "\n",
        "print(\"\\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:\")\n",
        "print(\"1. çµæœã‚’ç¢ºèªã—ã€æ¨è«–ãŒæ­£å¸¸ã«å‹•ä½œã™ã‚‹ã“ã¨ã‚’ç¢ºèª\")\n",
        "print(\"2. cmi-2025-baseline-submission-final.ipynb ã‚’ Kaggle ã«æå‡º\")\n",
        "print(\"3. Kaggleç’°å¢ƒã§ã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ\")\n",
        "\n",
        "print(\"\\nğŸ‰ ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆãŒå®Œäº†ã—ã¾ã—ãŸï¼\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
