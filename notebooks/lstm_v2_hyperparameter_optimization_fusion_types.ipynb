{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# LSTM v2 åŒ…æ‹¬çš„ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–\n",
        "\n",
        "## æ¦‚è¦\n",
        "ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã¨Fusionæ–¹å¼ã‚’åŒ…æ‹¬çš„ã«æœ€é©åŒ–ã—ã€æœ€é«˜æ€§èƒ½ã®ãƒ¢ãƒ‡ãƒ«æ§‹æˆã‚’ç™ºè¦‹ã—ã¾ã™ã€‚\n",
        "\n",
        "### æœ€é©åŒ–å¯¾è±¡\n",
        "- **ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º**: w64_s16 vs w128_s32\n",
        "- **Fusionæ–¹å¼**: concatenate, attention, gated\n",
        "- **ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**: LSTMå±¤ã€Denseå±¤ã€Dropoutç­‰\n",
        "- **å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**: å­¦ç¿’ç‡ã€ãƒãƒƒãƒã‚µã‚¤ã‚ºç­‰\n",
        "\n",
        "### è©•ä¾¡æŒ‡æ¨™\n",
        "- **CMI Score**: Competition Metric Index (ä¸»è¦æŒ‡æ¨™)\n",
        "- **Binary F1**: Target vs Non-targetè­˜åˆ¥æ€§èƒ½\n",
        "- **Macro F1**: 18ã‚¯ãƒ©ã‚¹åˆ†é¡æ€§èƒ½\n",
        "- **Test Accuracy**: åˆ†é¡ç²¾åº¦\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿å®Œäº†\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’è¿½åŠ \n",
        "sys.path.append('../src')\n",
        "\n",
        "from lstm_v2_trainer import LSTMv2Trainer\n",
        "from cmi_evaluation import calculate_cmi_score\n",
        "\n",
        "import optuna\n",
        "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿å®Œäº†\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ LSTM v2 åŒ…æ‹¬çš„ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
            "ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®š: ['w64_s16', 'w128_s32']\n",
            "Fusionæ–¹å¼: ['concatenate', 'attention', 'gated']\n",
            "å„è¨­å®šã®è©¦è¡Œæ•°: 50\n",
            "ç·è©¦è¡Œæ•°äºˆå®š: 100\n",
            "æœ€é©åŒ–ã•ã‚ŒãŸdemographicsä½¿ç”¨: True\n",
            "çµæœä¿å­˜å…ˆ: ../results/comprehensive_optimization\n"
          ]
        }
      ],
      "source": [
        "# åŒ…æ‹¬çš„æœ€é©åŒ–è¨­å®š\n",
        "USE_OPTIMIZED_DEMOGRAPHICS = True\n",
        "N_TRIALS_PER_CONFIG = 50  # å„ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®šã‚ãŸã‚Šã®è©¦è¡Œæ•°\n",
        "WINDOW_CONFIGS = [\"w64_s16\", \"w128_s32\"]  # æ¯”è¼ƒã™ã‚‹ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º\n",
        "FUSION_TYPES = ['concatenate', 'attention', 'gated']  # æ¯”è¼ƒã™ã‚‹Fusionæ–¹å¼\n",
        "\n",
        "# æœ¬ç•ªç”¨Studyå\n",
        "STUDY_BASE_NAME = \"lstm_v2_comprehensive_optimization\"\n",
        "RESULTS_DIR = \"../results/comprehensive_optimization\"\n",
        "\n",
        "print(f\"ğŸš€ LSTM v2 åŒ…æ‹¬çš„ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–\")\n",
        "print(f\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
        "print(f\"ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®š: {WINDOW_CONFIGS}\")\n",
        "print(f\"Fusionæ–¹å¼: {FUSION_TYPES}\")\n",
        "print(f\"å„è¨­å®šã®è©¦è¡Œæ•°: {N_TRIALS_PER_CONFIG}\")\n",
        "print(f\"ç·è©¦è¡Œæ•°äºˆå®š: {N_TRIALS_PER_CONFIG * len(WINDOW_CONFIGS)}\")\n",
        "print(f\"æœ€é©åŒ–ã•ã‚ŒãŸdemographicsä½¿ç”¨: {USE_OPTIMIZED_DEMOGRAPHICS}\")\n",
        "print(f\"çµæœä¿å­˜å…ˆ: {RESULTS_DIR}\")\n",
        "\n",
        "# çµæœä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ\n",
        "import os\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“Š å„ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®šã®ãƒ‡ãƒ¼ã‚¿æƒ…å ±:\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
            "Mixed precision enabled for better GPU performance\n",
            "GPUåˆ©ç”¨å¯èƒ½: 1å°\n",
            "ä½¿ç”¨GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
            "LSTM v2å­¦ç¿’ç’°å¢ƒåˆæœŸåŒ–å®Œäº†\n",
            "å®Ÿé¨“å: temp_info\n",
            "ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®š: w64_s16\n",
            "å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: ../output/experiments/temp_info_w64_s16\n",
            "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿: ../output/experiments/lstm_v2_w64_s16/preprocessed\n",
            "GPUåˆ©ç”¨å¯èƒ½: True\n",
            "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...\n",
            "æœ€é©åŒ–ã•ã‚ŒãŸdemographicsç‰¹å¾´é‡ã‚’ä½¿ç”¨ã—ã¾ã™\n",
            "æœ€é©åŒ–ã•ã‚ŒãŸdemographicså½¢çŠ¶: (13393, 18)\n",
            "ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†:\n",
            "  ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿: (13393, 64, 332)\n",
            "  Demographics: (13393, 18)\n",
            "  ãƒ©ãƒ™ãƒ«: (13393,)\n",
            "  ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "w64_s16:\n",
            "  ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿: (13393, 64, 332)\n",
            "  Demographics: (13393, 18)\n",
            "  ãƒ©ãƒ™ãƒ«: (13393,)\n",
            "\n",
            "Mixed precision enabled for better GPU performance\n",
            "GPUåˆ©ç”¨å¯èƒ½: 1å°\n",
            "ä½¿ç”¨GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
            "LSTM v2å­¦ç¿’ç’°å¢ƒåˆæœŸåŒ–å®Œäº†\n",
            "å®Ÿé¨“å: temp_info\n",
            "ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®š: w128_s32\n",
            "å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: ../output/experiments/temp_info_w128_s32\n",
            "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿: ../output/experiments/lstm_v2_w128_s32/preprocessed\n",
            "GPUåˆ©ç”¨å¯èƒ½: True\n",
            "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...\n",
            "æœ€é©åŒ–ã•ã‚ŒãŸdemographicsç‰¹å¾´é‡ã‚’ä½¿ç”¨ã—ã¾ã™\n",
            "æœ€é©åŒ–ã•ã‚ŒãŸdemographicså½¢çŠ¶: (13393, 18)\n",
            "ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†:\n",
            "  ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿: (8673, 128, 332)\n",
            "  Demographics: (13393, 18)\n",
            "  ãƒ©ãƒ™ãƒ«: (8673,)\n",
            "  ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "w128_s32: ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ - ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºãŒä¸€è‡´ã—ã¾ã›ã‚“\n",
            "\n",
            "âœ… ãƒ‡ãƒ¼ã‚¿æƒ…å ±ç¢ºèªå®Œäº†\n"
          ]
        }
      ],
      "source": [
        "# å„ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã®ãƒ‡ãƒ¼ã‚¿æƒ…å ±ã‚’ç¢ºèª\n",
        "print(\"ğŸ“Š å„ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®šã®ãƒ‡ãƒ¼ã‚¿æƒ…å ±:\")\n",
        "print(\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
        "\n",
        "for window_config in WINDOW_CONFIGS:\n",
        "    try:\n",
        "        # ä¸€æ™‚çš„ã«ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚’ä½œæˆã—ã¦ãƒ‡ãƒ¼ã‚¿æƒ…å ±ã‚’å–å¾—\n",
        "        temp_trainer = LSTMv2Trainer(\n",
        "            experiment_name=\"temp_info\",\n",
        "            window_config=window_config,\n",
        "            n_demographics_features=18 if USE_OPTIMIZED_DEMOGRAPHICS else 20\n",
        "        )\n",
        "        temp_data = temp_trainer.load_preprocessed_data(use_optimized_demographics=USE_OPTIMIZED_DEMOGRAPHICS)\n",
        "        \n",
        "        print(f\"{window_config}:\")\n",
        "        print(f\"  ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿: {temp_data['X_sensor_windows'].shape}\")\n",
        "        print(f\"  Demographics: {temp_data['X_demographics_windows'].shape}\")\n",
        "        print(f\"  ãƒ©ãƒ™ãƒ«: {temp_data['y_windows'].shape}\")\n",
        "        print()\n",
        "        \n",
        "        # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢\n",
        "        del temp_trainer, temp_data\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"{window_config}: ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ - {str(e)}\")\n",
        "        print()\n",
        "\n",
        "print(\"âœ… ãƒ‡ãƒ¼ã‚¿æƒ…å ±ç¢ºèªå®Œäº†\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Objectiveé–¢æ•°ä½œæˆå®Œäº†\n"
          ]
        }
      ],
      "source": [
        "def create_objective_function(window_config):\n",
        "    \"\"\"\n",
        "    æŒ‡å®šã•ã‚ŒãŸã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®šç”¨ã®Objectiveé–¢æ•°ã‚’ä½œæˆ\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    window_config : str\n",
        "        ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®š (\"w64_s16\" or \"w128_s32\")\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    function\n",
        "        Optunaæœ€é©åŒ–ã®ç›®çš„é–¢æ•°\n",
        "    \"\"\"\n",
        "    \n",
        "    def objective(trial):\n",
        "        \"\"\"\n",
        "        Optunaæœ€é©åŒ–ã®ç›®çš„é–¢æ•°\n",
        "        \"\"\"\n",
        "        try:\n",
        "            print(f\"\\nğŸ” Trial {trial.number} - {window_config}\")\n",
        "            \n",
        "            # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ææ¡ˆ\n",
        "            params = {\n",
        "                # ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
        "                'lstm_units_1': trial.suggest_int('lstm_units_1', 32, 128, step=16),\n",
        "                'lstm_units_2': trial.suggest_int('lstm_units_2', 16, 64, step=8),\n",
        "                'dense_units': trial.suggest_int('dense_units', 16, 64, step=8),\n",
        "                'demographics_dense_units': trial.suggest_int('demographics_dense_units', 8, 32, step=4),\n",
        "                'fusion_dense_units': trial.suggest_int('fusion_dense_units', 16, 48, step=8),\n",
        "                \n",
        "                # æ­£å‰‡åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
        "                'dropout_rate': trial.suggest_float('dropout_rate', 0.1, 0.5, step=0.05),\n",
        "                'dense_dropout_rate': trial.suggest_float('dense_dropout_rate', 0.1, 0.4, step=0.05),\n",
        "                \n",
        "                # å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
        "                'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True),\n",
        "                'batch_size': trial.suggest_categorical('batch_size', [16, 32, 64]),\n",
        "                \n",
        "                # Fusionæ–¹å¼\n",
        "                'fusion_type': trial.suggest_categorical('fusion_type', FUSION_TYPES),\n",
        "                \n",
        "                # å­¦ç¿’åˆ¶å¾¡ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆæœ¬ç•ªç”¨è¨­å®šï¼‰\n",
        "                'epochs': 100,  # æœ€å¤§ã‚¨ãƒãƒƒã‚¯æ•°\n",
        "                'patience': 20,  # æ—©æœŸåœæ­¢ã®å¾…æ©Ÿã‚¨ãƒãƒƒã‚¯æ•°\n",
        "                'reduce_lr_patience': 10,  # å­¦ç¿’ç‡å‰Šæ¸›ã®å¾…æ©Ÿã‚¨ãƒãƒƒã‚¯æ•°\n",
        "                'use_tqdm': False,  # æœ€é©åŒ–ä¸­ã¯é€²æ—ãƒãƒ¼ç„¡åŠ¹\n",
        "                'use_tensorboard': False  # æœ€é©åŒ–ä¸­ã¯TensorBoardç„¡åŠ¹\n",
        "            }\n",
        "            \n",
        "            # ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã®åˆæœŸåŒ–ï¼ˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®šã‚’å‹•çš„ã«è¨­å®šï¼‰\n",
        "            trainer = LSTMv2Trainer(\n",
        "                experiment_name=f\"trial_{trial.number}_{window_config}\",\n",
        "                window_config=window_config,\n",
        "                n_demographics_features=18 if USE_OPTIMIZED_DEMOGRAPHICS else 20\n",
        "            )\n",
        "            \n",
        "            # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆæ¯å›èª­ã¿è¾¼ã¿ã§ç¢ºå®Ÿæ€§ã‚’ä¿è¨¼ï¼‰\n",
        "            data = trainer.load_preprocessed_data(use_optimized_demographics=USE_OPTIMIZED_DEMOGRAPHICS)\n",
        "            \n",
        "            # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’\n",
        "            results = trainer.train_model(data, model_params=params, fusion_type=params['fusion_type'])\n",
        "            \n",
        "            # äºˆæ¸¬çµæœã®å–å¾—\n",
        "            predictions = results['results']['predictions']\n",
        "            \n",
        "            # CMIã‚¹ã‚³ã‚¢è¨ˆç®—\n",
        "            # label_encoderã‚’å–å¾—\n",
        "            label_encoder = data['label_encoder'] if 'label_encoder' in data else None\n",
        "            \n",
        "            cmi_score, binary_f1, macro_f1, test_accuracy = calculate_cmi_score(\n",
        "                predictions,  # y_pred \n",
        "                results['test_data'][2],  # y_true\n",
        "                label_encoder=label_encoder,\n",
        "                verbose=False\n",
        "            )\n",
        "            \n",
        "            # è©³ç´°ãªçµæœã‚’trial attributesã¨ã—ã¦è¨˜éŒ²\n",
        "            trial.set_user_attr('window_config', window_config)\n",
        "            trial.set_user_attr('binary_f1', binary_f1)\n",
        "            trial.set_user_attr('macro_f1', macro_f1)\n",
        "            trial.set_user_attr('test_accuracy', test_accuracy)\n",
        "            trial.set_user_attr('fusion_type', params['fusion_type'])\n",
        "            \n",
        "            print(f\"âœ… Trial {trial.number}: CMI={cmi_score:.4f}, Binary F1={binary_f1:.4f}, Fusion={params['fusion_type']}\")\n",
        "            \n",
        "            # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢\n",
        "            del trainer, data, results\n",
        "            \n",
        "            return cmi_score\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Trial {trial.number} failed: {str(e)}\")\n",
        "            return 0.0\n",
        "    \n",
        "    return objective\n",
        "\n",
        "print(\"âœ… Objectiveé–¢æ•°ä½œæˆå®Œäº†\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ åŒ…æ‹¬çš„æœ€é©åŒ–é–‹å§‹\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
            "\n",
            "ğŸ“Š w64_s16 ã§ã®æœ€é©åŒ–é–‹å§‹\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-08 21:05:56,710] Using an existing study with name 'lstm_v2_comprehensive_optimization_w64_s16' instead of creating a new one.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Studyå: lstm_v2_comprehensive_optimization_w64_s16\n",
            "æ—¢å­˜è©¦è¡Œæ•°: 36\n",
            "å®Ÿè¡Œã™ã‚‹è©¦è¡Œæ•°: 14\n",
            "\n",
            "ğŸ” Trial 36 - w64_s16\n",
            "Mixed precision enabled for better GPU performance\n",
            "GPUåˆ©ç”¨å¯èƒ½: 1å°\n",
            "ä½¿ç”¨GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
            "LSTM v2å­¦ç¿’ç’°å¢ƒåˆæœŸåŒ–å®Œäº†\n",
            "å®Ÿé¨“å: trial_36_w64_s16\n",
            "ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®š: w64_s16\n",
            "å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: ../output/experiments/trial_36_w64_s16_w64_s16\n",
            "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿: ../output/experiments/lstm_v2_w64_s16/preprocessed\n",
            "GPUåˆ©ç”¨å¯èƒ½: True\n",
            "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...\n",
            "æœ€é©åŒ–ã•ã‚ŒãŸdemographicsç‰¹å¾´é‡ã‚’ä½¿ç”¨ã—ã¾ã™\n",
            "æœ€é©åŒ–ã•ã‚ŒãŸdemographicså½¢çŠ¶: (13393, 18)\n",
            "ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†:\n",
            "  ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿: (13393, 64, 332)\n",
            "  Demographics: (13393, 18)\n",
            "  ãƒ©ãƒ™ãƒ«: (13393,)\n",
            "  ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹ (èåˆæ–¹å¼: attention)...\n",
            "ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ä¸­...\n",
            "ãƒ†ã‚¹ãƒˆã‚µã‚¤ã‚º: 0.2\n",
            "æ¤œè¨¼ã‚µã‚¤ã‚º: 0.2\n",
            "ãƒ‡ãƒ¼ã‚¿åˆ†å‰²å®Œäº†:\n",
            "  è¨“ç·´ - ã‚»ãƒ³ã‚µãƒ¼: (8571, 64, 332), Demographics: (8571, 18), ãƒ©ãƒ™ãƒ«: (8571,)\n",
            "  æ¤œè¨¼ - ã‚»ãƒ³ã‚µãƒ¼: (2143, 64, 332), Demographics: (2143, 18), ãƒ©ãƒ™ãƒ«: (2143,)\n",
            "  ãƒ†ã‚¹ãƒˆ - ã‚»ãƒ³ã‚µãƒ¼: (2679, 64, 332), Demographics: (2679, 18), ãƒ©ãƒ™ãƒ«: (2679,)\n",
            "å…¥åŠ›å½¢çŠ¶:\n",
            "  ã‚»ãƒ³ã‚µãƒ¼: (64, 332)\n",
            "  Demographics: (18,)\n",
            "  ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "GPUä¸Šã§ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆãƒ»å­¦ç¿’ã—ã¾ã™\n",
            "Mixed precision enabled for better GPU performance\n",
            "GPUåˆ©ç”¨å¯èƒ½: 1å°\n",
            "ä½¿ç”¨GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
            "LSTM v2ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†\n",
            "ã‚»ãƒ³ã‚µãƒ¼å…¥åŠ›å½¢çŠ¶: (64, 332)\n",
            "Demographicså…¥åŠ›å½¢çŠ¶: (18,)\n",
            "ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "èåˆæ–¹å¼: attention\n",
            "GPUåˆ©ç”¨å¯èƒ½: True\n",
            "LSTM v2ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ä¸­...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1751976365.479637  506286 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5660 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰å®Œäº†\n",
            "ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 181,042\n",
            "\n",
            "=== ãƒ¢ãƒ‡ãƒ«ã‚µãƒãƒªãƒ¼ ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"lstm_v2_hybrid\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"lstm_v2_hybrid\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ sensor_input        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">332</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">132,160</span> â”‚ sensor_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_1           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> â”‚ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_1      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ lstm_bn_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_input  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">37,120</span> â”‚ lstm_dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">608</span> â”‚ demographics_inpâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_2           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_2      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ lstm_bn_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dense        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,120</span> â”‚ lstm_dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dropout      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sensor_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_weights   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,584</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attended_sensor     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sensor_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          â”‚                   â”‚            â”‚ attention_weightâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_projeâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,584</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_fusion    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ attended_sensor[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚                   â”‚            â”‚ demographics_proâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dense        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,352</span> â”‚ attention_fusionâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dropout      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ fusion_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">882</span> â”‚ fusion_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ sensor_input        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m332\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m80\u001b[0m)    â”‚    \u001b[38;5;34m132,160\u001b[0m â”‚ sensor_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_1           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m80\u001b[0m)    â”‚        \u001b[38;5;34m320\u001b[0m â”‚ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_1      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m80\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ lstm_bn_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_input  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚     \u001b[38;5;34m37,120\u001b[0m â”‚ lstm_dropout_1[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚        \u001b[38;5;34m608\u001b[0m â”‚ demographics_inpâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_2           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m256\u001b[0m â”‚ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_2      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ lstm_bn_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚      \u001b[38;5;34m1,056\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dense        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚      \u001b[38;5;34m3,120\u001b[0m â”‚ lstm_dropout_2[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dropout      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sensor_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_weights   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚      \u001b[38;5;34m1,584\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attended_sensor     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sensor_dropout[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mMultiply\u001b[0m)          â”‚                   â”‚            â”‚ attention_weightâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_projeâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚      \u001b[38;5;34m1,584\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_fusion    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ attended_sensor[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚                   â”‚            â”‚ demographics_proâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dense        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚      \u001b[38;5;34m2,352\u001b[0m â”‚ attention_fusionâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dropout      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ fusion_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (\u001b[38;5;33mDense\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        â”‚        \u001b[38;5;34m882\u001b[0m â”‚ fusion_dropout[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">181,042</span> (707.20 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m181,042\u001b[0m (707.20 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">180,754</span> (706.07 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m180,754\u001b[0m (706.07 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> (1.12 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m288\u001b[0m (1.12 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹...\n",
            "ã‚»ãƒ³ã‚µãƒ¼è¨“ç·´ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (8571, 64, 332)\n",
            "Demographicsè¨“ç·´ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (8571, 18)\n",
            "ã‚»ãƒ³ã‚µãƒ¼æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (2143, 64, 332)\n",
            "Demographicsæ¤œè¨¼ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (2143, 18)\n",
            "è¨“ç·´ãƒ©ãƒ™ãƒ«å½¢çŠ¶: (8571,)\n",
            "æ¤œè¨¼ãƒ©ãƒ™ãƒ«å½¢çŠ¶: (2143,)\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-08 21:06:13.078957: E tensorflow/core/util/util.cc:131] oneDNN supports DT_HALF only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n",
            "I0000 00:00:1751976374.208365  769988 cuda_dnn.cc:529] Loaded cuDNN version 90501\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.1499 - loss: 2.7991\n",
            "Epoch 1: val_loss improved from inf to 2.47966, saving model to ../output/experiments/trial_36_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 45ms/step - accuracy: 0.1501 - loss: 2.7984 - val_accuracy: 0.2450 - val_loss: 2.4797 - learning_rate: 0.0040\n",
            "Epoch 2/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.2583 - loss: 2.4500\n",
            "Epoch 2: val_loss improved from 2.47966 to 2.32697, saving model to ../output/experiments/trial_36_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.2583 - loss: 2.4499 - val_accuracy: 0.2893 - val_loss: 2.3270 - learning_rate: 0.0040\n",
            "Epoch 3/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.2789 - loss: 2.3378\n",
            "Epoch 3: val_loss improved from 2.32697 to 2.28436, saving model to ../output/experiments/trial_36_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.2790 - loss: 2.3377 - val_accuracy: 0.3220 - val_loss: 2.2844 - learning_rate: 0.0040\n",
            "Epoch 4/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.2993 - loss: 2.3105\n",
            "Epoch 4: val_loss improved from 2.28436 to 2.26390, saving model to ../output/experiments/trial_36_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.2994 - loss: 2.3105 - val_accuracy: 0.3304 - val_loss: 2.2639 - learning_rate: 0.0040\n",
            "Epoch 5/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3322 - loss: 2.2329\n",
            "Epoch 5: val_loss improved from 2.26390 to 2.23139, saving model to ../output/experiments/trial_36_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.3322 - loss: 2.2330 - val_accuracy: 0.3341 - val_loss: 2.2314 - learning_rate: 0.0040\n",
            "Epoch 6/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3437 - loss: 2.1810\n",
            "Epoch 6: val_loss improved from 2.23139 to 2.18091, saving model to ../output/experiments/trial_36_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.3437 - loss: 2.1810 - val_accuracy: 0.3486 - val_loss: 2.1809 - learning_rate: 0.0040\n",
            "Epoch 7/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3567 - loss: 2.1914\n",
            "Epoch 7: val_loss did not improve from 2.18091\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.3567 - loss: 2.1915 - val_accuracy: 0.3420 - val_loss: 2.2028 - learning_rate: 0.0040\n",
            "Epoch 8/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3668 - loss: 2.1554\n",
            "Epoch 8: val_loss improved from 2.18091 to 2.16343, saving model to ../output/experiments/trial_36_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.3668 - loss: 2.1555 - val_accuracy: 0.3644 - val_loss: 2.1634 - learning_rate: 0.0040\n",
            "Epoch 9/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3759 - loss: 2.1546\n",
            "Epoch 9: val_loss did not improve from 2.16343\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.3759 - loss: 2.1546 - val_accuracy: 0.3486 - val_loss: 2.1889 - learning_rate: 0.0040\n",
            "Epoch 10/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3787 - loss: 2.1662\n",
            "Epoch 10: val_loss improved from 2.16343 to 2.16070, saving model to ../output/experiments/trial_36_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.3787 - loss: 2.1662 - val_accuracy: 0.3644 - val_loss: 2.1607 - learning_rate: 0.0040\n",
            "Epoch 11/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4071 - loss: 2.0775\n",
            "Epoch 11: val_loss improved from 2.16070 to 2.10467, saving model to ../output/experiments/trial_36_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.4071 - loss: 2.0777 - val_accuracy: 0.3952 - val_loss: 2.1047 - learning_rate: 0.0040\n",
            "Epoch 12/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4125 - loss: 2.0651\n",
            "Epoch 12: val_loss did not improve from 2.10467\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.4124 - loss: 2.0654 - val_accuracy: 0.3915 - val_loss: 2.1140 - learning_rate: 0.0040\n",
            "Epoch 13/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4168 - loss: 2.0784\n",
            "Epoch 13: val_loss did not improve from 2.10467\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.4168 - loss: 2.0785 - val_accuracy: 0.3906 - val_loss: 2.1536 - learning_rate: 0.0040\n",
            "Epoch 14/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3958 - loss: 2.1109\n",
            "Epoch 14: val_loss did not improve from 2.10467\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.3959 - loss: 2.1110 - val_accuracy: 0.3747 - val_loss: 2.1896 - learning_rate: 0.0040\n",
            "Epoch 15/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4348 - loss: 2.0332\n",
            "Epoch 15: val_loss did not improve from 2.10467\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4347 - loss: 2.0334 - val_accuracy: 0.4036 - val_loss: 2.1187 - learning_rate: 0.0040\n",
            "Epoch 16/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4465 - loss: 2.0425\n",
            "Epoch 16: val_loss improved from 2.10467 to 2.09063, saving model to ../output/experiments/trial_36_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.4465 - loss: 2.0425 - val_accuracy: 0.4279 - val_loss: 2.0906 - learning_rate: 0.0040\n",
            "Epoch 17/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4417 - loss: 2.0271\n",
            "Epoch 17: val_loss improved from 2.09063 to 2.05769, saving model to ../output/experiments/trial_36_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4417 - loss: 2.0273 - val_accuracy: 0.4414 - val_loss: 2.0577 - learning_rate: 0.0040\n",
            "Epoch 18/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4513 - loss: 2.0034\n",
            "Epoch 18: val_loss did not improve from 2.05769\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.4513 - loss: 2.0035 - val_accuracy: 0.4312 - val_loss: 2.0615 - learning_rate: 0.0040\n",
            "Epoch 19/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4657 - loss: 1.9774\n",
            "Epoch 19: val_loss improved from 2.05769 to 2.04000, saving model to ../output/experiments/trial_36_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.4656 - loss: 1.9775 - val_accuracy: 0.4382 - val_loss: 2.0400 - learning_rate: 0.0040\n",
            "Epoch 20/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4716 - loss: 1.9654\n",
            "Epoch 20: val_loss improved from 2.04000 to 2.02265, saving model to ../output/experiments/trial_36_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.4716 - loss: 1.9656 - val_accuracy: 0.4536 - val_loss: 2.0226 - learning_rate: 0.0040\n",
            "Epoch 21/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4683 - loss: 1.9578\n",
            "Epoch 21: val_loss did not improve from 2.02265\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.4683 - loss: 1.9579 - val_accuracy: 0.4540 - val_loss: 2.0369 - learning_rate: 0.0040\n",
            "Epoch 22/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4842 - loss: 1.9332\n",
            "Epoch 22: val_loss did not improve from 2.02265\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.4842 - loss: 1.9333 - val_accuracy: 0.4503 - val_loss: 2.0670 - learning_rate: 0.0040\n",
            "Epoch 23/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4800 - loss: 1.9476\n",
            "Epoch 23: val_loss did not improve from 2.02265\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4800 - loss: 1.9477 - val_accuracy: 0.4158 - val_loss: 2.1098 - learning_rate: 0.0040\n",
            "Epoch 24/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4812 - loss: 1.9457\n",
            "Epoch 24: val_loss improved from 2.02265 to 2.01098, saving model to ../output/experiments/trial_36_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4812 - loss: 1.9458 - val_accuracy: 0.4587 - val_loss: 2.0110 - learning_rate: 0.0040\n",
            "Epoch 25/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4933 - loss: 1.8875\n",
            "Epoch 25: val_loss did not improve from 2.01098\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.4932 - loss: 1.8876 - val_accuracy: 0.4634 - val_loss: 2.0286 - learning_rate: 0.0040\n",
            "Epoch 26/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4974 - loss: 1.8863\n",
            "Epoch 26: val_loss did not improve from 2.01098\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.4974 - loss: 1.8865 - val_accuracy: 0.4573 - val_loss: 2.0141 - learning_rate: 0.0040\n",
            "Epoch 27/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4937 - loss: 1.8915\n",
            "Epoch 27: val_loss did not improve from 2.01098\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.4937 - loss: 1.8917 - val_accuracy: 0.4620 - val_loss: 2.0313 - learning_rate: 0.0040\n",
            "Epoch 28/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4949 - loss: 1.9069\n",
            "Epoch 28: val_loss did not improve from 2.01098\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4949 - loss: 1.9068 - val_accuracy: 0.4526 - val_loss: 2.0362 - learning_rate: 0.0040\n",
            "Epoch 29/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5015 - loss: 1.8791\n",
            "Epoch 29: val_loss improved from 2.01098 to 2.00985, saving model to ../output/experiments/trial_36_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.5015 - loss: 1.8791 - val_accuracy: 0.4517 - val_loss: 2.0098 - learning_rate: 0.0040\n",
            "Epoch 30/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5044 - loss: 1.8698\n",
            "Epoch 30: val_loss improved from 2.00985 to 2.00961, saving model to ../output/experiments/trial_36_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.5044 - loss: 1.8698 - val_accuracy: 0.4704 - val_loss: 2.0096 - learning_rate: 0.0040\n",
            "Epoch 31/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5071 - loss: 1.8564\n",
            "Epoch 31: val_loss improved from 2.00961 to 1.97060, saving model to ../output/experiments/trial_36_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.5072 - loss: 1.8565 - val_accuracy: 0.4802 - val_loss: 1.9706 - learning_rate: 0.0040\n",
            "Epoch 32/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5102 - loss: 1.8573\n",
            "Epoch 32: val_loss did not improve from 1.97060\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.5102 - loss: 1.8574 - val_accuracy: 0.4643 - val_loss: 2.0028 - learning_rate: 0.0040\n",
            "Epoch 33/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5195 - loss: 1.8315\n",
            "Epoch 33: val_loss improved from 1.97060 to 1.96450, saving model to ../output/experiments/trial_36_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.5195 - loss: 1.8314 - val_accuracy: 0.4876 - val_loss: 1.9645 - learning_rate: 0.0040\n",
            "Epoch 34/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5386 - loss: 1.7736\n",
            "Epoch 34: val_loss did not improve from 1.96450\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5385 - loss: 1.7737 - val_accuracy: 0.4680 - val_loss: 2.0382 - learning_rate: 0.0040\n",
            "Epoch 35/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5230 - loss: 1.8152\n",
            "Epoch 35: val_loss improved from 1.96450 to 1.94804, saving model to ../output/experiments/trial_36_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.5230 - loss: 1.8152 - val_accuracy: 0.4900 - val_loss: 1.9480 - learning_rate: 0.0040\n",
            "Epoch 36/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5350 - loss: 1.7976\n",
            "Epoch 36: val_loss improved from 1.94804 to 1.89536, saving model to ../output/experiments/trial_36_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5350 - loss: 1.7976 - val_accuracy: 0.5068 - val_loss: 1.8954 - learning_rate: 0.0040\n",
            "Epoch 37/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5431 - loss: 1.7611\n",
            "Epoch 37: val_loss did not improve from 1.89536\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5431 - loss: 1.7613 - val_accuracy: 0.4680 - val_loss: 1.9683 - learning_rate: 0.0040\n",
            "Epoch 38/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5417 - loss: 1.7850\n",
            "Epoch 38: val_loss did not improve from 1.89536\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5416 - loss: 1.7852 - val_accuracy: 0.4876 - val_loss: 1.9489 - learning_rate: 0.0040\n",
            "Epoch 39/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5476 - loss: 1.7855\n",
            "Epoch 39: val_loss did not improve from 1.89536\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.5476 - loss: 1.7855 - val_accuracy: 0.4802 - val_loss: 1.9638 - learning_rate: 0.0040\n",
            "Epoch 40/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5567 - loss: 1.7580\n",
            "Epoch 40: val_loss did not improve from 1.89536\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5565 - loss: 1.7583 - val_accuracy: 0.5044 - val_loss: 1.9033 - learning_rate: 0.0040\n",
            "Epoch 41/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5549 - loss: 1.7526\n",
            "Epoch 41: val_loss did not improve from 1.89536\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.5549 - loss: 1.7528 - val_accuracy: 0.4993 - val_loss: 1.9663 - learning_rate: 0.0040\n",
            "Epoch 42/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5468 - loss: 1.7344\n",
            "Epoch 42: val_loss did not improve from 1.89536\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5468 - loss: 1.7346 - val_accuracy: 0.4839 - val_loss: 1.9266 - learning_rate: 0.0040\n",
            "Epoch 43/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5659 - loss: 1.7180\n",
            "Epoch 43: val_loss improved from 1.89536 to 1.88442, saving model to ../output/experiments/trial_36_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5658 - loss: 1.7182 - val_accuracy: 0.5077 - val_loss: 1.8844 - learning_rate: 0.0040\n",
            "Epoch 44/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5510 - loss: 1.7246\n",
            "Epoch 44: val_loss did not improve from 1.88442\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5510 - loss: 1.7247 - val_accuracy: 0.5063 - val_loss: 1.9383 - learning_rate: 0.0040\n",
            "Epoch 45/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5436 - loss: 1.7802\n",
            "Epoch 45: val_loss did not improve from 1.88442\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.5436 - loss: 1.7802 - val_accuracy: 0.5063 - val_loss: 1.9259 - learning_rate: 0.0040\n",
            "Epoch 46/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5682 - loss: 1.7019\n",
            "Epoch 46: val_loss did not improve from 1.88442\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.5682 - loss: 1.7021 - val_accuracy: 0.5170 - val_loss: 1.9160 - learning_rate: 0.0040\n",
            "Epoch 47/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5727 - loss: 1.6743\n",
            "Epoch 47: val_loss improved from 1.88442 to 1.86854, saving model to ../output/experiments/trial_36_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.5727 - loss: 1.6743 - val_accuracy: 0.5091 - val_loss: 1.8685 - learning_rate: 0.0040\n",
            "Epoch 48/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5840 - loss: 1.6385\n",
            "Epoch 48: val_loss did not improve from 1.86854\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5839 - loss: 1.6387 - val_accuracy: 0.5198 - val_loss: 1.9033 - learning_rate: 0.0040\n",
            "Epoch 49/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5751 - loss: 1.6758\n",
            "Epoch 49: val_loss did not improve from 1.86854\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5751 - loss: 1.6761 - val_accuracy: 0.5170 - val_loss: 1.9243 - learning_rate: 0.0040\n",
            "Epoch 50/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5776 - loss: 1.6894\n",
            "Epoch 50: val_loss did not improve from 1.86854\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.5775 - loss: 1.6896 - val_accuracy: 0.5138 - val_loss: 1.8920 - learning_rate: 0.0040\n",
            "Epoch 51/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5835 - loss: 1.6638\n",
            "Epoch 51: val_loss improved from 1.86854 to 1.84798, saving model to ../output/experiments/trial_36_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5835 - loss: 1.6638 - val_accuracy: 0.5366 - val_loss: 1.8480 - learning_rate: 0.0040\n",
            "Epoch 52/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5818 - loss: 1.6555\n",
            "Epoch 52: val_loss did not improve from 1.84798\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.5818 - loss: 1.6556 - val_accuracy: 0.5138 - val_loss: 1.9575 - learning_rate: 0.0040\n",
            "Epoch 53/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5849 - loss: 1.6988\n",
            "Epoch 53: val_loss did not improve from 1.84798\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.5849 - loss: 1.6989 - val_accuracy: 0.5180 - val_loss: 1.8970 - learning_rate: 0.0040\n",
            "Epoch 54/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5857 - loss: 1.6270\n",
            "Epoch 54: val_loss did not improve from 1.84798\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.5857 - loss: 1.6274 - val_accuracy: 0.5282 - val_loss: 1.8791 - learning_rate: 0.0040\n",
            "Epoch 55/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5930 - loss: 1.6422\n",
            "Epoch 55: val_loss did not improve from 1.84798\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.5929 - loss: 1.6422 - val_accuracy: 0.5021 - val_loss: 1.9001 - learning_rate: 0.0040\n",
            "Epoch 56/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6047 - loss: 1.5989\n",
            "Epoch 56: val_loss did not improve from 1.84798\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.6047 - loss: 1.5990 - val_accuracy: 0.5282 - val_loss: 1.8644 - learning_rate: 0.0040\n",
            "Epoch 57/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6094 - loss: 1.5725\n",
            "Epoch 57: val_loss did not improve from 1.84798\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.6094 - loss: 1.5728 - val_accuracy: 0.5035 - val_loss: 1.9361 - learning_rate: 0.0040\n",
            "Epoch 58/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6144 - loss: 1.5697\n",
            "Epoch 58: val_loss did not improve from 1.84798\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.6142 - loss: 1.5699 - val_accuracy: 0.5236 - val_loss: 1.8523 - learning_rate: 0.0040\n",
            "Epoch 59/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6030 - loss: 1.6185\n",
            "Epoch 59: val_loss did not improve from 1.84798\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.6029 - loss: 1.6186 - val_accuracy: 0.5026 - val_loss: 1.9448 - learning_rate: 0.0040\n",
            "Epoch 60/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6047 - loss: 1.6073\n",
            "Epoch 60: val_loss improved from 1.84798 to 1.83193, saving model to ../output/experiments/trial_36_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.6047 - loss: 1.6073 - val_accuracy: 0.5306 - val_loss: 1.8319 - learning_rate: 0.0040\n",
            "Epoch 61/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6245 - loss: 1.5780\n",
            "Epoch 61: val_loss did not improve from 1.83193\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.6243 - loss: 1.5784 - val_accuracy: 0.5301 - val_loss: 1.8925 - learning_rate: 0.0040\n",
            "Epoch 62/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6079 - loss: 1.5988\n",
            "Epoch 62: val_loss did not improve from 1.83193\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.6079 - loss: 1.5988 - val_accuracy: 0.5175 - val_loss: 1.9130 - learning_rate: 0.0040\n",
            "Epoch 63/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5975 - loss: 1.6062\n",
            "Epoch 63: val_loss did not improve from 1.83193\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.5975 - loss: 1.6063 - val_accuracy: 0.5306 - val_loss: 1.8538 - learning_rate: 0.0040\n",
            "Epoch 64/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6124 - loss: 1.6166\n",
            "Epoch 64: val_loss did not improve from 1.83193\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.6124 - loss: 1.6166 - val_accuracy: 0.5133 - val_loss: 1.9116 - learning_rate: 0.0040\n",
            "Epoch 65/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6067 - loss: 1.5700\n",
            "Epoch 65: val_loss did not improve from 1.83193\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.6067 - loss: 1.5701 - val_accuracy: 0.5287 - val_loss: 1.9102 - learning_rate: 0.0040\n",
            "Epoch 66/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6233 - loss: 1.5399\n",
            "Epoch 66: val_loss did not improve from 1.83193\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.6233 - loss: 1.5399 - val_accuracy: 0.5268 - val_loss: 1.8847 - learning_rate: 0.0040\n",
            "Epoch 67/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6254 - loss: 1.5364\n",
            "Epoch 67: val_loss did not improve from 1.83193\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.6254 - loss: 1.5365 - val_accuracy: 0.5390 - val_loss: 1.9070 - learning_rate: 0.0040\n",
            "Epoch 68/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6136 - loss: 1.5949\n",
            "Epoch 68: val_loss did not improve from 1.83193\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.6136 - loss: 1.5949 - val_accuracy: 0.5422 - val_loss: 1.8574 - learning_rate: 0.0040\n",
            "Epoch 69/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6359 - loss: 1.5218\n",
            "Epoch 69: val_loss improved from 1.83193 to 1.82398, saving model to ../output/experiments/trial_36_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.6359 - loss: 1.5218 - val_accuracy: 0.5497 - val_loss: 1.8240 - learning_rate: 0.0040\n",
            "Epoch 70/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6393 - loss: 1.4808\n",
            "Epoch 70: val_loss did not improve from 1.82398\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.6393 - loss: 1.4809 - val_accuracy: 0.5278 - val_loss: 1.8491 - learning_rate: 0.0040\n",
            "Epoch 71/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6383 - loss: 1.5109\n",
            "Epoch 71: val_loss did not improve from 1.82398\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.6383 - loss: 1.5110 - val_accuracy: 0.5306 - val_loss: 1.8813 - learning_rate: 0.0040\n",
            "Epoch 72/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6390 - loss: 1.5287\n",
            "Epoch 72: val_loss did not improve from 1.82398\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.6389 - loss: 1.5288 - val_accuracy: 0.5483 - val_loss: 1.8636 - learning_rate: 0.0040\n",
            "Epoch 73/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6398 - loss: 1.5146\n",
            "Epoch 73: val_loss improved from 1.82398 to 1.81487, saving model to ../output/experiments/trial_36_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.6398 - loss: 1.5146 - val_accuracy: 0.5539 - val_loss: 1.8149 - learning_rate: 0.0040\n",
            "Epoch 74/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6330 - loss: 1.5124\n",
            "Epoch 74: val_loss did not improve from 1.81487\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.6330 - loss: 1.5126 - val_accuracy: 0.5450 - val_loss: 1.8473 - learning_rate: 0.0040\n",
            "Epoch 75/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6259 - loss: 1.5642\n",
            "Epoch 75: val_loss did not improve from 1.81487\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.6259 - loss: 1.5642 - val_accuracy: 0.5539 - val_loss: 1.8243 - learning_rate: 0.0040\n",
            "Epoch 76/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6450 - loss: 1.4941\n",
            "Epoch 76: val_loss did not improve from 1.81487\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.6450 - loss: 1.4942 - val_accuracy: 0.5469 - val_loss: 1.8502 - learning_rate: 0.0040\n",
            "Epoch 77/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6343 - loss: 1.5215\n",
            "Epoch 77: val_loss did not improve from 1.81487\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.6343 - loss: 1.5215 - val_accuracy: 0.5492 - val_loss: 1.8352 - learning_rate: 0.0040\n",
            "Epoch 78/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6410 - loss: 1.5201\n",
            "Epoch 78: val_loss did not improve from 1.81487\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.6410 - loss: 1.5201 - val_accuracy: 0.5492 - val_loss: 1.8202 - learning_rate: 0.0040\n",
            "Epoch 79/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6468 - loss: 1.4740\n",
            "Epoch 79: val_loss did not improve from 1.81487\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.6468 - loss: 1.4741 - val_accuracy: 0.5614 - val_loss: 1.8443 - learning_rate: 0.0040\n",
            "Epoch 80/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6516 - loss: 1.4686\n",
            "Epoch 80: val_loss improved from 1.81487 to 1.78136, saving model to ../output/experiments/trial_36_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.6515 - loss: 1.4687 - val_accuracy: 0.5665 - val_loss: 1.7814 - learning_rate: 0.0040\n",
            "Epoch 81/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6350 - loss: 1.5140\n",
            "Epoch 81: val_loss did not improve from 1.78136\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.6350 - loss: 1.5140 - val_accuracy: 0.5324 - val_loss: 1.9049 - learning_rate: 0.0040\n",
            "Epoch 82/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6405 - loss: 1.5080\n",
            "Epoch 82: val_loss did not improve from 1.78136\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.6404 - loss: 1.5083 - val_accuracy: 0.5273 - val_loss: 1.9389 - learning_rate: 0.0040\n",
            "Epoch 83/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6445 - loss: 1.5212\n",
            "Epoch 83: val_loss did not improve from 1.78136\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.6444 - loss: 1.5212 - val_accuracy: 0.5618 - val_loss: 1.7978 - learning_rate: 0.0040\n",
            "Epoch 84/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6496 - loss: 1.4770\n",
            "Epoch 84: val_loss did not improve from 1.78136\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.6496 - loss: 1.4771 - val_accuracy: 0.5408 - val_loss: 1.8549 - learning_rate: 0.0040\n",
            "Epoch 85/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6356 - loss: 1.4990\n",
            "Epoch 85: val_loss did not improve from 1.78136\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.6356 - loss: 1.4991 - val_accuracy: 0.5506 - val_loss: 1.8279 - learning_rate: 0.0040\n",
            "Epoch 86/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6528 - loss: 1.4686\n",
            "Epoch 86: val_loss did not improve from 1.78136\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.6527 - loss: 1.4691 - val_accuracy: 0.5548 - val_loss: 1.8261 - learning_rate: 0.0040\n",
            "Epoch 87/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6627 - loss: 1.4636\n",
            "Epoch 87: val_loss did not improve from 1.78136\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.6626 - loss: 1.4638 - val_accuracy: 0.5264 - val_loss: 1.8497 - learning_rate: 0.0040\n",
            "Epoch 88/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6402 - loss: 1.5019\n",
            "Epoch 88: val_loss did not improve from 1.78136\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.6402 - loss: 1.5020 - val_accuracy: 0.5604 - val_loss: 1.7964 - learning_rate: 0.0040\n",
            "Epoch 89/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6649 - loss: 1.4227\n",
            "Epoch 89: val_loss did not improve from 1.78136\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.6649 - loss: 1.4228 - val_accuracy: 0.5600 - val_loss: 1.8276 - learning_rate: 0.0040\n",
            "Epoch 90/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6530 - loss: 1.4505\n",
            "Epoch 90: val_loss did not improve from 1.78136\n",
            "\n",
            "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.00197959179058671.\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.6530 - loss: 1.4505 - val_accuracy: 0.5516 - val_loss: 1.8047 - learning_rate: 0.0040\n",
            "Epoch 91/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6916 - loss: 1.3541\n",
            "Epoch 91: val_loss did not improve from 1.78136\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.6917 - loss: 1.3540 - val_accuracy: 0.5679 - val_loss: 1.7937 - learning_rate: 0.0020\n",
            "Epoch 92/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7059 - loss: 1.2636\n",
            "Epoch 92: val_loss improved from 1.78136 to 1.78014, saving model to ../output/experiments/trial_36_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.7059 - loss: 1.2636 - val_accuracy: 0.5777 - val_loss: 1.7801 - learning_rate: 0.0020\n",
            "Epoch 93/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7305 - loss: 1.1960\n",
            "Epoch 93: val_loss did not improve from 1.78014\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.7305 - loss: 1.1960 - val_accuracy: 0.5754 - val_loss: 1.8208 - learning_rate: 0.0020\n",
            "Epoch 94/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7341 - loss: 1.1806\n",
            "Epoch 94: val_loss did not improve from 1.78014\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.7341 - loss: 1.1806 - val_accuracy: 0.5688 - val_loss: 1.7878 - learning_rate: 0.0020\n",
            "Epoch 95/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7304 - loss: 1.1570\n",
            "Epoch 95: val_loss improved from 1.78014 to 1.75273, saving model to ../output/experiments/trial_36_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.7304 - loss: 1.1571 - val_accuracy: 0.5810 - val_loss: 1.7527 - learning_rate: 0.0020\n",
            "Epoch 96/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7418 - loss: 1.1451\n",
            "Epoch 96: val_loss improved from 1.75273 to 1.73990, saving model to ../output/experiments/trial_36_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.7418 - loss: 1.1451 - val_accuracy: 0.5936 - val_loss: 1.7399 - learning_rate: 0.0020\n",
            "Epoch 97/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7607 - loss: 1.1014\n",
            "Epoch 97: val_loss did not improve from 1.73990\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.7607 - loss: 1.1014 - val_accuracy: 0.5959 - val_loss: 1.7531 - learning_rate: 0.0020\n",
            "Epoch 98/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7569 - loss: 1.0686\n",
            "Epoch 98: val_loss did not improve from 1.73990\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.7569 - loss: 1.0687 - val_accuracy: 0.5950 - val_loss: 1.7402 - learning_rate: 0.0020\n",
            "Epoch 99/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7716 - loss: 1.0345\n",
            "Epoch 99: val_loss improved from 1.73990 to 1.72935, saving model to ../output/experiments/trial_36_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.7716 - loss: 1.0347 - val_accuracy: 0.6001 - val_loss: 1.7293 - learning_rate: 0.0020\n",
            "Epoch 100/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7651 - loss: 1.0553\n",
            "Epoch 100: val_loss improved from 1.72935 to 1.72328, saving model to ../output/experiments/trial_36_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.7651 - loss: 1.0554 - val_accuracy: 0.5945 - val_loss: 1.7233 - learning_rate: 0.0020\n",
            "Restoring model weights from the end of the best epoch: 100.\n",
            "å­¦ç¿’å®Œäº†ï¼å­¦ç¿’æ™‚é–“: 1140.05ç§’\n",
            "æœ€è‰¯æ¤œè¨¼Loss: 1.7233\n",
            "æœ€è‰¯æ¤œè¨¼Accuracy: 0.6001\n",
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ä¸­...\n",
            "ãƒ†ã‚¹ãƒˆLoss: 1.7173\n",
            "ãƒ†ã‚¹ãƒˆAccuracy: 0.6062\n",
            "F1-Score (macro): 0.5730\n",
            "F1-Score (weighted): 0.6048\n",
            "çµæœä¿å­˜ä¸­...\n",
            "å­¦ç¿’å±¥æ­´ä¿å­˜å®Œäº†: ../output/experiments/trial_36_w64_s16_w64_s16/results/training_history_attention.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-08 21:25:13,239] Trial 36 finished with value: 0.7937435944934252 and parameters: {'lstm_units_1': 80, 'lstm_units_2': 64, 'dense_units': 48, 'demographics_dense_units': 32, 'fusion_dense_units': 48, 'dropout_rate': 0.1, 'dense_dropout_rate': 0.2, 'learning_rate': 0.003959183395187926, 'batch_size': 32, 'fusion_type': 'attention'}. Best is trial 34 with value: 0.8021217206997858.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "çµæœä¿å­˜å®Œäº†: ../output/experiments/trial_36_w64_s16_w64_s16/results\n",
            "âœ… Trial 36: CMI=0.7937, Binary F1=0.9583, Fusion=attention\n",
            "\n",
            "ğŸ” Trial 37 - w64_s16\n",
            "Mixed precision enabled for better GPU performance\n",
            "GPUåˆ©ç”¨å¯èƒ½: 1å°\n",
            "ä½¿ç”¨GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
            "LSTM v2å­¦ç¿’ç’°å¢ƒåˆæœŸåŒ–å®Œäº†\n",
            "å®Ÿé¨“å: trial_37_w64_s16\n",
            "ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®š: w64_s16\n",
            "å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: ../output/experiments/trial_37_w64_s16_w64_s16\n",
            "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿: ../output/experiments/lstm_v2_w64_s16/preprocessed\n",
            "GPUåˆ©ç”¨å¯èƒ½: True\n",
            "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...\n",
            "æœ€é©åŒ–ã•ã‚ŒãŸdemographicsç‰¹å¾´é‡ã‚’ä½¿ç”¨ã—ã¾ã™\n",
            "æœ€é©åŒ–ã•ã‚ŒãŸdemographicså½¢çŠ¶: (13393, 18)\n",
            "ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†:\n",
            "  ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿: (13393, 64, 332)\n",
            "  Demographics: (13393, 18)\n",
            "  ãƒ©ãƒ™ãƒ«: (13393,)\n",
            "  ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹ (èåˆæ–¹å¼: attention)...\n",
            "ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ä¸­...\n",
            "ãƒ†ã‚¹ãƒˆã‚µã‚¤ã‚º: 0.2\n",
            "æ¤œè¨¼ã‚µã‚¤ã‚º: 0.2\n",
            "ãƒ‡ãƒ¼ã‚¿åˆ†å‰²å®Œäº†:\n",
            "  è¨“ç·´ - ã‚»ãƒ³ã‚µãƒ¼: (8571, 64, 332), Demographics: (8571, 18), ãƒ©ãƒ™ãƒ«: (8571,)\n",
            "  æ¤œè¨¼ - ã‚»ãƒ³ã‚µãƒ¼: (2143, 64, 332), Demographics: (2143, 18), ãƒ©ãƒ™ãƒ«: (2143,)\n",
            "  ãƒ†ã‚¹ãƒˆ - ã‚»ãƒ³ã‚µãƒ¼: (2679, 64, 332), Demographics: (2679, 18), ãƒ©ãƒ™ãƒ«: (2679,)\n",
            "å…¥åŠ›å½¢çŠ¶:\n",
            "  ã‚»ãƒ³ã‚µãƒ¼: (64, 332)\n",
            "  Demographics: (18,)\n",
            "  ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "GPUä¸Šã§ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆãƒ»å­¦ç¿’ã—ã¾ã™\n",
            "Mixed precision enabled for better GPU performance\n",
            "GPUåˆ©ç”¨å¯èƒ½: 1å°\n",
            "ä½¿ç”¨GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
            "LSTM v2ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†\n",
            "ã‚»ãƒ³ã‚µãƒ¼å…¥åŠ›å½¢çŠ¶: (64, 332)\n",
            "Demographicså…¥åŠ›å½¢çŠ¶: (18,)\n",
            "ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "èåˆæ–¹å¼: attention\n",
            "GPUåˆ©ç”¨å¯èƒ½: True\n",
            "LSTM v2ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ä¸­...\n",
            "ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰å®Œäº†\n",
            "ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 180,338\n",
            "\n",
            "=== ãƒ¢ãƒ‡ãƒ«ã‚µãƒãƒªãƒ¼ ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"lstm_v2_hybrid\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"lstm_v2_hybrid\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ sensor_input        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">332</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">132,160</span> â”‚ sensor_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_1           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> â”‚ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_1      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ lstm_bn_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_input  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">37,120</span> â”‚ lstm_dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">532</span> â”‚ demographics_inpâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_2           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_2      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ lstm_bn_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">812</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dense        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,120</span> â”‚ lstm_dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dropout      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sensor_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_weights   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,392</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attended_sensor     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sensor_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          â”‚                   â”‚            â”‚ attention_weightâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_projeâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,392</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_fusion    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ attended_sensor[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚                   â”‚            â”‚ demographics_proâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dense        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,352</span> â”‚ attention_fusionâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dropout      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ fusion_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">882</span> â”‚ fusion_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ sensor_input        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m332\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m80\u001b[0m)    â”‚    \u001b[38;5;34m132,160\u001b[0m â”‚ sensor_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_1           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m80\u001b[0m)    â”‚        \u001b[38;5;34m320\u001b[0m â”‚ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_1      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m80\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ lstm_bn_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_input  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚     \u001b[38;5;34m37,120\u001b[0m â”‚ lstm_dropout_1[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)        â”‚        \u001b[38;5;34m532\u001b[0m â”‚ demographics_inpâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_2           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m256\u001b[0m â”‚ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_2      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ lstm_bn_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)        â”‚        \u001b[38;5;34m812\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dense        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚      \u001b[38;5;34m3,120\u001b[0m â”‚ lstm_dropout_2[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dropout      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sensor_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_weights   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚      \u001b[38;5;34m1,392\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attended_sensor     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sensor_dropout[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mMultiply\u001b[0m)          â”‚                   â”‚            â”‚ attention_weightâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_projeâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚      \u001b[38;5;34m1,392\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_fusion    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ attended_sensor[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚                   â”‚            â”‚ demographics_proâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dense        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚      \u001b[38;5;34m2,352\u001b[0m â”‚ attention_fusionâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dropout      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ fusion_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (\u001b[38;5;33mDense\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        â”‚        \u001b[38;5;34m882\u001b[0m â”‚ fusion_dropout[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">180,338</span> (704.45 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m180,338\u001b[0m (704.45 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">180,050</span> (703.32 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m180,050\u001b[0m (703.32 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> (1.12 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m288\u001b[0m (1.12 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹...\n",
            "ã‚»ãƒ³ã‚µãƒ¼è¨“ç·´ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (8571, 64, 332)\n",
            "Demographicsè¨“ç·´ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (8571, 18)\n",
            "ã‚»ãƒ³ã‚µãƒ¼æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (2143, 64, 332)\n",
            "Demographicsæ¤œè¨¼ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (2143, 18)\n",
            "è¨“ç·´ãƒ©ãƒ™ãƒ«å½¢çŠ¶: (8571,)\n",
            "æ¤œè¨¼ãƒ©ãƒ™ãƒ«å½¢çŠ¶: (2143,)\n",
            "Epoch 1/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.1288 - loss: 2.8192\n",
            "Epoch 1: val_loss improved from inf to 2.47413, saving model to ../output/experiments/trial_37_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 47ms/step - accuracy: 0.1291 - loss: 2.8184 - val_accuracy: 0.2594 - val_loss: 2.4741 - learning_rate: 0.0037\n",
            "Epoch 2/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.2446 - loss: 2.4649\n",
            "Epoch 2: val_loss improved from 2.47413 to 2.32080, saving model to ../output/experiments/trial_37_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.2447 - loss: 2.4645 - val_accuracy: 0.2902 - val_loss: 2.3208 - learning_rate: 0.0037\n",
            "Epoch 3/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.2921 - loss: 2.3361\n",
            "Epoch 3: val_loss improved from 2.32080 to 2.24155, saving model to ../output/experiments/trial_37_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.2920 - loss: 2.3360 - val_accuracy: 0.3252 - val_loss: 2.2415 - learning_rate: 0.0037\n",
            "Epoch 4/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3120 - loss: 2.2666\n",
            "Epoch 4: val_loss improved from 2.24155 to 2.17758, saving model to ../output/experiments/trial_37_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.3120 - loss: 2.2667 - val_accuracy: 0.3276 - val_loss: 2.1776 - learning_rate: 0.0037\n",
            "Epoch 5/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3149 - loss: 2.2488\n",
            "Epoch 5: val_loss did not improve from 2.17758\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.3149 - loss: 2.2488 - val_accuracy: 0.3318 - val_loss: 2.2574 - learning_rate: 0.0037\n",
            "Epoch 6/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3389 - loss: 2.1875\n",
            "Epoch 6: val_loss improved from 2.17758 to 2.14896, saving model to ../output/experiments/trial_37_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.3389 - loss: 2.1876 - val_accuracy: 0.3276 - val_loss: 2.1490 - learning_rate: 0.0037\n",
            "Epoch 7/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3476 - loss: 2.1423\n",
            "Epoch 7: val_loss did not improve from 2.14896\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.3476 - loss: 2.1426 - val_accuracy: 0.3486 - val_loss: 2.1648 - learning_rate: 0.0037\n",
            "Epoch 8/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3625 - loss: 2.1549\n",
            "Epoch 8: val_loss improved from 2.14896 to 2.13910, saving model to ../output/experiments/trial_37_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.3626 - loss: 2.1549 - val_accuracy: 0.3616 - val_loss: 2.1391 - learning_rate: 0.0037\n",
            "Epoch 9/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.3834 - loss: 2.1260\n",
            "Epoch 9: val_loss improved from 2.13910 to 2.08436, saving model to ../output/experiments/trial_37_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.3834 - loss: 2.1261 - val_accuracy: 0.3714 - val_loss: 2.0844 - learning_rate: 0.0037\n",
            "Epoch 10/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3985 - loss: 2.0792\n",
            "Epoch 10: val_loss did not improve from 2.08436\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.3985 - loss: 2.0792 - val_accuracy: 0.3850 - val_loss: 2.0880 - learning_rate: 0.0037\n",
            "Epoch 11/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.3993 - loss: 2.0573\n",
            "Epoch 11: val_loss did not improve from 2.08436\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.3992 - loss: 2.0574 - val_accuracy: 0.3672 - val_loss: 2.1375 - learning_rate: 0.0037\n",
            "Epoch 12/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4077 - loss: 2.0673\n",
            "Epoch 12: val_loss improved from 2.08436 to 2.02072, saving model to ../output/experiments/trial_37_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4077 - loss: 2.0671 - val_accuracy: 0.4041 - val_loss: 2.0207 - learning_rate: 0.0037\n",
            "Epoch 13/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4169 - loss: 2.0204\n",
            "Epoch 13: val_loss did not improve from 2.02072\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4169 - loss: 2.0204 - val_accuracy: 0.4116 - val_loss: 2.0793 - learning_rate: 0.0037\n",
            "Epoch 14/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.4158 - loss: 2.0433\n",
            "Epoch 14: val_loss did not improve from 2.02072\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.4158 - loss: 2.0432 - val_accuracy: 0.4097 - val_loss: 2.0327 - learning_rate: 0.0037\n",
            "Epoch 15/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4515 - loss: 1.9854\n",
            "Epoch 15: val_loss did not improve from 2.02072\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.4514 - loss: 1.9855 - val_accuracy: 0.4321 - val_loss: 2.0254 - learning_rate: 0.0037\n",
            "Epoch 16/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4472 - loss: 1.9792\n",
            "Epoch 16: val_loss improved from 2.02072 to 2.01231, saving model to ../output/experiments/trial_37_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.4472 - loss: 1.9792 - val_accuracy: 0.4200 - val_loss: 2.0123 - learning_rate: 0.0037\n",
            "Epoch 17/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4532 - loss: 1.9456\n",
            "Epoch 17: val_loss improved from 2.01231 to 2.01182, saving model to ../output/experiments/trial_37_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.4532 - loss: 1.9457 - val_accuracy: 0.4321 - val_loss: 2.0118 - learning_rate: 0.0037\n",
            "Epoch 18/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4743 - loss: 1.9245\n",
            "Epoch 18: val_loss improved from 2.01182 to 1.98068, saving model to ../output/experiments/trial_37_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.4743 - loss: 1.9245 - val_accuracy: 0.4433 - val_loss: 1.9807 - learning_rate: 0.0037\n",
            "Epoch 19/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.4803 - loss: 1.8996\n",
            "Epoch 19: val_loss did not improve from 1.98068\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.4802 - loss: 1.8999 - val_accuracy: 0.4386 - val_loss: 2.0011 - learning_rate: 0.0037\n",
            "Epoch 20/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.4763 - loss: 1.9001\n",
            "Epoch 20: val_loss did not improve from 1.98068\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.4763 - loss: 1.9004 - val_accuracy: 0.4489 - val_loss: 1.9852 - learning_rate: 0.0037\n",
            "Epoch 21/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4769 - loss: 1.9041\n",
            "Epoch 21: val_loss did not improve from 1.98068\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.4769 - loss: 1.9042 - val_accuracy: 0.4489 - val_loss: 1.9905 - learning_rate: 0.0037\n",
            "Epoch 22/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.4876 - loss: 1.8526\n",
            "Epoch 22: val_loss improved from 1.98068 to 1.94167, saving model to ../output/experiments/trial_37_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.4876 - loss: 1.8527 - val_accuracy: 0.4657 - val_loss: 1.9417 - learning_rate: 0.0037\n",
            "Epoch 23/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4961 - loss: 1.8555\n",
            "Epoch 23: val_loss did not improve from 1.94167\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.4961 - loss: 1.8555 - val_accuracy: 0.4531 - val_loss: 1.9844 - learning_rate: 0.0037\n",
            "Epoch 24/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5072 - loss: 1.7936\n",
            "Epoch 24: val_loss improved from 1.94167 to 1.92229, saving model to ../output/experiments/trial_37_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.5071 - loss: 1.7939 - val_accuracy: 0.4629 - val_loss: 1.9223 - learning_rate: 0.0037\n",
            "Epoch 25/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5111 - loss: 1.7981\n",
            "Epoch 25: val_loss did not improve from 1.92229\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.5111 - loss: 1.7981 - val_accuracy: 0.4774 - val_loss: 1.9336 - learning_rate: 0.0037\n",
            "Epoch 26/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5206 - loss: 1.7753\n",
            "Epoch 26: val_loss did not improve from 1.92229\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.5206 - loss: 1.7754 - val_accuracy: 0.4587 - val_loss: 1.9277 - learning_rate: 0.0037\n",
            "Epoch 27/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5066 - loss: 1.7834\n",
            "Epoch 27: val_loss did not improve from 1.92229\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5067 - loss: 1.7834 - val_accuracy: 0.4750 - val_loss: 1.9321 - learning_rate: 0.0037\n",
            "Epoch 28/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5173 - loss: 1.7541\n",
            "Epoch 28: val_loss improved from 1.92229 to 1.91398, saving model to ../output/experiments/trial_37_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5173 - loss: 1.7543 - val_accuracy: 0.4671 - val_loss: 1.9140 - learning_rate: 0.0037\n",
            "Epoch 29/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5198 - loss: 1.7722\n",
            "Epoch 29: val_loss improved from 1.91398 to 1.87002, saving model to ../output/experiments/trial_37_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.5197 - loss: 1.7723 - val_accuracy: 0.4844 - val_loss: 1.8700 - learning_rate: 0.0037\n",
            "Epoch 30/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5309 - loss: 1.7466\n",
            "Epoch 30: val_loss did not improve from 1.87002\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.5308 - loss: 1.7469 - val_accuracy: 0.4764 - val_loss: 1.9373 - learning_rate: 0.0037\n",
            "Epoch 31/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5332 - loss: 1.7583\n",
            "Epoch 31: val_loss improved from 1.87002 to 1.86575, saving model to ../output/experiments/trial_37_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.5332 - loss: 1.7582 - val_accuracy: 0.4942 - val_loss: 1.8657 - learning_rate: 0.0037\n",
            "Epoch 32/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5330 - loss: 1.7129\n",
            "Epoch 32: val_loss did not improve from 1.86575\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.5329 - loss: 1.7131 - val_accuracy: 0.4900 - val_loss: 1.9316 - learning_rate: 0.0037\n",
            "Epoch 33/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5247 - loss: 1.7612\n",
            "Epoch 33: val_loss did not improve from 1.86575\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.5247 - loss: 1.7613 - val_accuracy: 0.4722 - val_loss: 1.9241 - learning_rate: 0.0037\n",
            "Epoch 34/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5321 - loss: 1.7500\n",
            "Epoch 34: val_loss did not improve from 1.86575\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.5320 - loss: 1.7501 - val_accuracy: 0.5072 - val_loss: 1.8828 - learning_rate: 0.0037\n",
            "Epoch 35/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5482 - loss: 1.7060\n",
            "Epoch 35: val_loss did not improve from 1.86575\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5482 - loss: 1.7063 - val_accuracy: 0.5049 - val_loss: 1.8817 - learning_rate: 0.0037\n",
            "Epoch 36/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5306 - loss: 1.7277\n",
            "Epoch 36: val_loss improved from 1.86575 to 1.85145, saving model to ../output/experiments/trial_37_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.5306 - loss: 1.7277 - val_accuracy: 0.5012 - val_loss: 1.8515 - learning_rate: 0.0037\n",
            "Epoch 37/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5403 - loss: 1.7142\n",
            "Epoch 37: val_loss improved from 1.85145 to 1.83631, saving model to ../output/experiments/trial_37_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.5403 - loss: 1.7142 - val_accuracy: 0.5096 - val_loss: 1.8363 - learning_rate: 0.0037\n",
            "Epoch 38/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5543 - loss: 1.6545\n",
            "Epoch 38: val_loss did not improve from 1.83631\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.5542 - loss: 1.6546 - val_accuracy: 0.5096 - val_loss: 1.8444 - learning_rate: 0.0037\n",
            "Epoch 39/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5490 - loss: 1.6553\n",
            "Epoch 39: val_loss did not improve from 1.83631\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.5490 - loss: 1.6553 - val_accuracy: 0.5166 - val_loss: 1.8736 - learning_rate: 0.0037\n",
            "Epoch 40/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5655 - loss: 1.6623\n",
            "Epoch 40: val_loss improved from 1.83631 to 1.80862, saving model to ../output/experiments/trial_37_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.5655 - loss: 1.6623 - val_accuracy: 0.5259 - val_loss: 1.8086 - learning_rate: 0.0037\n",
            "Epoch 41/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5652 - loss: 1.6475\n",
            "Epoch 41: val_loss did not improve from 1.80862\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.5651 - loss: 1.6478 - val_accuracy: 0.5100 - val_loss: 1.8110 - learning_rate: 0.0037\n",
            "Epoch 42/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5659 - loss: 1.6552\n",
            "Epoch 42: val_loss did not improve from 1.80862\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.5659 - loss: 1.6551 - val_accuracy: 0.5329 - val_loss: 1.8097 - learning_rate: 0.0037\n",
            "Epoch 43/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5602 - loss: 1.6357\n",
            "Epoch 43: val_loss did not improve from 1.80862\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5602 - loss: 1.6357 - val_accuracy: 0.5133 - val_loss: 1.8464 - learning_rate: 0.0037\n",
            "Epoch 44/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5747 - loss: 1.6310\n",
            "Epoch 44: val_loss did not improve from 1.80862\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5746 - loss: 1.6313 - val_accuracy: 0.5184 - val_loss: 1.8260 - learning_rate: 0.0037\n",
            "Epoch 45/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5819 - loss: 1.6013\n",
            "Epoch 45: val_loss did not improve from 1.80862\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.5819 - loss: 1.6014 - val_accuracy: 0.5086 - val_loss: 1.8399 - learning_rate: 0.0037\n",
            "Epoch 46/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5953 - loss: 1.5846\n",
            "Epoch 46: val_loss improved from 1.80862 to 1.77412, saving model to ../output/experiments/trial_37_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.5952 - loss: 1.5848 - val_accuracy: 0.5320 - val_loss: 1.7741 - learning_rate: 0.0037\n",
            "Epoch 47/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5866 - loss: 1.5722\n",
            "Epoch 47: val_loss did not improve from 1.77412\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.5866 - loss: 1.5724 - val_accuracy: 0.5114 - val_loss: 1.8340 - learning_rate: 0.0037\n",
            "Epoch 48/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5780 - loss: 1.5865\n",
            "Epoch 48: val_loss did not improve from 1.77412\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.5780 - loss: 1.5866 - val_accuracy: 0.5110 - val_loss: 1.8432 - learning_rate: 0.0037\n",
            "Epoch 49/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5804 - loss: 1.6086\n",
            "Epoch 49: val_loss did not improve from 1.77412\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5804 - loss: 1.6087 - val_accuracy: 0.5194 - val_loss: 1.8301 - learning_rate: 0.0037\n",
            "Epoch 50/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5860 - loss: 1.5673\n",
            "Epoch 50: val_loss did not improve from 1.77412\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.5860 - loss: 1.5675 - val_accuracy: 0.5152 - val_loss: 1.8580 - learning_rate: 0.0037\n",
            "Epoch 51/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5944 - loss: 1.5772\n",
            "Epoch 51: val_loss did not improve from 1.77412\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5943 - loss: 1.5774 - val_accuracy: 0.5320 - val_loss: 1.8054 - learning_rate: 0.0037\n",
            "Epoch 52/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5885 - loss: 1.5715\n",
            "Epoch 52: val_loss did not improve from 1.77412\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5884 - loss: 1.5716 - val_accuracy: 0.5245 - val_loss: 1.8250 - learning_rate: 0.0037\n",
            "Epoch 53/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5920 - loss: 1.5980\n",
            "Epoch 53: val_loss did not improve from 1.77412\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5920 - loss: 1.5981 - val_accuracy: 0.5418 - val_loss: 1.8712 - learning_rate: 0.0037\n",
            "Epoch 54/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5877 - loss: 1.6393\n",
            "Epoch 54: val_loss did not improve from 1.77412\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.5876 - loss: 1.6393 - val_accuracy: 0.5432 - val_loss: 1.8264 - learning_rate: 0.0037\n",
            "Epoch 55/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5981 - loss: 1.5686\n",
            "Epoch 55: val_loss did not improve from 1.77412\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.5980 - loss: 1.5688 - val_accuracy: 0.5208 - val_loss: 1.8678 - learning_rate: 0.0037\n",
            "Epoch 56/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5972 - loss: 1.5597\n",
            "Epoch 56: val_loss did not improve from 1.77412\n",
            "\n",
            "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0018470047507435083.\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.5972 - loss: 1.5597 - val_accuracy: 0.5273 - val_loss: 1.8619 - learning_rate: 0.0037\n",
            "Epoch 57/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6335 - loss: 1.4812\n",
            "Epoch 57: val_loss improved from 1.77412 to 1.75362, saving model to ../output/experiments/trial_37_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.6335 - loss: 1.4811 - val_accuracy: 0.5660 - val_loss: 1.7536 - learning_rate: 0.0018\n",
            "Epoch 58/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6585 - loss: 1.3484\n",
            "Epoch 58: val_loss improved from 1.75362 to 1.73281, saving model to ../output/experiments/trial_37_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.6585 - loss: 1.3485 - val_accuracy: 0.5651 - val_loss: 1.7328 - learning_rate: 0.0018\n",
            "Epoch 59/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6664 - loss: 1.3185\n",
            "Epoch 59: val_loss did not improve from 1.73281\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.6664 - loss: 1.3186 - val_accuracy: 0.5628 - val_loss: 1.7510 - learning_rate: 0.0018\n",
            "Epoch 60/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6766 - loss: 1.2955\n",
            "Epoch 60: val_loss did not improve from 1.73281\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.6766 - loss: 1.2955 - val_accuracy: 0.5684 - val_loss: 1.7477 - learning_rate: 0.0018\n",
            "Epoch 61/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6859 - loss: 1.2359\n",
            "Epoch 61: val_loss improved from 1.73281 to 1.72800, saving model to ../output/experiments/trial_37_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.6859 - loss: 1.2361 - val_accuracy: 0.5693 - val_loss: 1.7280 - learning_rate: 0.0018\n",
            "Epoch 62/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6802 - loss: 1.2485\n",
            "Epoch 62: val_loss improved from 1.72800 to 1.68667, saving model to ../output/experiments/trial_37_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.6802 - loss: 1.2485 - val_accuracy: 0.5772 - val_loss: 1.6867 - learning_rate: 0.0018\n",
            "Epoch 63/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6827 - loss: 1.2306\n",
            "Epoch 63: val_loss did not improve from 1.68667\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.6828 - loss: 1.2307 - val_accuracy: 0.5684 - val_loss: 1.7399 - learning_rate: 0.0018\n",
            "Epoch 64/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6880 - loss: 1.2344\n",
            "Epoch 64: val_loss improved from 1.68667 to 1.65049, saving model to ../output/experiments/trial_37_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.6880 - loss: 1.2344 - val_accuracy: 0.5852 - val_loss: 1.6505 - learning_rate: 0.0018\n",
            "Epoch 65/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6995 - loss: 1.1912\n",
            "Epoch 65: val_loss did not improve from 1.65049\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.6995 - loss: 1.1913 - val_accuracy: 0.5842 - val_loss: 1.6658 - learning_rate: 0.0018\n",
            "Epoch 66/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7044 - loss: 1.1919\n",
            "Epoch 66: val_loss did not improve from 1.65049\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.7043 - loss: 1.1919 - val_accuracy: 0.5819 - val_loss: 1.7099 - learning_rate: 0.0018\n",
            "Epoch 67/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7166 - loss: 1.1569\n",
            "Epoch 67: val_loss did not improve from 1.65049\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.7165 - loss: 1.1569 - val_accuracy: 0.5730 - val_loss: 1.7205 - learning_rate: 0.0018\n",
            "Epoch 68/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7066 - loss: 1.1800\n",
            "Epoch 68: val_loss did not improve from 1.65049\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.7066 - loss: 1.1801 - val_accuracy: 0.5852 - val_loss: 1.6768 - learning_rate: 0.0018\n",
            "Epoch 69/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7233 - loss: 1.1428\n",
            "Epoch 69: val_loss did not improve from 1.65049\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.7233 - loss: 1.1428 - val_accuracy: 0.5828 - val_loss: 1.7087 - learning_rate: 0.0018\n",
            "Epoch 70/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7267 - loss: 1.1218\n",
            "Epoch 70: val_loss did not improve from 1.65049\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.7267 - loss: 1.1219 - val_accuracy: 0.5870 - val_loss: 1.7119 - learning_rate: 0.0018\n",
            "Epoch 71/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7214 - loss: 1.1058\n",
            "Epoch 71: val_loss did not improve from 1.65049\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.7214 - loss: 1.1059 - val_accuracy: 0.5842 - val_loss: 1.6919 - learning_rate: 0.0018\n",
            "Epoch 72/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7277 - loss: 1.1208\n",
            "Epoch 72: val_loss did not improve from 1.65049\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.7277 - loss: 1.1208 - val_accuracy: 0.5978 - val_loss: 1.6539 - learning_rate: 0.0018\n",
            "Epoch 73/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7403 - loss: 1.0901\n",
            "Epoch 73: val_loss did not improve from 1.65049\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.7403 - loss: 1.0902 - val_accuracy: 0.5950 - val_loss: 1.6863 - learning_rate: 0.0018\n",
            "Epoch 74/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7362 - loss: 1.0806\n",
            "Epoch 74: val_loss did not improve from 1.65049\n",
            "\n",
            "Epoch 74: ReduceLROnPlateau reducing learning rate to 0.0009235023753717542.\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.7362 - loss: 1.0808 - val_accuracy: 0.5861 - val_loss: 1.6929 - learning_rate: 0.0018\n",
            "Epoch 75/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7468 - loss: 1.0557\n",
            "Epoch 75: val_loss did not improve from 1.65049\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.7469 - loss: 1.0555 - val_accuracy: 0.6118 - val_loss: 1.6689 - learning_rate: 9.2350e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7796 - loss: 0.9702\n",
            "Epoch 76: val_loss did not improve from 1.65049\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.7796 - loss: 0.9702 - val_accuracy: 0.6174 - val_loss: 1.6612 - learning_rate: 9.2350e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7864 - loss: 0.9399\n",
            "Epoch 77: val_loss did not improve from 1.65049\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.7864 - loss: 0.9399 - val_accuracy: 0.6183 - val_loss: 1.6746 - learning_rate: 9.2350e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7941 - loss: 0.9297\n",
            "Epoch 78: val_loss did not improve from 1.65049\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.7941 - loss: 0.9297 - val_accuracy: 0.6225 - val_loss: 1.7410 - learning_rate: 9.2350e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7964 - loss: 0.9107\n",
            "Epoch 79: val_loss did not improve from 1.65049\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.7964 - loss: 0.9108 - val_accuracy: 0.6090 - val_loss: 1.7491 - learning_rate: 9.2350e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7986 - loss: 0.9213\n",
            "Epoch 80: val_loss did not improve from 1.65049\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.7986 - loss: 0.9214 - val_accuracy: 0.6192 - val_loss: 1.6766 - learning_rate: 9.2350e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8006 - loss: 0.8889\n",
            "Epoch 81: val_loss did not improve from 1.65049\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.8006 - loss: 0.8889 - val_accuracy: 0.6099 - val_loss: 1.7731 - learning_rate: 9.2350e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8047 - loss: 0.8763\n",
            "Epoch 82: val_loss did not improve from 1.65049\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.8047 - loss: 0.8764 - val_accuracy: 0.6276 - val_loss: 1.7636 - learning_rate: 9.2350e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8076 - loss: 0.8725\n",
            "Epoch 83: val_loss did not improve from 1.65049\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.8076 - loss: 0.8726 - val_accuracy: 0.6393 - val_loss: 1.7428 - learning_rate: 9.2350e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8165 - loss: 0.8487\n",
            "Epoch 84: val_loss did not improve from 1.65049\n",
            "\n",
            "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0004617511876858771.\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 47ms/step - accuracy: 0.8165 - loss: 0.8487 - val_accuracy: 0.6276 - val_loss: 1.7635 - learning_rate: 9.2350e-04\n",
            "Epoch 84: early stopping\n",
            "Restoring model weights from the end of the best epoch: 64.\n",
            "å­¦ç¿’å®Œäº†ï¼å­¦ç¿’æ™‚é–“: 990.37ç§’\n",
            "æœ€è‰¯æ¤œè¨¼Loss: 1.6505\n",
            "æœ€è‰¯æ¤œè¨¼Accuracy: 0.6393\n",
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ä¸­...\n",
            "ãƒ†ã‚¹ãƒˆLoss: 1.7060\n",
            "ãƒ†ã‚¹ãƒˆAccuracy: 0.5782\n",
            "F1-Score (macro): 0.5395\n",
            "F1-Score (weighted): 0.5777\n",
            "çµæœä¿å­˜ä¸­...\n",
            "å­¦ç¿’å±¥æ­´ä¿å­˜å®Œäº†: ../output/experiments/trial_37_w64_s16_w64_s16/results/training_history_attention.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-08 21:41:59,837] Trial 37 finished with value: 0.7730779388529894 and parameters: {'lstm_units_1': 80, 'lstm_units_2': 64, 'dense_units': 48, 'demographics_dense_units': 28, 'fusion_dense_units': 48, 'dropout_rate': 0.1, 'dense_dropout_rate': 0.30000000000000004, 'learning_rate': 0.003694009568602056, 'batch_size': 32, 'fusion_type': 'attention'}. Best is trial 34 with value: 0.8021217206997858.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "çµæœä¿å­˜å®Œäº†: ../output/experiments/trial_37_w64_s16_w64_s16/results\n",
            "âœ… Trial 37: CMI=0.7731, Binary F1=0.9495, Fusion=attention\n",
            "\n",
            "ğŸ” Trial 38 - w64_s16\n",
            "Mixed precision enabled for better GPU performance\n",
            "GPUåˆ©ç”¨å¯èƒ½: 1å°\n",
            "ä½¿ç”¨GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
            "LSTM v2å­¦ç¿’ç’°å¢ƒåˆæœŸåŒ–å®Œäº†\n",
            "å®Ÿé¨“å: trial_38_w64_s16\n",
            "ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®š: w64_s16\n",
            "å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: ../output/experiments/trial_38_w64_s16_w64_s16\n",
            "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿: ../output/experiments/lstm_v2_w64_s16/preprocessed\n",
            "GPUåˆ©ç”¨å¯èƒ½: True\n",
            "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...\n",
            "æœ€é©åŒ–ã•ã‚ŒãŸdemographicsç‰¹å¾´é‡ã‚’ä½¿ç”¨ã—ã¾ã™\n",
            "æœ€é©åŒ–ã•ã‚ŒãŸdemographicså½¢çŠ¶: (13393, 18)\n",
            "ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†:\n",
            "  ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿: (13393, 64, 332)\n",
            "  Demographics: (13393, 18)\n",
            "  ãƒ©ãƒ™ãƒ«: (13393,)\n",
            "  ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹ (èåˆæ–¹å¼: attention)...\n",
            "ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ä¸­...\n",
            "ãƒ†ã‚¹ãƒˆã‚µã‚¤ã‚º: 0.2\n",
            "æ¤œè¨¼ã‚µã‚¤ã‚º: 0.2\n",
            "ãƒ‡ãƒ¼ã‚¿åˆ†å‰²å®Œäº†:\n",
            "  è¨“ç·´ - ã‚»ãƒ³ã‚µãƒ¼: (8571, 64, 332), Demographics: (8571, 18), ãƒ©ãƒ™ãƒ«: (8571,)\n",
            "  æ¤œè¨¼ - ã‚»ãƒ³ã‚µãƒ¼: (2143, 64, 332), Demographics: (2143, 18), ãƒ©ãƒ™ãƒ«: (2143,)\n",
            "  ãƒ†ã‚¹ãƒˆ - ã‚»ãƒ³ã‚µãƒ¼: (2679, 64, 332), Demographics: (2679, 18), ãƒ©ãƒ™ãƒ«: (2679,)\n",
            "å…¥åŠ›å½¢çŠ¶:\n",
            "  ã‚»ãƒ³ã‚µãƒ¼: (64, 332)\n",
            "  Demographics: (18,)\n",
            "  ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "GPUä¸Šã§ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆãƒ»å­¦ç¿’ã—ã¾ã™\n",
            "Mixed precision enabled for better GPU performance\n",
            "GPUåˆ©ç”¨å¯èƒ½: 1å°\n",
            "ä½¿ç”¨GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
            "LSTM v2ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†\n",
            "ã‚»ãƒ³ã‚µãƒ¼å…¥åŠ›å½¢çŠ¶: (64, 332)\n",
            "Demographicså…¥åŠ›å½¢çŠ¶: (18,)\n",
            "ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "èåˆæ–¹å¼: attention\n",
            "GPUåˆ©ç”¨å¯èƒ½: True\n",
            "LSTM v2ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ä¸­...\n",
            "ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰å®Œäº†\n",
            "ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 216,402\n",
            "\n",
            "=== ãƒ¢ãƒ‡ãƒ«ã‚µãƒãƒªãƒ¼ ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"lstm_v2_hybrid\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"lstm_v2_hybrid\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ sensor_input        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">332</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">164,736</span> â”‚ sensor_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_1           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> â”‚ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_1      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ lstm_bn_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_input  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">41,216</span> â”‚ lstm_dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">456</span> â”‚ demographics_inpâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_2           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_2      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ lstm_bn_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dense        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,120</span> â”‚ lstm_dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dropout      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sensor_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_weights   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,200</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attended_sensor     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sensor_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          â”‚                   â”‚            â”‚ attention_weightâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_projeâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,200</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_fusion    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ attended_sensor[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚                   â”‚            â”‚ demographics_proâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dense        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,352</span> â”‚ attention_fusionâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dropout      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ fusion_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">882</span> â”‚ fusion_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ sensor_input        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m332\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m96\u001b[0m)    â”‚    \u001b[38;5;34m164,736\u001b[0m â”‚ sensor_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_1           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m96\u001b[0m)    â”‚        \u001b[38;5;34m384\u001b[0m â”‚ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_1      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m96\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ lstm_bn_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_input  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚     \u001b[38;5;34m41,216\u001b[0m â”‚ lstm_dropout_1[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)        â”‚        \u001b[38;5;34m456\u001b[0m â”‚ demographics_inpâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_2           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m256\u001b[0m â”‚ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_2      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ lstm_bn_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)        â”‚        \u001b[38;5;34m600\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dense        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚      \u001b[38;5;34m3,120\u001b[0m â”‚ lstm_dropout_2[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dropout      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sensor_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_weights   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚      \u001b[38;5;34m1,200\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attended_sensor     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sensor_dropout[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mMultiply\u001b[0m)          â”‚                   â”‚            â”‚ attention_weightâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_projeâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚      \u001b[38;5;34m1,200\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_fusion    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ attended_sensor[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚                   â”‚            â”‚ demographics_proâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dense        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚      \u001b[38;5;34m2,352\u001b[0m â”‚ attention_fusionâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dropout      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ fusion_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (\u001b[38;5;33mDense\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        â”‚        \u001b[38;5;34m882\u001b[0m â”‚ fusion_dropout[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">216,402</span> (845.32 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m216,402\u001b[0m (845.32 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">216,082</span> (844.07 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m216,082\u001b[0m (844.07 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> (1.25 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m320\u001b[0m (1.25 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹...\n",
            "ã‚»ãƒ³ã‚µãƒ¼è¨“ç·´ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (8571, 64, 332)\n",
            "Demographicsè¨“ç·´ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (8571, 18)\n",
            "ã‚»ãƒ³ã‚µãƒ¼æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (2143, 64, 332)\n",
            "Demographicsæ¤œè¨¼ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (2143, 18)\n",
            "è¨“ç·´ãƒ©ãƒ™ãƒ«å½¢çŠ¶: (8571,)\n",
            "æ¤œè¨¼ãƒ©ãƒ™ãƒ«å½¢çŠ¶: (2143,)\n",
            "Epoch 1/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.1311 - loss: 2.7875\n",
            "Epoch 1: val_loss improved from inf to 2.43195, saving model to ../output/experiments/trial_38_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 39ms/step - accuracy: 0.1312 - loss: 2.7870 - val_accuracy: 0.2221 - val_loss: 2.4319 - learning_rate: 0.0027\n",
            "Epoch 2/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2530 - loss: 2.3774\n",
            "Epoch 2: val_loss improved from 2.43195 to 2.21971, saving model to ../output/experiments/trial_38_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.2530 - loss: 2.3772 - val_accuracy: 0.2991 - val_loss: 2.2197 - learning_rate: 0.0027\n",
            "Epoch 3/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2977 - loss: 2.1926\n",
            "Epoch 3: val_loss improved from 2.21971 to 2.11699, saving model to ../output/experiments/trial_38_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.2977 - loss: 2.1926 - val_accuracy: 0.3229 - val_loss: 2.1170 - learning_rate: 0.0027\n",
            "Epoch 4/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3317 - loss: 2.1190\n",
            "Epoch 4: val_loss did not improve from 2.11699\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - accuracy: 0.3317 - loss: 2.1190 - val_accuracy: 0.3355 - val_loss: 2.1250 - learning_rate: 0.0027\n",
            "Epoch 5/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.3510 - loss: 2.0833\n",
            "Epoch 5: val_loss did not improve from 2.11699\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.3510 - loss: 2.0833 - val_accuracy: 0.3355 - val_loss: 2.1179 - learning_rate: 0.0027\n",
            "Epoch 6/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3623 - loss: 2.0531\n",
            "Epoch 6: val_loss improved from 2.11699 to 2.02113, saving model to ../output/experiments/trial_38_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.3623 - loss: 2.0531 - val_accuracy: 0.3612 - val_loss: 2.0211 - learning_rate: 0.0027\n",
            "Epoch 7/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.3772 - loss: 2.0000\n",
            "Epoch 7: val_loss improved from 2.02113 to 1.99873, saving model to ../output/experiments/trial_38_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - accuracy: 0.3772 - loss: 2.0001 - val_accuracy: 0.3892 - val_loss: 1.9987 - learning_rate: 0.0027\n",
            "Epoch 8/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4042 - loss: 1.9531\n",
            "Epoch 8: val_loss improved from 1.99873 to 1.98819, saving model to ../output/experiments/trial_38_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.4042 - loss: 1.9532 - val_accuracy: 0.4004 - val_loss: 1.9882 - learning_rate: 0.0027\n",
            "Epoch 9/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4084 - loss: 1.9142\n",
            "Epoch 9: val_loss improved from 1.98819 to 1.94196, saving model to ../output/experiments/trial_38_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.4084 - loss: 1.9143 - val_accuracy: 0.4130 - val_loss: 1.9420 - learning_rate: 0.0027\n",
            "Epoch 10/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4260 - loss: 1.8724\n",
            "Epoch 10: val_loss improved from 1.94196 to 1.93590, saving model to ../output/experiments/trial_38_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.4259 - loss: 1.8724 - val_accuracy: 0.4046 - val_loss: 1.9359 - learning_rate: 0.0027\n",
            "Epoch 11/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4331 - loss: 1.8586\n",
            "Epoch 11: val_loss improved from 1.93590 to 1.91823, saving model to ../output/experiments/trial_38_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.4331 - loss: 1.8586 - val_accuracy: 0.4176 - val_loss: 1.9182 - learning_rate: 0.0027\n",
            "Epoch 12/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.4532 - loss: 1.8107\n",
            "Epoch 12: val_loss did not improve from 1.91823\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.4532 - loss: 1.8108 - val_accuracy: 0.4260 - val_loss: 1.9530 - learning_rate: 0.0027\n",
            "Epoch 13/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.4628 - loss: 1.8051\n",
            "Epoch 13: val_loss did not improve from 1.91823\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.4628 - loss: 1.8051 - val_accuracy: 0.4148 - val_loss: 2.0318 - learning_rate: 0.0027\n",
            "Epoch 14/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4555 - loss: 1.8177\n",
            "Epoch 14: val_loss improved from 1.91823 to 1.88198, saving model to ../output/experiments/trial_38_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.4556 - loss: 1.8176 - val_accuracy: 0.4484 - val_loss: 1.8820 - learning_rate: 0.0027\n",
            "Epoch 15/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4837 - loss: 1.7757\n",
            "Epoch 15: val_loss did not improve from 1.88198\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.4837 - loss: 1.7758 - val_accuracy: 0.4489 - val_loss: 1.9254 - learning_rate: 0.0027\n",
            "Epoch 16/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.4897 - loss: 1.7644\n",
            "Epoch 16: val_loss did not improve from 1.88198\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.4896 - loss: 1.7645 - val_accuracy: 0.4386 - val_loss: 1.9256 - learning_rate: 0.0027\n",
            "Epoch 17/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4935 - loss: 1.7562\n",
            "Epoch 17: val_loss improved from 1.88198 to 1.87409, saving model to ../output/experiments/trial_38_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.4934 - loss: 1.7563 - val_accuracy: 0.4559 - val_loss: 1.8741 - learning_rate: 0.0027\n",
            "Epoch 18/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5001 - loss: 1.6946\n",
            "Epoch 18: val_loss did not improve from 1.87409\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.5000 - loss: 1.6948 - val_accuracy: 0.4596 - val_loss: 1.9081 - learning_rate: 0.0027\n",
            "Epoch 19/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5091 - loss: 1.6734\n",
            "Epoch 19: val_loss improved from 1.87409 to 1.84272, saving model to ../output/experiments/trial_38_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.5090 - loss: 1.6735 - val_accuracy: 0.4587 - val_loss: 1.8427 - learning_rate: 0.0027\n",
            "Epoch 20/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5186 - loss: 1.6733\n",
            "Epoch 20: val_loss did not improve from 1.84272\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.5186 - loss: 1.6733 - val_accuracy: 0.4680 - val_loss: 1.8749 - learning_rate: 0.0027\n",
            "Epoch 21/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5247 - loss: 1.6376\n",
            "Epoch 21: val_loss improved from 1.84272 to 1.83858, saving model to ../output/experiments/trial_38_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.5247 - loss: 1.6377 - val_accuracy: 0.4914 - val_loss: 1.8386 - learning_rate: 0.0027\n",
            "Epoch 22/100\n",
            "\u001b[1m266/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5379 - loss: 1.6361\n",
            "Epoch 22: val_loss did not improve from 1.83858\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.5379 - loss: 1.6361 - val_accuracy: 0.4792 - val_loss: 1.8723 - learning_rate: 0.0027\n",
            "Epoch 23/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5424 - loss: 1.6347\n",
            "Epoch 23: val_loss improved from 1.83858 to 1.83773, saving model to ../output/experiments/trial_38_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.5423 - loss: 1.6348 - val_accuracy: 0.4648 - val_loss: 1.8377 - learning_rate: 0.0027\n",
            "Epoch 24/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5517 - loss: 1.6055\n",
            "Epoch 24: val_loss improved from 1.83773 to 1.79378, saving model to ../output/experiments/trial_38_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.5518 - loss: 1.6054 - val_accuracy: 0.5077 - val_loss: 1.7938 - learning_rate: 0.0027\n",
            "Epoch 25/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5654 - loss: 1.5663\n",
            "Epoch 25: val_loss did not improve from 1.79378\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.5653 - loss: 1.5666 - val_accuracy: 0.5012 - val_loss: 1.8057 - learning_rate: 0.0027\n",
            "Epoch 26/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5636 - loss: 1.5588\n",
            "Epoch 26: val_loss did not improve from 1.79378\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.5636 - loss: 1.5590 - val_accuracy: 0.4615 - val_loss: 1.9067 - learning_rate: 0.0027\n",
            "Epoch 27/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5477 - loss: 1.6432\n",
            "Epoch 27: val_loss improved from 1.79378 to 1.78663, saving model to ../output/experiments/trial_38_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.5477 - loss: 1.6432 - val_accuracy: 0.5110 - val_loss: 1.7866 - learning_rate: 0.0027\n",
            "Epoch 28/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5702 - loss: 1.5523\n",
            "Epoch 28: val_loss did not improve from 1.78663\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.5702 - loss: 1.5523 - val_accuracy: 0.5161 - val_loss: 1.8087 - learning_rate: 0.0027\n",
            "Epoch 29/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5848 - loss: 1.5579\n",
            "Epoch 29: val_loss did not improve from 1.78663\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.5848 - loss: 1.5579 - val_accuracy: 0.4988 - val_loss: 1.8249 - learning_rate: 0.0027\n",
            "Epoch 30/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5906 - loss: 1.5176\n",
            "Epoch 30: val_loss improved from 1.78663 to 1.78536, saving model to ../output/experiments/trial_38_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.5906 - loss: 1.5180 - val_accuracy: 0.4984 - val_loss: 1.7854 - learning_rate: 0.0027\n",
            "Epoch 31/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5880 - loss: 1.5163\n",
            "Epoch 31: val_loss did not improve from 1.78536\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.5879 - loss: 1.5165 - val_accuracy: 0.4998 - val_loss: 1.8121 - learning_rate: 0.0027\n",
            "Epoch 32/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5790 - loss: 1.5475\n",
            "Epoch 32: val_loss did not improve from 1.78536\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.5790 - loss: 1.5479 - val_accuracy: 0.4918 - val_loss: 1.8483 - learning_rate: 0.0027\n",
            "Epoch 33/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5905 - loss: 1.5345\n",
            "Epoch 33: val_loss did not improve from 1.78536\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.5905 - loss: 1.5346 - val_accuracy: 0.5226 - val_loss: 1.8342 - learning_rate: 0.0027\n",
            "Epoch 34/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5960 - loss: 1.5194\n",
            "Epoch 34: val_loss improved from 1.78536 to 1.75419, saving model to ../output/experiments/trial_38_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.5960 - loss: 1.5194 - val_accuracy: 0.5268 - val_loss: 1.7542 - learning_rate: 0.0027\n",
            "Epoch 35/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6075 - loss: 1.4648\n",
            "Epoch 35: val_loss did not improve from 1.75419\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.6075 - loss: 1.4650 - val_accuracy: 0.5385 - val_loss: 1.8184 - learning_rate: 0.0027\n",
            "Epoch 36/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6124 - loss: 1.4747\n",
            "Epoch 36: val_loss did not improve from 1.75419\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.6123 - loss: 1.4748 - val_accuracy: 0.5380 - val_loss: 1.8010 - learning_rate: 0.0027\n",
            "Epoch 37/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6196 - loss: 1.4761\n",
            "Epoch 37: val_loss did not improve from 1.75419\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.6196 - loss: 1.4763 - val_accuracy: 0.5320 - val_loss: 1.8248 - learning_rate: 0.0027\n",
            "Epoch 38/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6057 - loss: 1.4952\n",
            "Epoch 38: val_loss did not improve from 1.75419\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.6057 - loss: 1.4953 - val_accuracy: 0.5119 - val_loss: 1.8381 - learning_rate: 0.0027\n",
            "Epoch 39/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6252 - loss: 1.4714\n",
            "Epoch 39: val_loss did not improve from 1.75419\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.6252 - loss: 1.4714 - val_accuracy: 0.5189 - val_loss: 1.8374 - learning_rate: 0.0027\n",
            "Epoch 40/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6267 - loss: 1.4538\n",
            "Epoch 40: val_loss did not improve from 1.75419\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.6267 - loss: 1.4539 - val_accuracy: 0.5254 - val_loss: 1.8044 - learning_rate: 0.0027\n",
            "Epoch 41/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6309 - loss: 1.4545\n",
            "Epoch 41: val_loss did not improve from 1.75419\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.6309 - loss: 1.4547 - val_accuracy: 0.5469 - val_loss: 1.8008 - learning_rate: 0.0027\n",
            "Epoch 42/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6415 - loss: 1.4334\n",
            "Epoch 42: val_loss improved from 1.75419 to 1.74636, saving model to ../output/experiments/trial_38_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.6415 - loss: 1.4333 - val_accuracy: 0.5558 - val_loss: 1.7464 - learning_rate: 0.0027\n",
            "Epoch 43/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6510 - loss: 1.3910\n",
            "Epoch 43: val_loss did not improve from 1.74636\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.6509 - loss: 1.3912 - val_accuracy: 0.5581 - val_loss: 1.7820 - learning_rate: 0.0027\n",
            "Epoch 44/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6580 - loss: 1.3994\n",
            "Epoch 44: val_loss did not improve from 1.74636\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.6579 - loss: 1.3996 - val_accuracy: 0.5450 - val_loss: 1.7767 - learning_rate: 0.0027\n",
            "Epoch 45/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6549 - loss: 1.3995\n",
            "Epoch 45: val_loss did not improve from 1.74636\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.6548 - loss: 1.3996 - val_accuracy: 0.5492 - val_loss: 1.8261 - learning_rate: 0.0027\n",
            "Epoch 46/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6565 - loss: 1.4283\n",
            "Epoch 46: val_loss did not improve from 1.74636\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.6564 - loss: 1.4285 - val_accuracy: 0.5422 - val_loss: 1.7697 - learning_rate: 0.0027\n",
            "Epoch 47/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6478 - loss: 1.4059\n",
            "Epoch 47: val_loss did not improve from 1.74636\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.6478 - loss: 1.4060 - val_accuracy: 0.5432 - val_loss: 1.8093 - learning_rate: 0.0027\n",
            "Epoch 48/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6472 - loss: 1.4051\n",
            "Epoch 48: val_loss did not improve from 1.74636\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.6473 - loss: 1.4051 - val_accuracy: 0.5026 - val_loss: 2.1477 - learning_rate: 0.0027\n",
            "Epoch 49/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6288 - loss: 1.4717\n",
            "Epoch 49: val_loss did not improve from 1.74636\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.6288 - loss: 1.4716 - val_accuracy: 0.5600 - val_loss: 1.7650 - learning_rate: 0.0027\n",
            "Epoch 50/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6882 - loss: 1.3347\n",
            "Epoch 50: val_loss did not improve from 1.74636\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.6881 - loss: 1.3350 - val_accuracy: 0.5576 - val_loss: 1.7745 - learning_rate: 0.0027\n",
            "Epoch 51/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6774 - loss: 1.3582\n",
            "Epoch 51: val_loss did not improve from 1.74636\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.6774 - loss: 1.3585 - val_accuracy: 0.5427 - val_loss: 1.7960 - learning_rate: 0.0027\n",
            "Epoch 52/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6450 - loss: 1.4540\n",
            "Epoch 52: val_loss did not improve from 1.74636\n",
            "\n",
            "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0013271671487018466.\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - accuracy: 0.6450 - loss: 1.4540 - val_accuracy: 0.5637 - val_loss: 1.7550 - learning_rate: 0.0027\n",
            "Epoch 53/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7093 - loss: 1.2909\n",
            "Epoch 53: val_loss improved from 1.74636 to 1.70613, saving model to ../output/experiments/trial_38_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.7093 - loss: 1.2907 - val_accuracy: 0.5884 - val_loss: 1.7061 - learning_rate: 0.0013\n",
            "Epoch 54/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7266 - loss: 1.2138\n",
            "Epoch 54: val_loss did not improve from 1.70613\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.7266 - loss: 1.2137 - val_accuracy: 0.5987 - val_loss: 1.7130 - learning_rate: 0.0013\n",
            "Epoch 55/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7320 - loss: 1.1779\n",
            "Epoch 55: val_loss improved from 1.70613 to 1.68002, saving model to ../output/experiments/trial_38_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.7320 - loss: 1.1779 - val_accuracy: 0.5931 - val_loss: 1.6800 - learning_rate: 0.0013\n",
            "Epoch 56/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7525 - loss: 1.1267\n",
            "Epoch 56: val_loss did not improve from 1.68002\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.7524 - loss: 1.1268 - val_accuracy: 0.6029 - val_loss: 1.7326 - learning_rate: 0.0013\n",
            "Epoch 57/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7688 - loss: 1.0940\n",
            "Epoch 57: val_loss did not improve from 1.68002\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - accuracy: 0.7688 - loss: 1.0940 - val_accuracy: 0.6048 - val_loss: 1.8059 - learning_rate: 0.0013\n",
            "Epoch 58/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7860 - loss: 1.0304\n",
            "Epoch 58: val_loss did not improve from 1.68002\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.7860 - loss: 1.0304 - val_accuracy: 0.6178 - val_loss: 1.7387 - learning_rate: 0.0013\n",
            "Epoch 59/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7891 - loss: 1.0253\n",
            "Epoch 59: val_loss did not improve from 1.68002\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.7890 - loss: 1.0254 - val_accuracy: 0.6127 - val_loss: 1.8092 - learning_rate: 0.0013\n",
            "Epoch 60/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7867 - loss: 1.0330\n",
            "Epoch 60: val_loss did not improve from 1.68002\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.7867 - loss: 1.0330 - val_accuracy: 0.6090 - val_loss: 1.7968 - learning_rate: 0.0013\n",
            "Epoch 61/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7887 - loss: 1.0253\n",
            "Epoch 61: val_loss did not improve from 1.68002\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - accuracy: 0.7887 - loss: 1.0253 - val_accuracy: 0.6160 - val_loss: 1.7705 - learning_rate: 0.0013\n",
            "Epoch 62/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7992 - loss: 0.9676\n",
            "Epoch 62: val_loss did not improve from 1.68002\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.7992 - loss: 0.9676 - val_accuracy: 0.6127 - val_loss: 1.7831 - learning_rate: 0.0013\n",
            "Epoch 63/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8067 - loss: 0.9506\n",
            "Epoch 63: val_loss did not improve from 1.68002\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.8066 - loss: 0.9509 - val_accuracy: 0.5968 - val_loss: 1.8044 - learning_rate: 0.0013\n",
            "Epoch 64/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8091 - loss: 0.9646\n",
            "Epoch 64: val_loss did not improve from 1.68002\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - accuracy: 0.8091 - loss: 0.9647 - val_accuracy: 0.5838 - val_loss: 1.9355 - learning_rate: 0.0013\n",
            "Epoch 65/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8026 - loss: 0.9704\n",
            "Epoch 65: val_loss did not improve from 1.68002\n",
            "\n",
            "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.0006635835743509233.\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.8025 - loss: 0.9704 - val_accuracy: 0.6169 - val_loss: 1.8072 - learning_rate: 0.0013\n",
            "Epoch 66/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8178 - loss: 0.9177\n",
            "Epoch 66: val_loss did not improve from 1.68002\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - accuracy: 0.8178 - loss: 0.9176 - val_accuracy: 0.6197 - val_loss: 1.8011 - learning_rate: 6.6358e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8471 - loss: 0.8380\n",
            "Epoch 67: val_loss did not improve from 1.68002\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.8471 - loss: 0.8381 - val_accuracy: 0.6360 - val_loss: 1.8253 - learning_rate: 6.6358e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8573 - loss: 0.8150\n",
            "Epoch 68: val_loss did not improve from 1.68002\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.8573 - loss: 0.8151 - val_accuracy: 0.6384 - val_loss: 1.8423 - learning_rate: 6.6358e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8455 - loss: 0.8194\n",
            "Epoch 69: val_loss did not improve from 1.68002\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.8455 - loss: 0.8193 - val_accuracy: 0.6435 - val_loss: 1.8455 - learning_rate: 6.6358e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8614 - loss: 0.7843\n",
            "Epoch 70: val_loss did not improve from 1.68002\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.8614 - loss: 0.7843 - val_accuracy: 0.6346 - val_loss: 1.9172 - learning_rate: 6.6358e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8693 - loss: 0.7658\n",
            "Epoch 71: val_loss did not improve from 1.68002\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.8693 - loss: 0.7659 - val_accuracy: 0.6393 - val_loss: 1.9391 - learning_rate: 6.6358e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8615 - loss: 0.7975\n",
            "Epoch 72: val_loss did not improve from 1.68002\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.8615 - loss: 0.7974 - val_accuracy: 0.6426 - val_loss: 1.9391 - learning_rate: 6.6358e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8765 - loss: 0.7458\n",
            "Epoch 73: val_loss did not improve from 1.68002\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.8765 - loss: 0.7458 - val_accuracy: 0.6514 - val_loss: 1.9383 - learning_rate: 6.6358e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8777 - loss: 0.7370\n",
            "Epoch 74: val_loss did not improve from 1.68002\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.8777 - loss: 0.7371 - val_accuracy: 0.6486 - val_loss: 1.9159 - learning_rate: 6.6358e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8810 - loss: 0.7270\n",
            "Epoch 75: val_loss did not improve from 1.68002\n",
            "\n",
            "Epoch 75: ReduceLROnPlateau reducing learning rate to 0.00033179178717546165.\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.8810 - loss: 0.7270 - val_accuracy: 0.6477 - val_loss: 1.9691 - learning_rate: 6.6358e-04\n",
            "Epoch 75: early stopping\n",
            "Restoring model weights from the end of the best epoch: 55.\n",
            "å­¦ç¿’å®Œäº†ï¼å­¦ç¿’æ™‚é–“: 729.11ç§’\n",
            "æœ€è‰¯æ¤œè¨¼Loss: 1.6800\n",
            "æœ€è‰¯æ¤œè¨¼Accuracy: 0.6514\n",
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ä¸­...\n",
            "ãƒ†ã‚¹ãƒˆLoss: 1.7687\n",
            "ãƒ†ã‚¹ãƒˆAccuracy: 0.5853\n",
            "F1-Score (macro): 0.5369\n",
            "F1-Score (weighted): 0.5754\n",
            "çµæœä¿å­˜ä¸­...\n",
            "å­¦ç¿’å±¥æ­´ä¿å­˜å®Œäº†: ../output/experiments/trial_38_w64_s16_w64_s16/results/training_history_attention.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-08 21:54:27,254] Trial 38 finished with value: 0.7822053579762716 and parameters: {'lstm_units_1': 96, 'lstm_units_2': 64, 'dense_units': 48, 'demographics_dense_units': 24, 'fusion_dense_units': 48, 'dropout_rate': 0.1, 'dense_dropout_rate': 0.2, 'learning_rate': 0.0026543342098933158, 'batch_size': 32, 'fusion_type': 'attention'}. Best is trial 34 with value: 0.8021217206997858.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "çµæœä¿å­˜å®Œäº†: ../output/experiments/trial_38_w64_s16_w64_s16/results\n",
            "âœ… Trial 38: CMI=0.7822, Binary F1=0.9486, Fusion=attention\n",
            "\n",
            "ğŸ” Trial 39 - w64_s16\n",
            "Mixed precision enabled for better GPU performance\n",
            "GPUåˆ©ç”¨å¯èƒ½: 1å°\n",
            "ä½¿ç”¨GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
            "LSTM v2å­¦ç¿’ç’°å¢ƒåˆæœŸåŒ–å®Œäº†\n",
            "å®Ÿé¨“å: trial_39_w64_s16\n",
            "ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®š: w64_s16\n",
            "å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: ../output/experiments/trial_39_w64_s16_w64_s16\n",
            "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿: ../output/experiments/lstm_v2_w64_s16/preprocessed\n",
            "GPUåˆ©ç”¨å¯èƒ½: True\n",
            "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...\n",
            "æœ€é©åŒ–ã•ã‚ŒãŸdemographicsç‰¹å¾´é‡ã‚’ä½¿ç”¨ã—ã¾ã™\n",
            "æœ€é©åŒ–ã•ã‚ŒãŸdemographicså½¢çŠ¶: (13393, 18)\n",
            "ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†:\n",
            "  ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿: (13393, 64, 332)\n",
            "  Demographics: (13393, 18)\n",
            "  ãƒ©ãƒ™ãƒ«: (13393,)\n",
            "  ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹ (èåˆæ–¹å¼: attention)...\n",
            "ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ä¸­...\n",
            "ãƒ†ã‚¹ãƒˆã‚µã‚¤ã‚º: 0.2\n",
            "æ¤œè¨¼ã‚µã‚¤ã‚º: 0.2\n",
            "ãƒ‡ãƒ¼ã‚¿åˆ†å‰²å®Œäº†:\n",
            "  è¨“ç·´ - ã‚»ãƒ³ã‚µãƒ¼: (8571, 64, 332), Demographics: (8571, 18), ãƒ©ãƒ™ãƒ«: (8571,)\n",
            "  æ¤œè¨¼ - ã‚»ãƒ³ã‚µãƒ¼: (2143, 64, 332), Demographics: (2143, 18), ãƒ©ãƒ™ãƒ«: (2143,)\n",
            "  ãƒ†ã‚¹ãƒˆ - ã‚»ãƒ³ã‚µãƒ¼: (2679, 64, 332), Demographics: (2679, 18), ãƒ©ãƒ™ãƒ«: (2679,)\n",
            "å…¥åŠ›å½¢çŠ¶:\n",
            "  ã‚»ãƒ³ã‚µãƒ¼: (64, 332)\n",
            "  Demographics: (18,)\n",
            "  ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "GPUä¸Šã§ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆãƒ»å­¦ç¿’ã—ã¾ã™\n",
            "Mixed precision enabled for better GPU performance\n",
            "GPUåˆ©ç”¨å¯èƒ½: 1å°\n",
            "ä½¿ç”¨GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
            "LSTM v2ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†\n",
            "ã‚»ãƒ³ã‚µãƒ¼å…¥åŠ›å½¢çŠ¶: (64, 332)\n",
            "Demographicså…¥åŠ›å½¢çŠ¶: (18,)\n",
            "ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "èåˆæ–¹å¼: attention\n",
            "GPUåˆ©ç”¨å¯èƒ½: True\n",
            "LSTM v2ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ä¸­...\n",
            "ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰å®Œäº†\n",
            "ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 164,130\n",
            "\n",
            "=== ãƒ¢ãƒ‡ãƒ«ã‚µãƒãƒªãƒ¼ ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"lstm_v2_hybrid\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"lstm_v2_hybrid\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ sensor_input        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">332</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">132,160</span> â”‚ sensor_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_1           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> â”‚ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_1      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ lstm_bn_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_input  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,768</span> â”‚ lstm_dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">456</span> â”‚ demographics_inpâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_2           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> â”‚ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_2      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ lstm_bn_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dense        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> â”‚ lstm_dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dropout      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sensor_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_weights   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attended_sensor     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sensor_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          â”‚                   â”‚            â”‚ attention_weightâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_projeâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_fusion    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ attended_sensor[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚                   â”‚            â”‚ demographics_proâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dense        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,584</span> â”‚ attention_fusionâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dropout      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ fusion_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">882</span> â”‚ fusion_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ sensor_input        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m332\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m80\u001b[0m)    â”‚    \u001b[38;5;34m132,160\u001b[0m â”‚ sensor_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_1           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m80\u001b[0m)    â”‚        \u001b[38;5;34m320\u001b[0m â”‚ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_1      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m80\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ lstm_bn_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_input  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚     \u001b[38;5;34m24,768\u001b[0m â”‚ lstm_dropout_1[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)        â”‚        \u001b[38;5;34m456\u001b[0m â”‚ demographics_inpâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_2           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚        \u001b[38;5;34m192\u001b[0m â”‚ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_2      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ lstm_bn_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)        â”‚        \u001b[38;5;34m600\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dense        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚      \u001b[38;5;34m1,568\u001b[0m â”‚ lstm_dropout_2[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dropout      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sensor_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_weights   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚        \u001b[38;5;34m800\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attended_sensor     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sensor_dropout[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mMultiply\u001b[0m)          â”‚                   â”‚            â”‚ attention_weightâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_projeâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚        \u001b[38;5;34m800\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_fusion    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ attended_sensor[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚                   â”‚            â”‚ demographics_proâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dense        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚      \u001b[38;5;34m1,584\u001b[0m â”‚ attention_fusionâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dropout      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ fusion_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (\u001b[38;5;33mDense\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        â”‚        \u001b[38;5;34m882\u001b[0m â”‚ fusion_dropout[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">164,130</span> (641.13 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m164,130\u001b[0m (641.13 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">163,874</span> (640.13 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m163,874\u001b[0m (640.13 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹...\n",
            "ã‚»ãƒ³ã‚µãƒ¼è¨“ç·´ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (8571, 64, 332)\n",
            "Demographicsè¨“ç·´ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (8571, 18)\n",
            "ã‚»ãƒ³ã‚µãƒ¼æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (2143, 64, 332)\n",
            "Demographicsæ¤œè¨¼ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (2143, 18)\n",
            "è¨“ç·´ãƒ©ãƒ™ãƒ«å½¢çŠ¶: (8571,)\n",
            "æ¤œè¨¼ãƒ©ãƒ™ãƒ«å½¢çŠ¶: (2143,)\n",
            "Epoch 1/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.1088 - loss: 2.8724\n",
            "Epoch 1: val_loss improved from inf to 2.65866, saving model to ../output/experiments/trial_39_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.1093 - loss: 2.8711 - val_accuracy: 0.1918 - val_loss: 2.6587 - learning_rate: 0.0027\n",
            "Epoch 2/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.1954 - loss: 2.5626\n",
            "Epoch 2: val_loss improved from 2.65866 to 2.37711, saving model to ../output/experiments/trial_39_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.1955 - loss: 2.5621 - val_accuracy: 0.2329 - val_loss: 2.3771 - learning_rate: 0.0027\n",
            "Epoch 3/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.2582 - loss: 2.3136\n",
            "Epoch 3: val_loss improved from 2.37711 to 2.15874, saving model to ../output/experiments/trial_39_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.2582 - loss: 2.3134 - val_accuracy: 0.2954 - val_loss: 2.1587 - learning_rate: 0.0027\n",
            "Epoch 4/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3001 - loss: 2.1555\n",
            "Epoch 4: val_loss improved from 2.15874 to 2.07479, saving model to ../output/experiments/trial_39_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - accuracy: 0.3001 - loss: 2.1556 - val_accuracy: 0.3005 - val_loss: 2.0748 - learning_rate: 0.0027\n",
            "Epoch 5/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3247 - loss: 2.0759\n",
            "Epoch 5: val_loss improved from 2.07479 to 2.07363, saving model to ../output/experiments/trial_39_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - accuracy: 0.3246 - loss: 2.0759 - val_accuracy: 0.3201 - val_loss: 2.0736 - learning_rate: 0.0027\n",
            "Epoch 6/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3371 - loss: 2.0308\n",
            "Epoch 6: val_loss improved from 2.07363 to 2.00935, saving model to ../output/experiments/trial_39_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - accuracy: 0.3370 - loss: 2.0310 - val_accuracy: 0.3374 - val_loss: 2.0094 - learning_rate: 0.0027\n",
            "Epoch 7/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3570 - loss: 1.9479\n",
            "Epoch 7: val_loss improved from 2.00935 to 1.97817, saving model to ../output/experiments/trial_39_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.3570 - loss: 1.9480 - val_accuracy: 0.3495 - val_loss: 1.9782 - learning_rate: 0.0027\n",
            "Epoch 8/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3608 - loss: 1.9291\n",
            "Epoch 8: val_loss improved from 1.97817 to 1.95761, saving model to ../output/experiments/trial_39_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.3607 - loss: 1.9294 - val_accuracy: 0.3518 - val_loss: 1.9576 - learning_rate: 0.0027\n",
            "Epoch 9/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3820 - loss: 1.8688\n",
            "Epoch 9: val_loss did not improve from 1.95761\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.3819 - loss: 1.8693 - val_accuracy: 0.3640 - val_loss: 1.9867 - learning_rate: 0.0027\n",
            "Epoch 10/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3982 - loss: 1.8739\n",
            "Epoch 10: val_loss improved from 1.95761 to 1.89288, saving model to ../output/experiments/trial_39_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.3981 - loss: 1.8739 - val_accuracy: 0.3840 - val_loss: 1.8929 - learning_rate: 0.0027\n",
            "Epoch 11/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3898 - loss: 1.8668\n",
            "Epoch 11: val_loss improved from 1.89288 to 1.86970, saving model to ../output/experiments/trial_39_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.3899 - loss: 1.8666 - val_accuracy: 0.3836 - val_loss: 1.8697 - learning_rate: 0.0027\n",
            "Epoch 12/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4123 - loss: 1.7533\n",
            "Epoch 12: val_loss improved from 1.86970 to 1.85994, saving model to ../output/experiments/trial_39_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.4122 - loss: 1.7536 - val_accuracy: 0.3966 - val_loss: 1.8599 - learning_rate: 0.0027\n",
            "Epoch 13/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4103 - loss: 1.8053\n",
            "Epoch 13: val_loss did not improve from 1.85994\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.4103 - loss: 1.8054 - val_accuracy: 0.3934 - val_loss: 1.8712 - learning_rate: 0.0027\n",
            "Epoch 14/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4283 - loss: 1.7260\n",
            "Epoch 14: val_loss did not improve from 1.85994\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - accuracy: 0.4283 - loss: 1.7266 - val_accuracy: 0.3756 - val_loss: 2.0020 - learning_rate: 0.0027\n",
            "Epoch 15/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4417 - loss: 1.7391\n",
            "Epoch 15: val_loss improved from 1.85994 to 1.85927, saving model to ../output/experiments/trial_39_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.4417 - loss: 1.7390 - val_accuracy: 0.4050 - val_loss: 1.8593 - learning_rate: 0.0027\n",
            "Epoch 16/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4443 - loss: 1.6963\n",
            "Epoch 16: val_loss improved from 1.85927 to 1.79788, saving model to ../output/experiments/trial_39_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.4442 - loss: 1.6965 - val_accuracy: 0.4316 - val_loss: 1.7979 - learning_rate: 0.0027\n",
            "Epoch 17/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.4474 - loss: 1.6706\n",
            "Epoch 17: val_loss did not improve from 1.79788\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.4473 - loss: 1.6710 - val_accuracy: 0.4265 - val_loss: 1.8887 - learning_rate: 0.0027\n",
            "Epoch 18/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4539 - loss: 1.6967\n",
            "Epoch 18: val_loss did not improve from 1.79788\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.4540 - loss: 1.6968 - val_accuracy: 0.4391 - val_loss: 1.8343 - learning_rate: 0.0027\n",
            "Epoch 19/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4737 - loss: 1.6443\n",
            "Epoch 19: val_loss improved from 1.79788 to 1.77816, saving model to ../output/experiments/trial_39_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.4736 - loss: 1.6445 - val_accuracy: 0.4503 - val_loss: 1.7782 - learning_rate: 0.0027\n",
            "Epoch 20/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4712 - loss: 1.6294\n",
            "Epoch 20: val_loss did not improve from 1.77816\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.4712 - loss: 1.6296 - val_accuracy: 0.4260 - val_loss: 1.8402 - learning_rate: 0.0027\n",
            "Epoch 21/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4607 - loss: 1.6312\n",
            "Epoch 21: val_loss did not improve from 1.77816\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - accuracy: 0.4608 - loss: 1.6312 - val_accuracy: 0.4396 - val_loss: 1.8823 - learning_rate: 0.0027\n",
            "Epoch 22/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4689 - loss: 1.6185\n",
            "Epoch 22: val_loss did not improve from 1.77816\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - accuracy: 0.4689 - loss: 1.6187 - val_accuracy: 0.4326 - val_loss: 1.8526 - learning_rate: 0.0027\n",
            "Epoch 23/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4860 - loss: 1.6144\n",
            "Epoch 23: val_loss did not improve from 1.77816\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.4860 - loss: 1.6143 - val_accuracy: 0.4573 - val_loss: 1.8056 - learning_rate: 0.0027\n",
            "Epoch 24/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4956 - loss: 1.5832\n",
            "Epoch 24: val_loss improved from 1.77816 to 1.77268, saving model to ../output/experiments/trial_39_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.4956 - loss: 1.5832 - val_accuracy: 0.4531 - val_loss: 1.7727 - learning_rate: 0.0027\n",
            "Epoch 25/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4916 - loss: 1.5615\n",
            "Epoch 25: val_loss did not improve from 1.77268\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.4917 - loss: 1.5614 - val_accuracy: 0.4657 - val_loss: 1.7944 - learning_rate: 0.0027\n",
            "Epoch 26/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5007 - loss: 1.5434\n",
            "Epoch 26: val_loss improved from 1.77268 to 1.72708, saving model to ../output/experiments/trial_39_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.5007 - loss: 1.5436 - val_accuracy: 0.4610 - val_loss: 1.7271 - learning_rate: 0.0027\n",
            "Epoch 27/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5204 - loss: 1.5020\n",
            "Epoch 27: val_loss did not improve from 1.72708\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - accuracy: 0.5202 - loss: 1.5027 - val_accuracy: 0.4414 - val_loss: 1.7984 - learning_rate: 0.0027\n",
            "Epoch 28/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5107 - loss: 1.5760\n",
            "Epoch 28: val_loss did not improve from 1.72708\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - accuracy: 0.5106 - loss: 1.5760 - val_accuracy: 0.4671 - val_loss: 1.7644 - learning_rate: 0.0027\n",
            "Epoch 29/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5195 - loss: 1.4938\n",
            "Epoch 29: val_loss did not improve from 1.72708\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.5196 - loss: 1.4938 - val_accuracy: 0.4648 - val_loss: 1.7728 - learning_rate: 0.0027\n",
            "Epoch 30/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5283 - loss: 1.5060\n",
            "Epoch 30: val_loss did not improve from 1.72708\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - accuracy: 0.5281 - loss: 1.5065 - val_accuracy: 0.4536 - val_loss: 1.8135 - learning_rate: 0.0027\n",
            "Epoch 31/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5252 - loss: 1.5120\n",
            "Epoch 31: val_loss did not improve from 1.72708\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.5252 - loss: 1.5122 - val_accuracy: 0.4620 - val_loss: 1.7594 - learning_rate: 0.0027\n",
            "Epoch 32/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5450 - loss: 1.4737\n",
            "Epoch 32: val_loss improved from 1.72708 to 1.71997, saving model to ../output/experiments/trial_39_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.5449 - loss: 1.4737 - val_accuracy: 0.4596 - val_loss: 1.7200 - learning_rate: 0.0027\n",
            "Epoch 33/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5400 - loss: 1.4763\n",
            "Epoch 33: val_loss did not improve from 1.71997\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.5399 - loss: 1.4764 - val_accuracy: 0.4657 - val_loss: 1.7651 - learning_rate: 0.0027\n",
            "Epoch 34/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5345 - loss: 1.4686\n",
            "Epoch 34: val_loss did not improve from 1.71997\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - accuracy: 0.5345 - loss: 1.4686 - val_accuracy: 0.4676 - val_loss: 1.8007 - learning_rate: 0.0027\n",
            "Epoch 35/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5535 - loss: 1.4244\n",
            "Epoch 35: val_loss did not improve from 1.71997\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.5533 - loss: 1.4247 - val_accuracy: 0.4844 - val_loss: 1.7849 - learning_rate: 0.0027\n",
            "Epoch 36/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5539 - loss: 1.4323\n",
            "Epoch 36: val_loss did not improve from 1.71997\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - accuracy: 0.5538 - loss: 1.4325 - val_accuracy: 0.4844 - val_loss: 1.7884 - learning_rate: 0.0027\n",
            "Epoch 37/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5610 - loss: 1.4277\n",
            "Epoch 37: val_loss did not improve from 1.71997\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.5610 - loss: 1.4277 - val_accuracy: 0.4909 - val_loss: 1.7698 - learning_rate: 0.0027\n",
            "Epoch 38/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5594 - loss: 1.3677\n",
            "Epoch 38: val_loss did not improve from 1.71997\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - accuracy: 0.5594 - loss: 1.3680 - val_accuracy: 0.4979 - val_loss: 1.7764 - learning_rate: 0.0027\n",
            "Epoch 39/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5616 - loss: 1.4299\n",
            "Epoch 39: val_loss did not improve from 1.71997\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.5616 - loss: 1.4299 - val_accuracy: 0.5030 - val_loss: 1.8049 - learning_rate: 0.0027\n",
            "Epoch 40/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5615 - loss: 1.4162\n",
            "Epoch 40: val_loss did not improve from 1.71997\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - accuracy: 0.5613 - loss: 1.4167 - val_accuracy: 0.4746 - val_loss: 1.8916 - learning_rate: 0.0027\n",
            "Epoch 41/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5381 - loss: 1.5080\n",
            "Epoch 41: val_loss did not improve from 1.71997\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - accuracy: 0.5383 - loss: 1.5076 - val_accuracy: 0.4965 - val_loss: 1.7999 - learning_rate: 0.0027\n",
            "Epoch 42/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5605 - loss: 1.4355\n",
            "Epoch 42: val_loss improved from 1.71997 to 1.70115, saving model to ../output/experiments/trial_39_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.5604 - loss: 1.4357 - val_accuracy: 0.5212 - val_loss: 1.7011 - learning_rate: 0.0027\n",
            "Epoch 43/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5721 - loss: 1.4121\n",
            "Epoch 43: val_loss did not improve from 1.70115\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.5720 - loss: 1.4124 - val_accuracy: 0.4998 - val_loss: 1.8115 - learning_rate: 0.0027\n",
            "Epoch 44/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5721 - loss: 1.3649\n",
            "Epoch 44: val_loss did not improve from 1.70115\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.5722 - loss: 1.3648 - val_accuracy: 0.5063 - val_loss: 1.8127 - learning_rate: 0.0027\n",
            "Epoch 45/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5824 - loss: 1.3537\n",
            "Epoch 45: val_loss did not improve from 1.70115\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 41ms/step - accuracy: 0.5824 - loss: 1.3539 - val_accuracy: 0.5021 - val_loss: 1.8347 - learning_rate: 0.0027\n",
            "Epoch 46/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5889 - loss: 1.3303\n",
            "Epoch 46: val_loss did not improve from 1.70115\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.5888 - loss: 1.3306 - val_accuracy: 0.5124 - val_loss: 1.8309 - learning_rate: 0.0027\n",
            "Epoch 47/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5801 - loss: 1.3908\n",
            "Epoch 47: val_loss did not improve from 1.70115\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.5802 - loss: 1.3908 - val_accuracy: 0.4769 - val_loss: 1.8581 - learning_rate: 0.0027\n",
            "Epoch 48/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5654 - loss: 1.4740\n",
            "Epoch 48: val_loss did not improve from 1.70115\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - accuracy: 0.5655 - loss: 1.4739 - val_accuracy: 0.5217 - val_loss: 1.7554 - learning_rate: 0.0027\n",
            "Epoch 49/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5973 - loss: 1.3483\n",
            "Epoch 49: val_loss did not improve from 1.70115\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - accuracy: 0.5972 - loss: 1.3488 - val_accuracy: 0.5026 - val_loss: 1.7854 - learning_rate: 0.0027\n",
            "Epoch 50/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5888 - loss: 1.4062\n",
            "Epoch 50: val_loss did not improve from 1.70115\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.5888 - loss: 1.4060 - val_accuracy: 0.4946 - val_loss: 1.8054 - learning_rate: 0.0027\n",
            "Epoch 51/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6043 - loss: 1.3332\n",
            "Epoch 51: val_loss did not improve from 1.70115\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - accuracy: 0.6043 - loss: 1.3334 - val_accuracy: 0.5063 - val_loss: 1.7655 - learning_rate: 0.0027\n",
            "Epoch 52/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6046 - loss: 1.3167\n",
            "Epoch 52: val_loss did not improve from 1.70115\n",
            "\n",
            "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0013417736627161503.\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 41ms/step - accuracy: 0.6047 - loss: 1.3168 - val_accuracy: 0.5194 - val_loss: 1.8158 - learning_rate: 0.0027\n",
            "Epoch 53/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6168 - loss: 1.2852\n",
            "Epoch 53: val_loss improved from 1.70115 to 1.69716, saving model to ../output/experiments/trial_39_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - accuracy: 0.6168 - loss: 1.2851 - val_accuracy: 0.5287 - val_loss: 1.6972 - learning_rate: 0.0013\n",
            "Epoch 54/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6428 - loss: 1.2027\n",
            "Epoch 54: val_loss did not improve from 1.69716\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.6427 - loss: 1.2028 - val_accuracy: 0.5446 - val_loss: 1.7033 - learning_rate: 0.0013\n",
            "Epoch 55/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6557 - loss: 1.1558\n",
            "Epoch 55: val_loss did not improve from 1.69716\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.6557 - loss: 1.1558 - val_accuracy: 0.5483 - val_loss: 1.7195 - learning_rate: 0.0013\n",
            "Epoch 56/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6602 - loss: 1.1563\n",
            "Epoch 56: val_loss did not improve from 1.69716\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.6601 - loss: 1.1563 - val_accuracy: 0.5432 - val_loss: 1.7424 - learning_rate: 0.0013\n",
            "Epoch 57/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6590 - loss: 1.1247\n",
            "Epoch 57: val_loss did not improve from 1.69716\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.6590 - loss: 1.1248 - val_accuracy: 0.5422 - val_loss: 1.7963 - learning_rate: 0.0013\n",
            "Epoch 58/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6715 - loss: 1.1233\n",
            "Epoch 58: val_loss did not improve from 1.69716\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - accuracy: 0.6714 - loss: 1.1234 - val_accuracy: 0.5478 - val_loss: 1.7348 - learning_rate: 0.0013\n",
            "Epoch 59/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6619 - loss: 1.1035\n",
            "Epoch 59: val_loss did not improve from 1.69716\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - accuracy: 0.6620 - loss: 1.1036 - val_accuracy: 0.5544 - val_loss: 1.7592 - learning_rate: 0.0013\n",
            "Epoch 60/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6871 - loss: 1.0664\n",
            "Epoch 60: val_loss did not improve from 1.69716\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - accuracy: 0.6870 - loss: 1.0666 - val_accuracy: 0.5558 - val_loss: 1.7346 - learning_rate: 0.0013\n",
            "Epoch 61/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6829 - loss: 1.0790\n",
            "Epoch 61: val_loss did not improve from 1.69716\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - accuracy: 0.6828 - loss: 1.0791 - val_accuracy: 0.5609 - val_loss: 1.7711 - learning_rate: 0.0013\n",
            "Epoch 62/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6764 - loss: 1.0764\n",
            "Epoch 62: val_loss did not improve from 1.69716\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.6765 - loss: 1.0764 - val_accuracy: 0.5544 - val_loss: 1.7934 - learning_rate: 0.0013\n",
            "Epoch 63/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6894 - loss: 1.0574\n",
            "Epoch 63: val_loss did not improve from 1.69716\n",
            "\n",
            "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0006708868313580751.\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - accuracy: 0.6894 - loss: 1.0575 - val_accuracy: 0.5502 - val_loss: 1.8190 - learning_rate: 0.0013\n",
            "Epoch 64/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6933 - loss: 1.0246\n",
            "Epoch 64: val_loss did not improve from 1.69716\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.6933 - loss: 1.0246 - val_accuracy: 0.5642 - val_loss: 1.7648 - learning_rate: 6.7089e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7102 - loss: 0.9882\n",
            "Epoch 65: val_loss did not improve from 1.69716\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - accuracy: 0.7101 - loss: 0.9884 - val_accuracy: 0.5800 - val_loss: 1.7825 - learning_rate: 6.7089e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7037 - loss: 0.9898\n",
            "Epoch 66: val_loss did not improve from 1.69716\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - accuracy: 0.7039 - loss: 0.9897 - val_accuracy: 0.5786 - val_loss: 1.7790 - learning_rate: 6.7089e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7204 - loss: 0.9544\n",
            "Epoch 67: val_loss did not improve from 1.69716\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - accuracy: 0.7203 - loss: 0.9545 - val_accuracy: 0.5763 - val_loss: 1.7877 - learning_rate: 6.7089e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7143 - loss: 0.9628\n",
            "Epoch 68: val_loss did not improve from 1.69716\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.7144 - loss: 0.9627 - val_accuracy: 0.5833 - val_loss: 1.8077 - learning_rate: 6.7089e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7176 - loss: 0.9575\n",
            "Epoch 69: val_loss did not improve from 1.69716\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - accuracy: 0.7177 - loss: 0.9574 - val_accuracy: 0.5763 - val_loss: 1.8379 - learning_rate: 6.7089e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7293 - loss: 0.9256\n",
            "Epoch 70: val_loss did not improve from 1.69716\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - accuracy: 0.7293 - loss: 0.9256 - val_accuracy: 0.5744 - val_loss: 1.8172 - learning_rate: 6.7089e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7244 - loss: 0.9218\n",
            "Epoch 71: val_loss did not improve from 1.69716\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.7244 - loss: 0.9218 - val_accuracy: 0.5721 - val_loss: 1.8501 - learning_rate: 6.7089e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7342 - loss: 0.9091\n",
            "Epoch 72: val_loss did not improve from 1.69716\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.7342 - loss: 0.9092 - val_accuracy: 0.5894 - val_loss: 1.8367 - learning_rate: 6.7089e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7363 - loss: 0.9117\n",
            "Epoch 73: val_loss did not improve from 1.69716\n",
            "\n",
            "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.00033544341567903757.\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - accuracy: 0.7362 - loss: 0.9118 - val_accuracy: 0.5819 - val_loss: 1.8553 - learning_rate: 6.7089e-04\n",
            "Epoch 73: early stopping\n",
            "Restoring model weights from the end of the best epoch: 53.\n",
            "å­¦ç¿’å®Œäº†ï¼å­¦ç¿’æ™‚é–“: 437.81ç§’\n",
            "æœ€è‰¯æ¤œè¨¼Loss: 1.6972\n",
            "æœ€è‰¯æ¤œè¨¼Accuracy: 0.5894\n",
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ä¸­...\n",
            "ãƒ†ã‚¹ãƒˆLoss: 1.6870\n",
            "ãƒ†ã‚¹ãƒˆAccuracy: 0.5450\n",
            "F1-Score (macro): 0.4761\n",
            "F1-Score (weighted): 0.5263\n",
            "çµæœä¿å­˜ä¸­...\n",
            "å­¦ç¿’å±¥æ­´ä¿å­˜å®Œäº†: ../output/experiments/trial_39_w64_s16_w64_s16/results/training_history_attention.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-08 22:01:53,341] Trial 39 finished with value: 0.7356274911048908 and parameters: {'lstm_units_1': 80, 'lstm_units_2': 48, 'dense_units': 32, 'demographics_dense_units': 24, 'fusion_dense_units': 48, 'dropout_rate': 0.2, 'dense_dropout_rate': 0.30000000000000004, 'learning_rate': 0.0026835472932003213, 'batch_size': 64, 'fusion_type': 'attention'}. Best is trial 34 with value: 0.8021217206997858.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "çµæœä¿å­˜å®Œäº†: ../output/experiments/trial_39_w64_s16_w64_s16/results\n",
            "âœ… Trial 39: CMI=0.7356, Binary F1=0.9427, Fusion=attention\n",
            "\n",
            "ğŸ” Trial 40 - w64_s16\n",
            "Mixed precision enabled for better GPU performance\n",
            "GPUåˆ©ç”¨å¯èƒ½: 1å°\n",
            "ä½¿ç”¨GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
            "LSTM v2å­¦ç¿’ç’°å¢ƒåˆæœŸåŒ–å®Œäº†\n",
            "å®Ÿé¨“å: trial_40_w64_s16\n",
            "ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®š: w64_s16\n",
            "å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: ../output/experiments/trial_40_w64_s16_w64_s16\n",
            "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿: ../output/experiments/lstm_v2_w64_s16/preprocessed\n",
            "GPUåˆ©ç”¨å¯èƒ½: True\n",
            "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...\n",
            "æœ€é©åŒ–ã•ã‚ŒãŸdemographicsç‰¹å¾´é‡ã‚’ä½¿ç”¨ã—ã¾ã™\n",
            "æœ€é©åŒ–ã•ã‚ŒãŸdemographicså½¢çŠ¶: (13393, 18)\n",
            "ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†:\n",
            "  ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿: (13393, 64, 332)\n",
            "  Demographics: (13393, 18)\n",
            "  ãƒ©ãƒ™ãƒ«: (13393,)\n",
            "  ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹ (èåˆæ–¹å¼: attention)...\n",
            "ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ä¸­...\n",
            "ãƒ†ã‚¹ãƒˆã‚µã‚¤ã‚º: 0.2\n",
            "æ¤œè¨¼ã‚µã‚¤ã‚º: 0.2\n",
            "ãƒ‡ãƒ¼ã‚¿åˆ†å‰²å®Œäº†:\n",
            "  è¨“ç·´ - ã‚»ãƒ³ã‚µãƒ¼: (8571, 64, 332), Demographics: (8571, 18), ãƒ©ãƒ™ãƒ«: (8571,)\n",
            "  æ¤œè¨¼ - ã‚»ãƒ³ã‚µãƒ¼: (2143, 64, 332), Demographics: (2143, 18), ãƒ©ãƒ™ãƒ«: (2143,)\n",
            "  ãƒ†ã‚¹ãƒˆ - ã‚»ãƒ³ã‚µãƒ¼: (2679, 64, 332), Demographics: (2679, 18), ãƒ©ãƒ™ãƒ«: (2679,)\n",
            "å…¥åŠ›å½¢çŠ¶:\n",
            "  ã‚»ãƒ³ã‚µãƒ¼: (64, 332)\n",
            "  Demographics: (18,)\n",
            "  ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "GPUä¸Šã§ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆãƒ»å­¦ç¿’ã—ã¾ã™\n",
            "Mixed precision enabled for better GPU performance\n",
            "GPUåˆ©ç”¨å¯èƒ½: 1å°\n",
            "ä½¿ç”¨GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
            "LSTM v2ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†\n",
            "ã‚»ãƒ³ã‚µãƒ¼å…¥åŠ›å½¢çŠ¶: (64, 332)\n",
            "Demographicså…¥åŠ›å½¢çŠ¶: (18,)\n",
            "ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "èåˆæ–¹å¼: attention\n",
            "GPUåˆ©ç”¨å¯èƒ½: True\n",
            "LSTM v2ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ä¸­...\n",
            "ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰å®Œäº†\n",
            "ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 179,610\n",
            "\n",
            "=== ãƒ¢ãƒ‡ãƒ«ã‚µãƒãƒªãƒ¼ ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"lstm_v2_hybrid\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"lstm_v2_hybrid\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ sensor_input        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">332</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">132,160</span> â”‚ sensor_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_1           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> â”‚ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_1      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ lstm_bn_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_input  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">37,120</span> â”‚ lstm_dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">608</span> â”‚ demographics_inpâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_2           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_2      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ lstm_bn_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dense        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,600</span> â”‚ lstm_dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dropout      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sensor_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_weights   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,320</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attended_sensor     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sensor_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          â”‚                   â”‚            â”‚ attention_weightâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_projeâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,320</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_fusion    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ attended_sensor[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚                   â”‚            â”‚ demographics_proâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dense        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,968</span> â”‚ attention_fusionâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dropout      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ fusion_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">882</span> â”‚ fusion_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ sensor_input        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m332\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m80\u001b[0m)    â”‚    \u001b[38;5;34m132,160\u001b[0m â”‚ sensor_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_1           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m80\u001b[0m)    â”‚        \u001b[38;5;34m320\u001b[0m â”‚ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_1      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m80\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ lstm_bn_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_input  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚     \u001b[38;5;34m37,120\u001b[0m â”‚ lstm_dropout_1[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚        \u001b[38;5;34m608\u001b[0m â”‚ demographics_inpâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_2           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m256\u001b[0m â”‚ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_2      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ lstm_bn_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚      \u001b[38;5;34m1,056\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dense        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)        â”‚      \u001b[38;5;34m2,600\u001b[0m â”‚ lstm_dropout_2[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dropout      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sensor_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_weights   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)        â”‚      \u001b[38;5;34m1,320\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attended_sensor     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sensor_dropout[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mMultiply\u001b[0m)          â”‚                   â”‚            â”‚ attention_weightâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_projeâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)        â”‚      \u001b[38;5;34m1,320\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_fusion    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ attended_sensor[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚                   â”‚            â”‚ demographics_proâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dense        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚      \u001b[38;5;34m1,968\u001b[0m â”‚ attention_fusionâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dropout      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ fusion_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (\u001b[38;5;33mDense\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        â”‚        \u001b[38;5;34m882\u001b[0m â”‚ fusion_dropout[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">179,610</span> (701.60 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m179,610\u001b[0m (701.60 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">179,322</span> (700.48 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m179,322\u001b[0m (700.48 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> (1.12 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m288\u001b[0m (1.12 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹...\n",
            "ã‚»ãƒ³ã‚µãƒ¼è¨“ç·´ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (8571, 64, 332)\n",
            "Demographicsè¨“ç·´ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (8571, 18)\n",
            "ã‚»ãƒ³ã‚µãƒ¼æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (2143, 64, 332)\n",
            "Demographicsæ¤œè¨¼ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (2143, 18)\n",
            "è¨“ç·´ãƒ©ãƒ™ãƒ«å½¢çŠ¶: (8571,)\n",
            "æ¤œè¨¼ãƒ©ãƒ™ãƒ«å½¢çŠ¶: (2143,)\n",
            "Epoch 1/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.1416 - loss: 2.7703\n",
            "Epoch 1: val_loss improved from inf to 2.43846, saving model to ../output/experiments/trial_40_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 45ms/step - accuracy: 0.1418 - loss: 2.7698 - val_accuracy: 0.2571 - val_loss: 2.4385 - learning_rate: 0.0040\n",
            "Epoch 2/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.2701 - loss: 2.3691\n",
            "Epoch 2: val_loss improved from 2.43846 to 2.23446, saving model to ../output/experiments/trial_40_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.2701 - loss: 2.3691 - val_accuracy: 0.2940 - val_loss: 2.2345 - learning_rate: 0.0040\n",
            "Epoch 3/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.3000 - loss: 2.2817\n",
            "Epoch 3: val_loss did not improve from 2.23446\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.3000 - loss: 2.2817 - val_accuracy: 0.3000 - val_loss: 2.2635 - learning_rate: 0.0040\n",
            "Epoch 4/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.3140 - loss: 2.2805\n",
            "Epoch 4: val_loss improved from 2.23446 to 2.21262, saving model to ../output/experiments/trial_40_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.3140 - loss: 2.2805 - val_accuracy: 0.3206 - val_loss: 2.2126 - learning_rate: 0.0040\n",
            "Epoch 5/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3324 - loss: 2.2373\n",
            "Epoch 5: val_loss did not improve from 2.21262\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.3324 - loss: 2.2373 - val_accuracy: 0.3285 - val_loss: 2.2233 - learning_rate: 0.0040\n",
            "Epoch 6/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3477 - loss: 2.2014\n",
            "Epoch 6: val_loss improved from 2.21262 to 2.19902, saving model to ../output/experiments/trial_40_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.3477 - loss: 2.2015 - val_accuracy: 0.3392 - val_loss: 2.1990 - learning_rate: 0.0040\n",
            "Epoch 7/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3555 - loss: 2.2016\n",
            "Epoch 7: val_loss improved from 2.19902 to 2.19730, saving model to ../output/experiments/trial_40_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.3555 - loss: 2.2017 - val_accuracy: 0.3439 - val_loss: 2.1973 - learning_rate: 0.0040\n",
            "Epoch 8/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3605 - loss: 2.1786\n",
            "Epoch 8: val_loss did not improve from 2.19730\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.3605 - loss: 2.1788 - val_accuracy: 0.3490 - val_loss: 2.2270 - learning_rate: 0.0040\n",
            "Epoch 9/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3787 - loss: 2.1323\n",
            "Epoch 9: val_loss improved from 2.19730 to 2.17199, saving model to ../output/experiments/trial_40_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.3787 - loss: 2.1324 - val_accuracy: 0.3710 - val_loss: 2.1720 - learning_rate: 0.0040\n",
            "Epoch 10/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3908 - loss: 2.1102\n",
            "Epoch 10: val_loss improved from 2.17199 to 2.15521, saving model to ../output/experiments/trial_40_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.3908 - loss: 2.1103 - val_accuracy: 0.3775 - val_loss: 2.1552 - learning_rate: 0.0040\n",
            "Epoch 11/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3878 - loss: 2.1785\n",
            "Epoch 11: val_loss improved from 2.15521 to 2.13538, saving model to ../output/experiments/trial_40_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.3878 - loss: 2.1784 - val_accuracy: 0.3971 - val_loss: 2.1354 - learning_rate: 0.0040\n",
            "Epoch 12/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4006 - loss: 2.1330\n",
            "Epoch 12: val_loss did not improve from 2.13538\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.4006 - loss: 2.1330 - val_accuracy: 0.4004 - val_loss: 2.1767 - learning_rate: 0.0040\n",
            "Epoch 13/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4166 - loss: 2.0779\n",
            "Epoch 13: val_loss did not improve from 2.13538\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4166 - loss: 2.0781 - val_accuracy: 0.3985 - val_loss: 2.1506 - learning_rate: 0.0040\n",
            "Epoch 14/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4167 - loss: 2.1069\n",
            "Epoch 14: val_loss improved from 2.13538 to 2.09703, saving model to ../output/experiments/trial_40_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.4167 - loss: 2.1069 - val_accuracy: 0.4130 - val_loss: 2.0970 - learning_rate: 0.0040\n",
            "Epoch 15/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4395 - loss: 2.0536\n",
            "Epoch 15: val_loss improved from 2.09703 to 2.08458, saving model to ../output/experiments/trial_40_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4395 - loss: 2.0536 - val_accuracy: 0.4153 - val_loss: 2.0846 - learning_rate: 0.0040\n",
            "Epoch 16/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4462 - loss: 2.0109\n",
            "Epoch 16: val_loss did not improve from 2.08458\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.4462 - loss: 2.0110 - val_accuracy: 0.4190 - val_loss: 2.0861 - learning_rate: 0.0040\n",
            "Epoch 17/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4534 - loss: 1.9953\n",
            "Epoch 17: val_loss did not improve from 2.08458\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.4534 - loss: 1.9954 - val_accuracy: 0.4139 - val_loss: 2.1026 - learning_rate: 0.0040\n",
            "Epoch 18/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4477 - loss: 2.0176\n",
            "Epoch 18: val_loss improved from 2.08458 to 2.07610, saving model to ../output/experiments/trial_40_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4477 - loss: 2.0176 - val_accuracy: 0.4251 - val_loss: 2.0761 - learning_rate: 0.0040\n",
            "Epoch 19/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4604 - loss: 1.9885\n",
            "Epoch 19: val_loss did not improve from 2.07610\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.4604 - loss: 1.9886 - val_accuracy: 0.4074 - val_loss: 2.1652 - learning_rate: 0.0040\n",
            "Epoch 20/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4407 - loss: 2.0427\n",
            "Epoch 20: val_loss improved from 2.07610 to 2.02834, saving model to ../output/experiments/trial_40_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.4408 - loss: 2.0424 - val_accuracy: 0.4414 - val_loss: 2.0283 - learning_rate: 0.0040\n",
            "Epoch 21/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4796 - loss: 1.9321\n",
            "Epoch 21: val_loss did not improve from 2.02834\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.4795 - loss: 1.9322 - val_accuracy: 0.4354 - val_loss: 2.0363 - learning_rate: 0.0040\n",
            "Epoch 22/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4699 - loss: 1.9342\n",
            "Epoch 22: val_loss did not improve from 2.02834\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.4699 - loss: 1.9344 - val_accuracy: 0.4545 - val_loss: 2.0332 - learning_rate: 0.0040\n",
            "Epoch 23/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4640 - loss: 1.9867\n",
            "Epoch 23: val_loss did not improve from 2.02834\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.4640 - loss: 1.9867 - val_accuracy: 0.4512 - val_loss: 2.0364 - learning_rate: 0.0040\n",
            "Epoch 24/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4796 - loss: 1.9266\n",
            "Epoch 24: val_loss improved from 2.02834 to 1.97707, saving model to ../output/experiments/trial_40_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4796 - loss: 1.9267 - val_accuracy: 0.4685 - val_loss: 1.9771 - learning_rate: 0.0040\n",
            "Epoch 25/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4761 - loss: 1.9493\n",
            "Epoch 25: val_loss did not improve from 1.97707\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4761 - loss: 1.9494 - val_accuracy: 0.4545 - val_loss: 2.0319 - learning_rate: 0.0040\n",
            "Epoch 26/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4654 - loss: 2.0098\n",
            "Epoch 26: val_loss did not improve from 1.97707\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4655 - loss: 2.0097 - val_accuracy: 0.4433 - val_loss: 2.0680 - learning_rate: 0.0040\n",
            "Epoch 27/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4819 - loss: 1.9497\n",
            "Epoch 27: val_loss did not improve from 1.97707\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.4819 - loss: 1.9498 - val_accuracy: 0.4601 - val_loss: 2.0413 - learning_rate: 0.0040\n",
            "Epoch 28/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5096 - loss: 1.9175\n",
            "Epoch 28: val_loss did not improve from 1.97707\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.5095 - loss: 1.9177 - val_accuracy: 0.4652 - val_loss: 2.0065 - learning_rate: 0.0040\n",
            "Epoch 29/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4995 - loss: 1.8953\n",
            "Epoch 29: val_loss did not improve from 1.97707\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4995 - loss: 1.8953 - val_accuracy: 0.4512 - val_loss: 2.0882 - learning_rate: 0.0040\n",
            "Epoch 30/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5121 - loss: 1.9196\n",
            "Epoch 30: val_loss did not improve from 1.97707\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5120 - loss: 1.9196 - val_accuracy: 0.4657 - val_loss: 2.0041 - learning_rate: 0.0040\n",
            "Epoch 31/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5128 - loss: 1.8532\n",
            "Epoch 31: val_loss did not improve from 1.97707\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5127 - loss: 1.8535 - val_accuracy: 0.4629 - val_loss: 2.0252 - learning_rate: 0.0040\n",
            "Epoch 32/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5167 - loss: 1.8548\n",
            "Epoch 32: val_loss did not improve from 1.97707\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5166 - loss: 1.8549 - val_accuracy: 0.4690 - val_loss: 2.0119 - learning_rate: 0.0040\n",
            "Epoch 33/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5262 - loss: 1.8357\n",
            "Epoch 33: val_loss did not improve from 1.97707\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.5261 - loss: 1.8358 - val_accuracy: 0.4536 - val_loss: 2.0175 - learning_rate: 0.0040\n",
            "Epoch 34/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5242 - loss: 1.8489\n",
            "Epoch 34: val_loss improved from 1.97707 to 1.93726, saving model to ../output/experiments/trial_40_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.5242 - loss: 1.8489 - val_accuracy: 0.4984 - val_loss: 1.9373 - learning_rate: 0.0040\n",
            "Epoch 35/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5278 - loss: 1.7825\n",
            "Epoch 35: val_loss did not improve from 1.93726\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5278 - loss: 1.7826 - val_accuracy: 0.4834 - val_loss: 1.9393 - learning_rate: 0.0040\n",
            "Epoch 36/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5103 - loss: 1.8160\n",
            "Epoch 36: val_loss did not improve from 1.93726\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.5104 - loss: 1.8160 - val_accuracy: 0.4881 - val_loss: 1.9457 - learning_rate: 0.0040\n",
            "Epoch 37/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5421 - loss: 1.7788\n",
            "Epoch 37: val_loss did not improve from 1.93726\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5420 - loss: 1.7789 - val_accuracy: 0.4755 - val_loss: 1.9622 - learning_rate: 0.0040\n",
            "Epoch 38/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5278 - loss: 1.7948\n",
            "Epoch 38: val_loss did not improve from 1.93726\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.5277 - loss: 1.7949 - val_accuracy: 0.4834 - val_loss: 1.9918 - learning_rate: 0.0040\n",
            "Epoch 39/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5257 - loss: 1.8158\n",
            "Epoch 39: val_loss improved from 1.93726 to 1.90677, saving model to ../output/experiments/trial_40_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.5257 - loss: 1.8157 - val_accuracy: 0.5086 - val_loss: 1.9068 - learning_rate: 0.0040\n",
            "Epoch 40/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5450 - loss: 1.7607\n",
            "Epoch 40: val_loss did not improve from 1.90677\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.5450 - loss: 1.7608 - val_accuracy: 0.4862 - val_loss: 1.9738 - learning_rate: 0.0040\n",
            "Epoch 41/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5400 - loss: 1.7419\n",
            "Epoch 41: val_loss did not improve from 1.90677\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.5400 - loss: 1.7420 - val_accuracy: 0.5002 - val_loss: 1.9411 - learning_rate: 0.0040\n",
            "Epoch 42/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5652 - loss: 1.6987\n",
            "Epoch 42: val_loss improved from 1.90677 to 1.87542, saving model to ../output/experiments/trial_40_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5652 - loss: 1.6988 - val_accuracy: 0.5198 - val_loss: 1.8754 - learning_rate: 0.0040\n",
            "Epoch 43/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5609 - loss: 1.7265\n",
            "Epoch 43: val_loss did not improve from 1.87542\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5608 - loss: 1.7266 - val_accuracy: 0.5002 - val_loss: 1.8951 - learning_rate: 0.0040\n",
            "Epoch 44/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5671 - loss: 1.6861\n",
            "Epoch 44: val_loss did not improve from 1.87542\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5671 - loss: 1.6863 - val_accuracy: 0.4993 - val_loss: 1.9142 - learning_rate: 0.0040\n",
            "Epoch 45/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5576 - loss: 1.7220\n",
            "Epoch 45: val_loss did not improve from 1.87542\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.5576 - loss: 1.7220 - val_accuracy: 0.5086 - val_loss: 1.8989 - learning_rate: 0.0040\n",
            "Epoch 46/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5530 - loss: 1.7360\n",
            "Epoch 46: val_loss did not improve from 1.87542\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.5530 - loss: 1.7360 - val_accuracy: 0.4998 - val_loss: 1.9093 - learning_rate: 0.0040\n",
            "Epoch 47/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5710 - loss: 1.6749\n",
            "Epoch 47: val_loss did not improve from 1.87542\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.5710 - loss: 1.6752 - val_accuracy: 0.5100 - val_loss: 1.9329 - learning_rate: 0.0040\n",
            "Epoch 48/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5592 - loss: 1.7183\n",
            "Epoch 48: val_loss did not improve from 1.87542\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.5592 - loss: 1.7186 - val_accuracy: 0.5091 - val_loss: 1.9201 - learning_rate: 0.0040\n",
            "Epoch 49/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5691 - loss: 1.6837\n",
            "Epoch 49: val_loss did not improve from 1.87542\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5690 - loss: 1.6839 - val_accuracy: 0.5203 - val_loss: 1.8877 - learning_rate: 0.0040\n",
            "Epoch 50/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5794 - loss: 1.6828\n",
            "Epoch 50: val_loss did not improve from 1.87542\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.5794 - loss: 1.6830 - val_accuracy: 0.4890 - val_loss: 2.0165 - learning_rate: 0.0040\n",
            "Epoch 51/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5605 - loss: 1.7522\n",
            "Epoch 51: val_loss did not improve from 1.87542\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5605 - loss: 1.7521 - val_accuracy: 0.5105 - val_loss: 1.9259 - learning_rate: 0.0040\n",
            "Epoch 52/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5860 - loss: 1.6987\n",
            "Epoch 52: val_loss did not improve from 1.87542\n",
            "\n",
            "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0020020436495542526.\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5859 - loss: 1.6990 - val_accuracy: 0.5082 - val_loss: 1.8892 - learning_rate: 0.0040\n",
            "Epoch 53/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5929 - loss: 1.6262\n",
            "Epoch 53: val_loss improved from 1.87542 to 1.83349, saving model to ../output/experiments/trial_40_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5930 - loss: 1.6259 - val_accuracy: 0.5315 - val_loss: 1.8335 - learning_rate: 0.0020\n",
            "Epoch 54/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6304 - loss: 1.4865\n",
            "Epoch 54: val_loss improved from 1.83349 to 1.82946, saving model to ../output/experiments/trial_40_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.6305 - loss: 1.4865 - val_accuracy: 0.5422 - val_loss: 1.8295 - learning_rate: 0.0020\n",
            "Epoch 55/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6474 - loss: 1.4325\n",
            "Epoch 55: val_loss improved from 1.82946 to 1.81179, saving model to ../output/experiments/trial_40_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.6473 - loss: 1.4325 - val_accuracy: 0.5520 - val_loss: 1.8118 - learning_rate: 0.0020\n",
            "Epoch 56/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6635 - loss: 1.3945\n",
            "Epoch 56: val_loss improved from 1.81179 to 1.78862, saving model to ../output/experiments/trial_40_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.6635 - loss: 1.3946 - val_accuracy: 0.5670 - val_loss: 1.7886 - learning_rate: 0.0020\n",
            "Epoch 57/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6678 - loss: 1.3709\n",
            "Epoch 57: val_loss improved from 1.78862 to 1.74253, saving model to ../output/experiments/trial_40_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.6677 - loss: 1.3710 - val_accuracy: 0.5707 - val_loss: 1.7425 - learning_rate: 0.0020\n",
            "Epoch 58/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6686 - loss: 1.3525\n",
            "Epoch 58: val_loss improved from 1.74253 to 1.70865, saving model to ../output/experiments/trial_40_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.6687 - loss: 1.3525 - val_accuracy: 0.5796 - val_loss: 1.7087 - learning_rate: 0.0020\n",
            "Epoch 59/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6865 - loss: 1.2918\n",
            "Epoch 59: val_loss improved from 1.70865 to 1.68266, saving model to ../output/experiments/trial_40_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.6864 - loss: 1.2919 - val_accuracy: 0.5712 - val_loss: 1.6827 - learning_rate: 0.0020\n",
            "Epoch 60/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6924 - loss: 1.2971\n",
            "Epoch 60: val_loss did not improve from 1.68266\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.6924 - loss: 1.2972 - val_accuracy: 0.5772 - val_loss: 1.7209 - learning_rate: 0.0020\n",
            "Epoch 61/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7024 - loss: 1.2538\n",
            "Epoch 61: val_loss did not improve from 1.68266\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.7023 - loss: 1.2541 - val_accuracy: 0.5763 - val_loss: 1.7111 - learning_rate: 0.0020\n",
            "Epoch 62/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6870 - loss: 1.2638\n",
            "Epoch 62: val_loss did not improve from 1.68266\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.6870 - loss: 1.2638 - val_accuracy: 0.5838 - val_loss: 1.6997 - learning_rate: 0.0020\n",
            "Epoch 63/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7120 - loss: 1.1963\n",
            "Epoch 63: val_loss did not improve from 1.68266\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.7120 - loss: 1.1963 - val_accuracy: 0.5852 - val_loss: 1.7593 - learning_rate: 0.0020\n",
            "Epoch 64/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7167 - loss: 1.2031\n",
            "Epoch 64: val_loss did not improve from 1.68266\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.7167 - loss: 1.2031 - val_accuracy: 0.5912 - val_loss: 1.7426 - learning_rate: 0.0020\n",
            "Epoch 65/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7161 - loss: 1.2057\n",
            "Epoch 65: val_loss did not improve from 1.68266\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.7160 - loss: 1.2058 - val_accuracy: 0.5754 - val_loss: 1.7634 - learning_rate: 0.0020\n",
            "Epoch 66/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7188 - loss: 1.1926\n",
            "Epoch 66: val_loss did not improve from 1.68266\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.7187 - loss: 1.1928 - val_accuracy: 0.5712 - val_loss: 1.7706 - learning_rate: 0.0020\n",
            "Epoch 67/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7168 - loss: 1.1831\n",
            "Epoch 67: val_loss did not improve from 1.68266\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.7168 - loss: 1.1832 - val_accuracy: 0.5805 - val_loss: 1.7297 - learning_rate: 0.0020\n",
            "Epoch 68/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7193 - loss: 1.1698\n",
            "Epoch 68: val_loss did not improve from 1.68266\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.7193 - loss: 1.1698 - val_accuracy: 0.5805 - val_loss: 1.7554 - learning_rate: 0.0020\n",
            "Epoch 69/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7449 - loss: 1.1350\n",
            "Epoch 69: val_loss did not improve from 1.68266\n",
            "\n",
            "Epoch 69: ReduceLROnPlateau reducing learning rate to 0.0010010218247771263.\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.7448 - loss: 1.1352 - val_accuracy: 0.5996 - val_loss: 1.7416 - learning_rate: 0.0020\n",
            "Epoch 70/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7456 - loss: 1.1018\n",
            "Epoch 70: val_loss did not improve from 1.68266\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.7456 - loss: 1.1018 - val_accuracy: 0.6150 - val_loss: 1.6967 - learning_rate: 0.0010\n",
            "Epoch 71/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7715 - loss: 1.0329\n",
            "Epoch 71: val_loss did not improve from 1.68266\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.7715 - loss: 1.0329 - val_accuracy: 0.6178 - val_loss: 1.7274 - learning_rate: 0.0010\n",
            "Epoch 72/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7792 - loss: 1.0047\n",
            "Epoch 72: val_loss did not improve from 1.68266\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.7792 - loss: 1.0046 - val_accuracy: 0.6071 - val_loss: 1.7812 - learning_rate: 0.0010\n",
            "Epoch 73/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7799 - loss: 0.9742\n",
            "Epoch 73: val_loss did not improve from 1.68266\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.7799 - loss: 0.9742 - val_accuracy: 0.6276 - val_loss: 1.7421 - learning_rate: 0.0010\n",
            "Epoch 74/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7974 - loss: 0.9353\n",
            "Epoch 74: val_loss did not improve from 1.68266\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.7974 - loss: 0.9353 - val_accuracy: 0.6141 - val_loss: 1.7702 - learning_rate: 0.0010\n",
            "Epoch 75/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7982 - loss: 0.9384\n",
            "Epoch 75: val_loss did not improve from 1.68266\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.7982 - loss: 0.9384 - val_accuracy: 0.6202 - val_loss: 1.7486 - learning_rate: 0.0010\n",
            "Epoch 76/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8020 - loss: 0.9339\n",
            "Epoch 76: val_loss did not improve from 1.68266\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.8020 - loss: 0.9339 - val_accuracy: 0.6066 - val_loss: 1.8081 - learning_rate: 0.0010\n",
            "Epoch 77/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8080 - loss: 0.9085\n",
            "Epoch 77: val_loss did not improve from 1.68266\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.8080 - loss: 0.9085 - val_accuracy: 0.6062 - val_loss: 1.7992 - learning_rate: 0.0010\n",
            "Epoch 78/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8186 - loss: 0.8786\n",
            "Epoch 78: val_loss did not improve from 1.68266\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.8185 - loss: 0.8786 - val_accuracy: 0.6043 - val_loss: 1.7922 - learning_rate: 0.0010\n",
            "Epoch 79/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8173 - loss: 0.8832\n",
            "Epoch 79: val_loss did not improve from 1.68266\n",
            "\n",
            "Epoch 79: ReduceLROnPlateau reducing learning rate to 0.0005005109123885632.\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.8173 - loss: 0.8833 - val_accuracy: 0.6104 - val_loss: 1.7999 - learning_rate: 0.0010\n",
            "Epoch 79: early stopping\n",
            "Restoring model weights from the end of the best epoch: 59.\n",
            "å­¦ç¿’å®Œäº†ï¼å­¦ç¿’æ™‚é–“: 873.90ç§’\n",
            "æœ€è‰¯æ¤œè¨¼Loss: 1.6827\n",
            "æœ€è‰¯æ¤œè¨¼Accuracy: 0.6276\n",
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ä¸­...\n",
            "ãƒ†ã‚¹ãƒˆLoss: 1.7427\n",
            "ãƒ†ã‚¹ãƒˆAccuracy: 0.5778\n",
            "F1-Score (macro): 0.5271\n",
            "F1-Score (weighted): 0.5704\n",
            "çµæœä¿å­˜ä¸­...\n",
            "å­¦ç¿’å±¥æ­´ä¿å­˜å®Œäº†: ../output/experiments/trial_40_w64_s16_w64_s16/results/training_history_attention.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-08 22:16:35,679] Trial 40 finished with value: 0.7646094583485418 and parameters: {'lstm_units_1': 80, 'lstm_units_2': 64, 'dense_units': 40, 'demographics_dense_units': 32, 'fusion_dense_units': 48, 'dropout_rate': 0.1, 'dense_dropout_rate': 0.2, 'learning_rate': 0.004004087255234955, 'batch_size': 32, 'fusion_type': 'attention'}. Best is trial 34 with value: 0.8021217206997858.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "çµæœä¿å­˜å®Œäº†: ../output/experiments/trial_40_w64_s16_w64_s16/results\n",
            "âœ… Trial 40: CMI=0.7646, Binary F1=0.9366, Fusion=attention\n",
            "\n",
            "ğŸ” Trial 41 - w64_s16\n",
            "Mixed precision enabled for better GPU performance\n",
            "GPUåˆ©ç”¨å¯èƒ½: 1å°\n",
            "ä½¿ç”¨GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
            "LSTM v2å­¦ç¿’ç’°å¢ƒåˆæœŸåŒ–å®Œäº†\n",
            "å®Ÿé¨“å: trial_41_w64_s16\n",
            "ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®š: w64_s16\n",
            "å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: ../output/experiments/trial_41_w64_s16_w64_s16\n",
            "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿: ../output/experiments/lstm_v2_w64_s16/preprocessed\n",
            "GPUåˆ©ç”¨å¯èƒ½: True\n",
            "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...\n",
            "æœ€é©åŒ–ã•ã‚ŒãŸdemographicsç‰¹å¾´é‡ã‚’ä½¿ç”¨ã—ã¾ã™\n",
            "æœ€é©åŒ–ã•ã‚ŒãŸdemographicså½¢çŠ¶: (13393, 18)\n",
            "ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†:\n",
            "  ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿: (13393, 64, 332)\n",
            "  Demographics: (13393, 18)\n",
            "  ãƒ©ãƒ™ãƒ«: (13393,)\n",
            "  ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹ (èåˆæ–¹å¼: concatenate)...\n",
            "ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ä¸­...\n",
            "ãƒ†ã‚¹ãƒˆã‚µã‚¤ã‚º: 0.2\n",
            "æ¤œè¨¼ã‚µã‚¤ã‚º: 0.2\n",
            "ãƒ‡ãƒ¼ã‚¿åˆ†å‰²å®Œäº†:\n",
            "  è¨“ç·´ - ã‚»ãƒ³ã‚µãƒ¼: (8571, 64, 332), Demographics: (8571, 18), ãƒ©ãƒ™ãƒ«: (8571,)\n",
            "  æ¤œè¨¼ - ã‚»ãƒ³ã‚µãƒ¼: (2143, 64, 332), Demographics: (2143, 18), ãƒ©ãƒ™ãƒ«: (2143,)\n",
            "  ãƒ†ã‚¹ãƒˆ - ã‚»ãƒ³ã‚µãƒ¼: (2679, 64, 332), Demographics: (2679, 18), ãƒ©ãƒ™ãƒ«: (2679,)\n",
            "å…¥åŠ›å½¢çŠ¶:\n",
            "  ã‚»ãƒ³ã‚µãƒ¼: (64, 332)\n",
            "  Demographics: (18,)\n",
            "  ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "GPUä¸Šã§ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆãƒ»å­¦ç¿’ã—ã¾ã™\n",
            "Mixed precision enabled for better GPU performance\n",
            "GPUåˆ©ç”¨å¯èƒ½: 1å°\n",
            "ä½¿ç”¨GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
            "LSTM v2ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†\n",
            "ã‚»ãƒ³ã‚µãƒ¼å…¥åŠ›å½¢çŠ¶: (64, 332)\n",
            "Demographicså…¥åŠ›å½¢çŠ¶: (18,)\n",
            "ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "èåˆæ–¹å¼: concatenate\n",
            "GPUåˆ©ç”¨å¯èƒ½: True\n",
            "LSTM v2ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ä¸­...\n",
            "ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰å®Œäº†\n",
            "ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 137,874\n",
            "\n",
            "=== ãƒ¢ãƒ‡ãƒ«ã‚µãƒãƒªãƒ¼ ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"lstm_v2_hybrid\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"lstm_v2_hybrid\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ sensor_input        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">332</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">101,632</span> â”‚ sensor_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_1           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_1      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ lstm_bn_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">27,104</span> â”‚ lstm_dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_input  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_2           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> â”‚ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">532</span> â”‚ demographics_inpâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_2      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ lstm_bn_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dense        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,736</span> â”‚ lstm_dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">812</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dropout      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sensor_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ feature_fusion      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sensor_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â”‚                   â”‚            â”‚ demographics_droâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dense        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,696</span> â”‚ feature_fusion[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dropout      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ fusion_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">882</span> â”‚ fusion_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ sensor_input        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m332\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚    \u001b[38;5;34m101,632\u001b[0m â”‚ sensor_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_1           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚        \u001b[38;5;34m256\u001b[0m â”‚ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_1      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ lstm_bn_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        â”‚     \u001b[38;5;34m27,104\u001b[0m â”‚ lstm_dropout_1[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_input  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_2           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        â”‚        \u001b[38;5;34m224\u001b[0m â”‚ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)        â”‚        \u001b[38;5;34m532\u001b[0m â”‚ demographics_inpâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_2      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ lstm_bn_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dense        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚      \u001b[38;5;34m2,736\u001b[0m â”‚ lstm_dropout_2[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)        â”‚        \u001b[38;5;34m812\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dropout      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sensor_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ feature_fusion      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m76\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sensor_dropout[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConcatenate\u001b[0m)       â”‚                   â”‚            â”‚ demographics_droâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dense        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚      \u001b[38;5;34m3,696\u001b[0m â”‚ feature_fusion[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dropout      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ fusion_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (\u001b[38;5;33mDense\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        â”‚        \u001b[38;5;34m882\u001b[0m â”‚ fusion_dropout[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">137,874</span> (538.57 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m137,874\u001b[0m (538.57 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">137,634</span> (537.63 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m137,634\u001b[0m (537.63 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> (960.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m240\u001b[0m (960.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹...\n",
            "ã‚»ãƒ³ã‚µãƒ¼è¨“ç·´ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (8571, 64, 332)\n",
            "Demographicsè¨“ç·´ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (8571, 18)\n",
            "ã‚»ãƒ³ã‚µãƒ¼æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (2143, 64, 332)\n",
            "Demographicsæ¤œè¨¼ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (2143, 18)\n",
            "è¨“ç·´ãƒ©ãƒ™ãƒ«å½¢çŠ¶: (8571,)\n",
            "æ¤œè¨¼ãƒ©ãƒ™ãƒ«å½¢çŠ¶: (2143,)\n",
            "Epoch 1/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.1262 - loss: 2.8900\n",
            "Epoch 1: val_loss improved from inf to 2.37551, saving model to ../output/experiments/trial_41_w64_s16_w64_s16/models/lstm_v2_hybrid_concatenate_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 42ms/step - accuracy: 0.1264 - loss: 2.8887 - val_accuracy: 0.2534 - val_loss: 2.3755 - learning_rate: 0.0016\n",
            "Epoch 2/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2372 - loss: 2.4360\n",
            "Epoch 2: val_loss improved from 2.37551 to 2.19691, saving model to ../output/experiments/trial_41_w64_s16_w64_s16/models/lstm_v2_hybrid_concatenate_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.2372 - loss: 2.4358 - val_accuracy: 0.2972 - val_loss: 2.1969 - learning_rate: 0.0016\n",
            "Epoch 3/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2857 - loss: 2.2680\n",
            "Epoch 3: val_loss improved from 2.19691 to 2.09504, saving model to ../output/experiments/trial_41_w64_s16_w64_s16/models/lstm_v2_hybrid_concatenate_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.2857 - loss: 2.2679 - val_accuracy: 0.3038 - val_loss: 2.0950 - learning_rate: 0.0016\n",
            "Epoch 4/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3124 - loss: 2.1478\n",
            "Epoch 4: val_loss improved from 2.09504 to 1.96078, saving model to ../output/experiments/trial_41_w64_s16_w64_s16/models/lstm_v2_hybrid_concatenate_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.3124 - loss: 2.1478 - val_accuracy: 0.3476 - val_loss: 1.9608 - learning_rate: 0.0016\n",
            "Epoch 5/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.3342 - loss: 2.0578\n",
            "Epoch 5: val_loss did not improve from 1.96078\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.3342 - loss: 2.0579 - val_accuracy: 0.3369 - val_loss: 1.9757 - learning_rate: 0.0016\n",
            "Epoch 6/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.3415 - loss: 1.9863\n",
            "Epoch 6: val_loss improved from 1.96078 to 1.87022, saving model to ../output/experiments/trial_41_w64_s16_w64_s16/models/lstm_v2_hybrid_concatenate_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.3415 - loss: 1.9864 - val_accuracy: 0.3770 - val_loss: 1.8702 - learning_rate: 0.0016\n",
            "Epoch 7/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.3680 - loss: 1.9558\n",
            "Epoch 7: val_loss improved from 1.87022 to 1.83350, saving model to ../output/experiments/trial_41_w64_s16_w64_s16/models/lstm_v2_hybrid_concatenate_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.3679 - loss: 1.9558 - val_accuracy: 0.3686 - val_loss: 1.8335 - learning_rate: 0.0016\n",
            "Epoch 8/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.3918 - loss: 1.8708\n",
            "Epoch 8: val_loss improved from 1.83350 to 1.82645, saving model to ../output/experiments/trial_41_w64_s16_w64_s16/models/lstm_v2_hybrid_concatenate_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.3918 - loss: 1.8709 - val_accuracy: 0.3836 - val_loss: 1.8265 - learning_rate: 0.0016\n",
            "Epoch 9/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3863 - loss: 1.8584\n",
            "Epoch 9: val_loss improved from 1.82645 to 1.77173, saving model to ../output/experiments/trial_41_w64_s16_w64_s16/models/lstm_v2_hybrid_concatenate_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 42ms/step - accuracy: 0.3863 - loss: 1.8583 - val_accuracy: 0.4018 - val_loss: 1.7717 - learning_rate: 0.0016\n",
            "Epoch 10/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4004 - loss: 1.7999\n",
            "Epoch 10: val_loss did not improve from 1.77173\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.4004 - loss: 1.8000 - val_accuracy: 0.4074 - val_loss: 1.8014 - learning_rate: 0.0016\n",
            "Epoch 11/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4156 - loss: 1.7697\n",
            "Epoch 11: val_loss improved from 1.77173 to 1.73372, saving model to ../output/experiments/trial_41_w64_s16_w64_s16/models/lstm_v2_hybrid_concatenate_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.4156 - loss: 1.7698 - val_accuracy: 0.4111 - val_loss: 1.7337 - learning_rate: 0.0016\n",
            "Epoch 12/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4227 - loss: 1.7356\n",
            "Epoch 12: val_loss did not improve from 1.73372\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.4226 - loss: 1.7357 - val_accuracy: 0.4200 - val_loss: 1.7338 - learning_rate: 0.0016\n",
            "Epoch 13/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4169 - loss: 1.7431\n",
            "Epoch 13: val_loss improved from 1.73372 to 1.71177, saving model to ../output/experiments/trial_41_w64_s16_w64_s16/models/lstm_v2_hybrid_concatenate_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.4169 - loss: 1.7430 - val_accuracy: 0.4181 - val_loss: 1.7118 - learning_rate: 0.0016\n",
            "Epoch 14/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4258 - loss: 1.6973\n",
            "Epoch 14: val_loss improved from 1.71177 to 1.70412, saving model to ../output/experiments/trial_41_w64_s16_w64_s16/models/lstm_v2_hybrid_concatenate_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.4258 - loss: 1.6973 - val_accuracy: 0.4200 - val_loss: 1.7041 - learning_rate: 0.0016\n",
            "Epoch 15/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4440 - loss: 1.6916\n",
            "Epoch 15: val_loss improved from 1.70412 to 1.65126, saving model to ../output/experiments/trial_41_w64_s16_w64_s16/models/lstm_v2_hybrid_concatenate_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.4439 - loss: 1.6915 - val_accuracy: 0.4372 - val_loss: 1.6513 - learning_rate: 0.0016\n",
            "Epoch 16/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4484 - loss: 1.6049\n",
            "Epoch 16: val_loss did not improve from 1.65126\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.4484 - loss: 1.6050 - val_accuracy: 0.4386 - val_loss: 1.6640 - learning_rate: 0.0016\n",
            "Epoch 17/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4651 - loss: 1.6372\n",
            "Epoch 17: val_loss did not improve from 1.65126\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.4651 - loss: 1.6373 - val_accuracy: 0.4372 - val_loss: 1.6626 - learning_rate: 0.0016\n",
            "Epoch 18/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4566 - loss: 1.6452\n",
            "Epoch 18: val_loss improved from 1.65126 to 1.64549, saving model to ../output/experiments/trial_41_w64_s16_w64_s16/models/lstm_v2_hybrid_concatenate_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.4566 - loss: 1.6451 - val_accuracy: 0.4372 - val_loss: 1.6455 - learning_rate: 0.0016\n",
            "Epoch 19/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4750 - loss: 1.5742\n",
            "Epoch 19: val_loss did not improve from 1.64549\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.4750 - loss: 1.5742 - val_accuracy: 0.4489 - val_loss: 1.6881 - learning_rate: 0.0016\n",
            "Epoch 20/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4706 - loss: 1.5919\n",
            "Epoch 20: val_loss did not improve from 1.64549\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.4707 - loss: 1.5919 - val_accuracy: 0.4526 - val_loss: 1.6826 - learning_rate: 0.0016\n",
            "Epoch 21/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4678 - loss: 1.5814\n",
            "Epoch 21: val_loss did not improve from 1.64549\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.4678 - loss: 1.5815 - val_accuracy: 0.4666 - val_loss: 1.6656 - learning_rate: 0.0016\n",
            "Epoch 22/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4839 - loss: 1.5607\n",
            "Epoch 22: val_loss did not improve from 1.64549\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.4839 - loss: 1.5608 - val_accuracy: 0.4452 - val_loss: 1.7001 - learning_rate: 0.0016\n",
            "Epoch 23/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4899 - loss: 1.5292\n",
            "Epoch 23: val_loss did not improve from 1.64549\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.4899 - loss: 1.5292 - val_accuracy: 0.4648 - val_loss: 1.6532 - learning_rate: 0.0016\n",
            "Epoch 24/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4994 - loss: 1.5278\n",
            "Epoch 24: val_loss improved from 1.64549 to 1.64091, saving model to ../output/experiments/trial_41_w64_s16_w64_s16/models/lstm_v2_hybrid_concatenate_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.4993 - loss: 1.5280 - val_accuracy: 0.4704 - val_loss: 1.6409 - learning_rate: 0.0016\n",
            "Epoch 25/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4948 - loss: 1.5082\n",
            "Epoch 25: val_loss improved from 1.64091 to 1.61789, saving model to ../output/experiments/trial_41_w64_s16_w64_s16/models/lstm_v2_hybrid_concatenate_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.4947 - loss: 1.5083 - val_accuracy: 0.4568 - val_loss: 1.6179 - learning_rate: 0.0016\n",
            "Epoch 26/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5029 - loss: 1.5012\n",
            "Epoch 26: val_loss did not improve from 1.61789\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5029 - loss: 1.5013 - val_accuracy: 0.4554 - val_loss: 1.6603 - learning_rate: 0.0016\n",
            "Epoch 27/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4831 - loss: 1.5144\n",
            "Epoch 27: val_loss did not improve from 1.61789\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.4831 - loss: 1.5144 - val_accuracy: 0.4746 - val_loss: 1.6687 - learning_rate: 0.0016\n",
            "Epoch 28/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5058 - loss: 1.4728\n",
            "Epoch 28: val_loss did not improve from 1.61789\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5058 - loss: 1.4728 - val_accuracy: 0.4662 - val_loss: 1.6345 - learning_rate: 0.0016\n",
            "Epoch 29/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5101 - loss: 1.4851\n",
            "Epoch 29: val_loss improved from 1.61789 to 1.60476, saving model to ../output/experiments/trial_41_w64_s16_w64_s16/models/lstm_v2_hybrid_concatenate_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5101 - loss: 1.4850 - val_accuracy: 0.4830 - val_loss: 1.6048 - learning_rate: 0.0016\n",
            "Epoch 30/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5215 - loss: 1.4225\n",
            "Epoch 30: val_loss did not improve from 1.60476\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5214 - loss: 1.4226 - val_accuracy: 0.4512 - val_loss: 1.6560 - learning_rate: 0.0016\n",
            "Epoch 31/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5240 - loss: 1.4257\n",
            "Epoch 31: val_loss did not improve from 1.60476\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.5240 - loss: 1.4257 - val_accuracy: 0.4797 - val_loss: 1.6147 - learning_rate: 0.0016\n",
            "Epoch 32/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5329 - loss: 1.4054\n",
            "Epoch 32: val_loss did not improve from 1.60476\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5328 - loss: 1.4056 - val_accuracy: 0.4676 - val_loss: 1.6349 - learning_rate: 0.0016\n",
            "Epoch 33/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5218 - loss: 1.4102\n",
            "Epoch 33: val_loss did not improve from 1.60476\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5218 - loss: 1.4103 - val_accuracy: 0.4746 - val_loss: 1.6329 - learning_rate: 0.0016\n",
            "Epoch 34/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5126 - loss: 1.4391\n",
            "Epoch 34: val_loss improved from 1.60476 to 1.57745, saving model to ../output/experiments/trial_41_w64_s16_w64_s16/models/lstm_v2_hybrid_concatenate_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5126 - loss: 1.4391 - val_accuracy: 0.5012 - val_loss: 1.5774 - learning_rate: 0.0016\n",
            "Epoch 35/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5307 - loss: 1.4034\n",
            "Epoch 35: val_loss did not improve from 1.57745\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.5307 - loss: 1.4034 - val_accuracy: 0.4942 - val_loss: 1.6025 - learning_rate: 0.0016\n",
            "Epoch 36/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5277 - loss: 1.4047\n",
            "Epoch 36: val_loss did not improve from 1.57745\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.5277 - loss: 1.4047 - val_accuracy: 0.4872 - val_loss: 1.6040 - learning_rate: 0.0016\n",
            "Epoch 37/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5377 - loss: 1.3688\n",
            "Epoch 37: val_loss did not improve from 1.57745\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.5377 - loss: 1.3689 - val_accuracy: 0.4886 - val_loss: 1.5958 - learning_rate: 0.0016\n",
            "Epoch 38/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5405 - loss: 1.3584\n",
            "Epoch 38: val_loss did not improve from 1.57745\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5406 - loss: 1.3584 - val_accuracy: 0.4881 - val_loss: 1.5823 - learning_rate: 0.0016\n",
            "Epoch 39/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5449 - loss: 1.4016\n",
            "Epoch 39: val_loss did not improve from 1.57745\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.5448 - loss: 1.4017 - val_accuracy: 0.4844 - val_loss: 1.6121 - learning_rate: 0.0016\n",
            "Epoch 40/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5387 - loss: 1.4018\n",
            "Epoch 40: val_loss did not improve from 1.57745\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5387 - loss: 1.4017 - val_accuracy: 0.5049 - val_loss: 1.6111 - learning_rate: 0.0016\n",
            "Epoch 41/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5575 - loss: 1.3462\n",
            "Epoch 41: val_loss did not improve from 1.57745\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.5575 - loss: 1.3463 - val_accuracy: 0.5049 - val_loss: 1.6211 - learning_rate: 0.0016\n",
            "Epoch 42/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5568 - loss: 1.3547\n",
            "Epoch 42: val_loss did not improve from 1.57745\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.5567 - loss: 1.3549 - val_accuracy: 0.4839 - val_loss: 1.6891 - learning_rate: 0.0016\n",
            "Epoch 43/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5553 - loss: 1.3496\n",
            "Epoch 43: val_loss did not improve from 1.57745\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.5553 - loss: 1.3495 - val_accuracy: 0.4918 - val_loss: 1.6661 - learning_rate: 0.0016\n",
            "Epoch 44/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5459 - loss: 1.3530\n",
            "Epoch 44: val_loss did not improve from 1.57745\n",
            "\n",
            "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0008017672225832939.\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.5459 - loss: 1.3531 - val_accuracy: 0.5077 - val_loss: 1.6529 - learning_rate: 0.0016\n",
            "Epoch 45/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5671 - loss: 1.2852\n",
            "Epoch 45: val_loss did not improve from 1.57745\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.5671 - loss: 1.2851 - val_accuracy: 0.5292 - val_loss: 1.6230 - learning_rate: 8.0177e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5905 - loss: 1.2189\n",
            "Epoch 46: val_loss did not improve from 1.57745\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.5905 - loss: 1.2189 - val_accuracy: 0.5212 - val_loss: 1.5901 - learning_rate: 8.0177e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6033 - loss: 1.1973\n",
            "Epoch 47: val_loss did not improve from 1.57745\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.6033 - loss: 1.1973 - val_accuracy: 0.5198 - val_loss: 1.6018 - learning_rate: 8.0177e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6081 - loss: 1.1494\n",
            "Epoch 48: val_loss did not improve from 1.57745\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.6080 - loss: 1.1496 - val_accuracy: 0.5180 - val_loss: 1.5866 - learning_rate: 8.0177e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5975 - loss: 1.1773\n",
            "Epoch 49: val_loss did not improve from 1.57745\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.5975 - loss: 1.1774 - val_accuracy: 0.5240 - val_loss: 1.6093 - learning_rate: 8.0177e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6011 - loss: 1.1820\n",
            "Epoch 50: val_loss improved from 1.57745 to 1.54914, saving model to ../output/experiments/trial_41_w64_s16_w64_s16/models/lstm_v2_hybrid_concatenate_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.6011 - loss: 1.1819 - val_accuracy: 0.5474 - val_loss: 1.5491 - learning_rate: 8.0177e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6210 - loss: 1.1297\n",
            "Epoch 51: val_loss did not improve from 1.54914\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.6209 - loss: 1.1298 - val_accuracy: 0.5287 - val_loss: 1.6168 - learning_rate: 8.0177e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6148 - loss: 1.1446\n",
            "Epoch 52: val_loss did not improve from 1.54914\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.6149 - loss: 1.1446 - val_accuracy: 0.5306 - val_loss: 1.5840 - learning_rate: 8.0177e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6231 - loss: 1.1036\n",
            "Epoch 53: val_loss did not improve from 1.54914\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.6230 - loss: 1.1038 - val_accuracy: 0.5292 - val_loss: 1.5856 - learning_rate: 8.0177e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6175 - loss: 1.1297\n",
            "Epoch 54: val_loss did not improve from 1.54914\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.6175 - loss: 1.1297 - val_accuracy: 0.5455 - val_loss: 1.5788 - learning_rate: 8.0177e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6217 - loss: 1.1013\n",
            "Epoch 55: val_loss did not improve from 1.54914\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.6217 - loss: 1.1014 - val_accuracy: 0.5511 - val_loss: 1.5598 - learning_rate: 8.0177e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6289 - loss: 1.0939\n",
            "Epoch 56: val_loss did not improve from 1.54914\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.6288 - loss: 1.0940 - val_accuracy: 0.5394 - val_loss: 1.5607 - learning_rate: 8.0177e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6221 - loss: 1.0962\n",
            "Epoch 57: val_loss did not improve from 1.54914\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.6221 - loss: 1.0963 - val_accuracy: 0.5464 - val_loss: 1.6033 - learning_rate: 8.0177e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6259 - loss: 1.0858\n",
            "Epoch 58: val_loss did not improve from 1.54914\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.6258 - loss: 1.0860 - val_accuracy: 0.5427 - val_loss: 1.6157 - learning_rate: 8.0177e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6478 - loss: 1.0976\n",
            "Epoch 59: val_loss did not improve from 1.54914\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.6477 - loss: 1.0976 - val_accuracy: 0.5492 - val_loss: 1.5784 - learning_rate: 8.0177e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6391 - loss: 1.0581\n",
            "Epoch 60: val_loss did not improve from 1.54914\n",
            "\n",
            "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.00040088361129164696.\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.6391 - loss: 1.0582 - val_accuracy: 0.5525 - val_loss: 1.6090 - learning_rate: 8.0177e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6532 - loss: 1.0597\n",
            "Epoch 61: val_loss did not improve from 1.54914\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.6532 - loss: 1.0596 - val_accuracy: 0.5404 - val_loss: 1.6116 - learning_rate: 4.0088e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6683 - loss: 1.0096\n",
            "Epoch 62: val_loss did not improve from 1.54914\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.6682 - loss: 1.0096 - val_accuracy: 0.5506 - val_loss: 1.6355 - learning_rate: 4.0088e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6537 - loss: 1.0219\n",
            "Epoch 63: val_loss did not improve from 1.54914\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.6538 - loss: 1.0218 - val_accuracy: 0.5562 - val_loss: 1.6270 - learning_rate: 4.0088e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6722 - loss: 0.9884\n",
            "Epoch 64: val_loss did not improve from 1.54914\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.6722 - loss: 0.9885 - val_accuracy: 0.5740 - val_loss: 1.5824 - learning_rate: 4.0088e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6609 - loss: 0.9991\n",
            "Epoch 65: val_loss did not improve from 1.54914\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.6609 - loss: 0.9990 - val_accuracy: 0.5637 - val_loss: 1.6277 - learning_rate: 4.0088e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6642 - loss: 0.9791\n",
            "Epoch 66: val_loss did not improve from 1.54914\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.6642 - loss: 0.9790 - val_accuracy: 0.5511 - val_loss: 1.6243 - learning_rate: 4.0088e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6827 - loss: 0.9464\n",
            "Epoch 67: val_loss did not improve from 1.54914\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.6826 - loss: 0.9465 - val_accuracy: 0.5553 - val_loss: 1.6659 - learning_rate: 4.0088e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6723 - loss: 0.9604\n",
            "Epoch 68: val_loss did not improve from 1.54914\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.6723 - loss: 0.9604 - val_accuracy: 0.5530 - val_loss: 1.6587 - learning_rate: 4.0088e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6912 - loss: 0.9311\n",
            "Epoch 69: val_loss did not improve from 1.54914\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.6911 - loss: 0.9311 - val_accuracy: 0.5539 - val_loss: 1.6577 - learning_rate: 4.0088e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6807 - loss: 0.9461\n",
            "Epoch 70: val_loss did not improve from 1.54914\n",
            "\n",
            "Epoch 70: ReduceLROnPlateau reducing learning rate to 0.00020044180564582348.\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.6807 - loss: 0.9460 - val_accuracy: 0.5590 - val_loss: 1.6541 - learning_rate: 4.0088e-04\n",
            "Epoch 70: early stopping\n",
            "Restoring model weights from the end of the best epoch: 50.\n",
            "å­¦ç¿’å®Œäº†ï¼å­¦ç¿’æ™‚é–“: 762.69ç§’\n",
            "æœ€è‰¯æ¤œè¨¼Loss: 1.5491\n",
            "æœ€è‰¯æ¤œè¨¼Accuracy: 0.5740\n",
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ä¸­...\n",
            "ãƒ†ã‚¹ãƒˆLoss: 1.5738\n",
            "ãƒ†ã‚¹ãƒˆAccuracy: 0.5495\n",
            "F1-Score (macro): 0.4820\n",
            "F1-Score (weighted): 0.5242\n",
            "çµæœä¿å­˜ä¸­...\n",
            "å­¦ç¿’å±¥æ­´ä¿å­˜å®Œäº†: ../output/experiments/trial_41_w64_s16_w64_s16/results/training_history_concatenate.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-08 22:29:26,751] Trial 41 finished with value: 0.7460175244635522 and parameters: {'lstm_units_1': 64, 'lstm_units_2': 56, 'dense_units': 48, 'demographics_dense_units': 28, 'fusion_dense_units': 48, 'dropout_rate': 0.45000000000000007, 'dense_dropout_rate': 0.25, 'learning_rate': 0.001603534389644652, 'batch_size': 32, 'fusion_type': 'concatenate'}. Best is trial 34 with value: 0.8021217206997858.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "çµæœä¿å­˜å®Œäº†: ../output/experiments/trial_41_w64_s16_w64_s16/results\n",
            "âœ… Trial 41: CMI=0.7460, Binary F1=0.9462, Fusion=concatenate\n",
            "\n",
            "ğŸ” Trial 42 - w64_s16\n",
            "Mixed precision enabled for better GPU performance\n",
            "GPUåˆ©ç”¨å¯èƒ½: 1å°\n",
            "ä½¿ç”¨GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
            "LSTM v2å­¦ç¿’ç’°å¢ƒåˆæœŸåŒ–å®Œäº†\n",
            "å®Ÿé¨“å: trial_42_w64_s16\n",
            "ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®š: w64_s16\n",
            "å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: ../output/experiments/trial_42_w64_s16_w64_s16\n",
            "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿: ../output/experiments/lstm_v2_w64_s16/preprocessed\n",
            "GPUåˆ©ç”¨å¯èƒ½: True\n",
            "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...\n",
            "æœ€é©åŒ–ã•ã‚ŒãŸdemographicsç‰¹å¾´é‡ã‚’ä½¿ç”¨ã—ã¾ã™\n",
            "æœ€é©åŒ–ã•ã‚ŒãŸdemographicså½¢çŠ¶: (13393, 18)\n",
            "ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†:\n",
            "  ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿: (13393, 64, 332)\n",
            "  Demographics: (13393, 18)\n",
            "  ãƒ©ãƒ™ãƒ«: (13393,)\n",
            "  ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹ (èåˆæ–¹å¼: attention)...\n",
            "ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ä¸­...\n",
            "ãƒ†ã‚¹ãƒˆã‚µã‚¤ã‚º: 0.2\n",
            "æ¤œè¨¼ã‚µã‚¤ã‚º: 0.2\n",
            "ãƒ‡ãƒ¼ã‚¿åˆ†å‰²å®Œäº†:\n",
            "  è¨“ç·´ - ã‚»ãƒ³ã‚µãƒ¼: (8571, 64, 332), Demographics: (8571, 18), ãƒ©ãƒ™ãƒ«: (8571,)\n",
            "  æ¤œè¨¼ - ã‚»ãƒ³ã‚µãƒ¼: (2143, 64, 332), Demographics: (2143, 18), ãƒ©ãƒ™ãƒ«: (2143,)\n",
            "  ãƒ†ã‚¹ãƒˆ - ã‚»ãƒ³ã‚µãƒ¼: (2679, 64, 332), Demographics: (2679, 18), ãƒ©ãƒ™ãƒ«: (2679,)\n",
            "å…¥åŠ›å½¢çŠ¶:\n",
            "  ã‚»ãƒ³ã‚µãƒ¼: (64, 332)\n",
            "  Demographics: (18,)\n",
            "  ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "GPUä¸Šã§ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆãƒ»å­¦ç¿’ã—ã¾ã™\n",
            "Mixed precision enabled for better GPU performance\n",
            "GPUåˆ©ç”¨å¯èƒ½: 1å°\n",
            "ä½¿ç”¨GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
            "LSTM v2ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†\n",
            "ã‚»ãƒ³ã‚µãƒ¼å…¥åŠ›å½¢çŠ¶: (64, 332)\n",
            "Demographicså…¥åŠ›å½¢çŠ¶: (18,)\n",
            "ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "èåˆæ–¹å¼: attention\n",
            "GPUåˆ©ç”¨å¯èƒ½: True\n",
            "LSTM v2ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ä¸­...\n",
            "ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰å®Œäº†\n",
            "ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 140,786\n",
            "\n",
            "=== ãƒ¢ãƒ‡ãƒ«ã‚µãƒãƒªãƒ¼ ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"lstm_v2_hybrid\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"lstm_v2_hybrid\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ sensor_input        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">332</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">101,632</span> â”‚ sensor_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_1           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_1      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ lstm_bn_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_input  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">27,104</span> â”‚ lstm_dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">608</span> â”‚ demographics_inpâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_2           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> â”‚ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_2      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ lstm_bn_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dense        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,192</span> â”‚ lstm_dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dropout      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sensor_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_weights   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,848</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attended_sensor     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sensor_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          â”‚                   â”‚            â”‚ attention_weightâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_projeâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,848</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_fusion    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ attended_sensor[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚                   â”‚            â”‚ demographics_proâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dense        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,280</span> â”‚ attention_fusionâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dropout      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ fusion_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">738</span> â”‚ fusion_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ sensor_input        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m332\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚    \u001b[38;5;34m101,632\u001b[0m â”‚ sensor_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_1           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚        \u001b[38;5;34m256\u001b[0m â”‚ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_1      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ lstm_bn_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_input  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        â”‚     \u001b[38;5;34m27,104\u001b[0m â”‚ lstm_dropout_1[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚        \u001b[38;5;34m608\u001b[0m â”‚ demographics_inpâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_2           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        â”‚        \u001b[38;5;34m224\u001b[0m â”‚ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_2      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ lstm_bn_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚      \u001b[38;5;34m1,056\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dense        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        â”‚      \u001b[38;5;34m3,192\u001b[0m â”‚ lstm_dropout_2[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dropout      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sensor_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_weights   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        â”‚      \u001b[38;5;34m1,848\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attended_sensor     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sensor_dropout[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mMultiply\u001b[0m)          â”‚                   â”‚            â”‚ attention_weightâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_projeâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        â”‚      \u001b[38;5;34m1,848\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_fusion    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ attended_sensor[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚                   â”‚            â”‚ demographics_proâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dense        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)        â”‚      \u001b[38;5;34m2,280\u001b[0m â”‚ attention_fusionâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dropout      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ fusion_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (\u001b[38;5;33mDense\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        â”‚        \u001b[38;5;34m738\u001b[0m â”‚ fusion_dropout[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">140,786</span> (549.95 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m140,786\u001b[0m (549.95 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">140,546</span> (549.01 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m140,546\u001b[0m (549.01 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> (960.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m240\u001b[0m (960.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹...\n",
            "ã‚»ãƒ³ã‚µãƒ¼è¨“ç·´ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (8571, 64, 332)\n",
            "Demographicsè¨“ç·´ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (8571, 18)\n",
            "ã‚»ãƒ³ã‚µãƒ¼æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (2143, 64, 332)\n",
            "Demographicsæ¤œè¨¼ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (2143, 18)\n",
            "è¨“ç·´ãƒ©ãƒ™ãƒ«å½¢çŠ¶: (8571,)\n",
            "æ¤œè¨¼ãƒ©ãƒ™ãƒ«å½¢çŠ¶: (2143,)\n",
            "Epoch 1/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.1417 - loss: 2.7544\n",
            "Epoch 1: val_loss improved from inf to 2.41348, saving model to ../output/experiments/trial_42_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 45ms/step - accuracy: 0.1419 - loss: 2.7539 - val_accuracy: 0.2711 - val_loss: 2.4135 - learning_rate: 0.0050\n",
            "Epoch 2/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.2531 - loss: 2.4175\n",
            "Epoch 2: val_loss improved from 2.41348 to 2.37465, saving model to ../output/experiments/trial_42_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.2531 - loss: 2.4175 - val_accuracy: 0.2725 - val_loss: 2.3746 - learning_rate: 0.0050\n",
            "Epoch 3/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.2873 - loss: 2.3577\n",
            "Epoch 3: val_loss improved from 2.37465 to 2.26568, saving model to ../output/experiments/trial_42_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.2873 - loss: 2.3578 - val_accuracy: 0.3206 - val_loss: 2.2657 - learning_rate: 0.0050\n",
            "Epoch 4/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3177 - loss: 2.2774\n",
            "Epoch 4: val_loss did not improve from 2.26568\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.3177 - loss: 2.2775 - val_accuracy: 0.3206 - val_loss: 2.2781 - learning_rate: 0.0050\n",
            "Epoch 5/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3263 - loss: 2.2519\n",
            "Epoch 5: val_loss improved from 2.26568 to 2.19882, saving model to ../output/experiments/trial_42_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.3263 - loss: 2.2520 - val_accuracy: 0.3434 - val_loss: 2.1988 - learning_rate: 0.0050\n",
            "Epoch 6/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.3403 - loss: 2.1964\n",
            "Epoch 6: val_loss did not improve from 2.19882\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.3403 - loss: 2.1966 - val_accuracy: 0.3336 - val_loss: 2.2371 - learning_rate: 0.0050\n",
            "Epoch 7/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3554 - loss: 2.1994\n",
            "Epoch 7: val_loss did not improve from 2.19882\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.3554 - loss: 2.1995 - val_accuracy: 0.3514 - val_loss: 2.2155 - learning_rate: 0.0050\n",
            "Epoch 8/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3679 - loss: 2.1954\n",
            "Epoch 8: val_loss did not improve from 2.19882\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.3679 - loss: 2.1954 - val_accuracy: 0.3602 - val_loss: 2.2386 - learning_rate: 0.0050\n",
            "Epoch 9/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3784 - loss: 2.1579\n",
            "Epoch 9: val_loss did not improve from 2.19882\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.3784 - loss: 2.1580 - val_accuracy: 0.3691 - val_loss: 2.2002 - learning_rate: 0.0050\n",
            "Epoch 10/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3855 - loss: 2.1472\n",
            "Epoch 10: val_loss improved from 2.19882 to 2.17101, saving model to ../output/experiments/trial_42_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.3855 - loss: 2.1473 - val_accuracy: 0.3840 - val_loss: 2.1710 - learning_rate: 0.0050\n",
            "Epoch 11/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4003 - loss: 2.1102\n",
            "Epoch 11: val_loss improved from 2.17101 to 2.12399, saving model to ../output/experiments/trial_42_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.4002 - loss: 2.1104 - val_accuracy: 0.4125 - val_loss: 2.1240 - learning_rate: 0.0050\n",
            "Epoch 12/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4077 - loss: 2.1172\n",
            "Epoch 12: val_loss improved from 2.12399 to 2.08670, saving model to ../output/experiments/trial_42_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.4077 - loss: 2.1172 - val_accuracy: 0.4055 - val_loss: 2.0867 - learning_rate: 0.0050\n",
            "Epoch 13/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4108 - loss: 2.0816\n",
            "Epoch 13: val_loss did not improve from 2.08670\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4108 - loss: 2.0817 - val_accuracy: 0.3943 - val_loss: 2.1260 - learning_rate: 0.0050\n",
            "Epoch 14/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4186 - loss: 2.0825\n",
            "Epoch 14: val_loss improved from 2.08670 to 2.07187, saving model to ../output/experiments/trial_42_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.4186 - loss: 2.0825 - val_accuracy: 0.3999 - val_loss: 2.0719 - learning_rate: 0.0050\n",
            "Epoch 15/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4422 - loss: 2.0071\n",
            "Epoch 15: val_loss did not improve from 2.07187\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.4422 - loss: 2.0073 - val_accuracy: 0.4083 - val_loss: 2.1063 - learning_rate: 0.0050\n",
            "Epoch 16/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4357 - loss: 2.0569\n",
            "Epoch 16: val_loss improved from 2.07187 to 2.06265, saving model to ../output/experiments/trial_42_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.4358 - loss: 2.0569 - val_accuracy: 0.4130 - val_loss: 2.0626 - learning_rate: 0.0050\n",
            "Epoch 17/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4379 - loss: 2.0250\n",
            "Epoch 17: val_loss improved from 2.06265 to 2.05228, saving model to ../output/experiments/trial_42_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.4379 - loss: 2.0251 - val_accuracy: 0.4162 - val_loss: 2.0523 - learning_rate: 0.0050\n",
            "Epoch 18/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4586 - loss: 1.9974\n",
            "Epoch 18: val_loss did not improve from 2.05228\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.4585 - loss: 1.9975 - val_accuracy: 0.4167 - val_loss: 2.0895 - learning_rate: 0.0050\n",
            "Epoch 19/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4673 - loss: 1.9931\n",
            "Epoch 19: val_loss did not improve from 2.05228\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.4672 - loss: 1.9932 - val_accuracy: 0.4274 - val_loss: 2.0685 - learning_rate: 0.0050\n",
            "Epoch 20/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4655 - loss: 1.9611\n",
            "Epoch 20: val_loss improved from 2.05228 to 2.02111, saving model to ../output/experiments/trial_42_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.4655 - loss: 1.9611 - val_accuracy: 0.4386 - val_loss: 2.0211 - learning_rate: 0.0050\n",
            "Epoch 21/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4566 - loss: 1.9921\n",
            "Epoch 21: val_loss improved from 2.02111 to 2.00883, saving model to ../output/experiments/trial_42_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.4566 - loss: 1.9921 - val_accuracy: 0.4106 - val_loss: 2.0088 - learning_rate: 0.0050\n",
            "Epoch 22/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4706 - loss: 1.9305\n",
            "Epoch 22: val_loss improved from 2.00883 to 1.97928, saving model to ../output/experiments/trial_42_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.4705 - loss: 1.9306 - val_accuracy: 0.4494 - val_loss: 1.9793 - learning_rate: 0.0050\n",
            "Epoch 23/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4724 - loss: 1.9265\n",
            "Epoch 23: val_loss improved from 1.97928 to 1.96978, saving model to ../output/experiments/trial_42_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.4725 - loss: 1.9265 - val_accuracy: 0.4643 - val_loss: 1.9698 - learning_rate: 0.0050\n",
            "Epoch 24/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4862 - loss: 1.8884\n",
            "Epoch 24: val_loss did not improve from 1.96978\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4862 - loss: 1.8884 - val_accuracy: 0.4536 - val_loss: 1.9827 - learning_rate: 0.0050\n",
            "Epoch 25/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4962 - loss: 1.8819\n",
            "Epoch 25: val_loss did not improve from 1.96978\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.4962 - loss: 1.8819 - val_accuracy: 0.4550 - val_loss: 1.9998 - learning_rate: 0.0050\n",
            "Epoch 26/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4956 - loss: 1.8654\n",
            "Epoch 26: val_loss improved from 1.96978 to 1.96864, saving model to ../output/experiments/trial_42_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.4955 - loss: 1.8657 - val_accuracy: 0.4568 - val_loss: 1.9686 - learning_rate: 0.0050\n",
            "Epoch 27/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4930 - loss: 1.8741\n",
            "Epoch 27: val_loss did not improve from 1.96864\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.4929 - loss: 1.8744 - val_accuracy: 0.4452 - val_loss: 2.0239 - learning_rate: 0.0050\n",
            "Epoch 28/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4880 - loss: 1.8931\n",
            "Epoch 28: val_loss did not improve from 1.96864\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.4881 - loss: 1.8931 - val_accuracy: 0.4601 - val_loss: 1.9841 - learning_rate: 0.0050\n",
            "Epoch 29/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5081 - loss: 1.8666\n",
            "Epoch 29: val_loss did not improve from 1.96864\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.5080 - loss: 1.8668 - val_accuracy: 0.4606 - val_loss: 2.0070 - learning_rate: 0.0050\n",
            "Epoch 30/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4983 - loss: 1.8990\n",
            "Epoch 30: val_loss did not improve from 1.96864\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.4982 - loss: 1.8991 - val_accuracy: 0.4732 - val_loss: 1.9722 - learning_rate: 0.0050\n",
            "Epoch 31/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5130 - loss: 1.8372\n",
            "Epoch 31: val_loss improved from 1.96864 to 1.95311, saving model to ../output/experiments/trial_42_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.5128 - loss: 1.8375 - val_accuracy: 0.4704 - val_loss: 1.9531 - learning_rate: 0.0050\n",
            "Epoch 32/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5132 - loss: 1.8440\n",
            "Epoch 32: val_loss improved from 1.95311 to 1.93648, saving model to ../output/experiments/trial_42_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.5131 - loss: 1.8441 - val_accuracy: 0.4676 - val_loss: 1.9365 - learning_rate: 0.0050\n",
            "Epoch 33/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5242 - loss: 1.7885\n",
            "Epoch 33: val_loss did not improve from 1.93648\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.5241 - loss: 1.7887 - val_accuracy: 0.4690 - val_loss: 1.9692 - learning_rate: 0.0050\n",
            "Epoch 34/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5245 - loss: 1.8119\n",
            "Epoch 34: val_loss did not improve from 1.93648\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.5244 - loss: 1.8120 - val_accuracy: 0.4578 - val_loss: 2.0084 - learning_rate: 0.0050\n",
            "Epoch 35/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5094 - loss: 1.8180\n",
            "Epoch 35: val_loss did not improve from 1.93648\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5094 - loss: 1.8181 - val_accuracy: 0.4442 - val_loss: 2.0102 - learning_rate: 0.0050\n",
            "Epoch 36/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5123 - loss: 1.8322\n",
            "Epoch 36: val_loss did not improve from 1.93648\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.5123 - loss: 1.8320 - val_accuracy: 0.4844 - val_loss: 1.9536 - learning_rate: 0.0050\n",
            "Epoch 37/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5365 - loss: 1.7648\n",
            "Epoch 37: val_loss improved from 1.93648 to 1.93132, saving model to ../output/experiments/trial_42_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5365 - loss: 1.7649 - val_accuracy: 0.4811 - val_loss: 1.9313 - learning_rate: 0.0050\n",
            "Epoch 38/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5378 - loss: 1.7800\n",
            "Epoch 38: val_loss improved from 1.93132 to 1.90571, saving model to ../output/experiments/trial_42_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.5378 - loss: 1.7801 - val_accuracy: 0.4872 - val_loss: 1.9057 - learning_rate: 0.0050\n",
            "Epoch 39/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5355 - loss: 1.7658\n",
            "Epoch 39: val_loss did not improve from 1.90571\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.5354 - loss: 1.7659 - val_accuracy: 0.4666 - val_loss: 1.9935 - learning_rate: 0.0050\n",
            "Epoch 40/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5428 - loss: 1.8048\n",
            "Epoch 40: val_loss did not improve from 1.90571\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5428 - loss: 1.8049 - val_accuracy: 0.4662 - val_loss: 2.0050 - learning_rate: 0.0050\n",
            "Epoch 41/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5466 - loss: 1.7454\n",
            "Epoch 41: val_loss did not improve from 1.90571\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5465 - loss: 1.7456 - val_accuracy: 0.4802 - val_loss: 1.9145 - learning_rate: 0.0050\n",
            "Epoch 42/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5203 - loss: 1.7910\n",
            "Epoch 42: val_loss improved from 1.90571 to 1.87389, saving model to ../output/experiments/trial_42_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5203 - loss: 1.7912 - val_accuracy: 0.5016 - val_loss: 1.8739 - learning_rate: 0.0050\n",
            "Epoch 43/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5431 - loss: 1.7449\n",
            "Epoch 43: val_loss did not improve from 1.87389\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.5430 - loss: 1.7451 - val_accuracy: 0.4909 - val_loss: 1.8833 - learning_rate: 0.0050\n",
            "Epoch 44/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5465 - loss: 1.7528\n",
            "Epoch 44: val_loss did not improve from 1.87389\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.5464 - loss: 1.7530 - val_accuracy: 0.4839 - val_loss: 1.9529 - learning_rate: 0.0050\n",
            "Epoch 45/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5472 - loss: 1.7612\n",
            "Epoch 45: val_loss did not improve from 1.87389\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5472 - loss: 1.7612 - val_accuracy: 0.4918 - val_loss: 1.9162 - learning_rate: 0.0050\n",
            "Epoch 46/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5419 - loss: 1.7590\n",
            "Epoch 46: val_loss did not improve from 1.87389\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5419 - loss: 1.7590 - val_accuracy: 0.4788 - val_loss: 1.9243 - learning_rate: 0.0050\n",
            "Epoch 47/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5444 - loss: 1.7576\n",
            "Epoch 47: val_loss did not improve from 1.87389\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5444 - loss: 1.7576 - val_accuracy: 0.4886 - val_loss: 1.9123 - learning_rate: 0.0050\n",
            "Epoch 48/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5540 - loss: 1.6982\n",
            "Epoch 48: val_loss improved from 1.87389 to 1.85199, saving model to ../output/experiments/trial_42_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.5540 - loss: 1.6983 - val_accuracy: 0.5068 - val_loss: 1.8520 - learning_rate: 0.0050\n",
            "Epoch 49/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5643 - loss: 1.6617\n",
            "Epoch 49: val_loss did not improve from 1.85199\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.5643 - loss: 1.6618 - val_accuracy: 0.4848 - val_loss: 1.9128 - learning_rate: 0.0050\n",
            "Epoch 50/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5708 - loss: 1.6663\n",
            "Epoch 50: val_loss did not improve from 1.85199\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5708 - loss: 1.6665 - val_accuracy: 0.4984 - val_loss: 1.9124 - learning_rate: 0.0050\n",
            "Epoch 51/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5599 - loss: 1.6892\n",
            "Epoch 51: val_loss did not improve from 1.85199\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5599 - loss: 1.6894 - val_accuracy: 0.4797 - val_loss: 1.9216 - learning_rate: 0.0050\n",
            "Epoch 52/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5718 - loss: 1.7069\n",
            "Epoch 52: val_loss did not improve from 1.85199\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.5717 - loss: 1.7070 - val_accuracy: 0.4998 - val_loss: 1.8810 - learning_rate: 0.0050\n",
            "Epoch 53/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5671 - loss: 1.6733\n",
            "Epoch 53: val_loss did not improve from 1.85199\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5670 - loss: 1.6733 - val_accuracy: 0.5072 - val_loss: 1.8869 - learning_rate: 0.0050\n",
            "Epoch 54/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5671 - loss: 1.6793\n",
            "Epoch 54: val_loss improved from 1.85199 to 1.84811, saving model to ../output/experiments/trial_42_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5671 - loss: 1.6794 - val_accuracy: 0.5072 - val_loss: 1.8481 - learning_rate: 0.0050\n",
            "Epoch 55/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5679 - loss: 1.6810\n",
            "Epoch 55: val_loss did not improve from 1.84811\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5679 - loss: 1.6812 - val_accuracy: 0.4979 - val_loss: 1.9274 - learning_rate: 0.0050\n",
            "Epoch 56/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5648 - loss: 1.6751\n",
            "Epoch 56: val_loss did not improve from 1.84811\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5648 - loss: 1.6752 - val_accuracy: 0.4993 - val_loss: 1.8988 - learning_rate: 0.0050\n",
            "Epoch 57/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5805 - loss: 1.6593\n",
            "Epoch 57: val_loss did not improve from 1.84811\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5804 - loss: 1.6595 - val_accuracy: 0.4848 - val_loss: 1.9087 - learning_rate: 0.0050\n",
            "Epoch 58/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5730 - loss: 1.6791\n",
            "Epoch 58: val_loss improved from 1.84811 to 1.83191, saving model to ../output/experiments/trial_42_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5729 - loss: 1.6792 - val_accuracy: 0.5166 - val_loss: 1.8319 - learning_rate: 0.0050\n",
            "Epoch 59/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5891 - loss: 1.6120\n",
            "Epoch 59: val_loss did not improve from 1.83191\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5890 - loss: 1.6122 - val_accuracy: 0.5063 - val_loss: 1.8542 - learning_rate: 0.0050\n",
            "Epoch 60/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5684 - loss: 1.6733\n",
            "Epoch 60: val_loss did not improve from 1.83191\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5684 - loss: 1.6733 - val_accuracy: 0.4942 - val_loss: 1.8720 - learning_rate: 0.0050\n",
            "Epoch 61/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5841 - loss: 1.6167\n",
            "Epoch 61: val_loss improved from 1.83191 to 1.82323, saving model to ../output/experiments/trial_42_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5840 - loss: 1.6167 - val_accuracy: 0.5072 - val_loss: 1.8232 - learning_rate: 0.0050\n",
            "Epoch 62/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5677 - loss: 1.6830\n",
            "Epoch 62: val_loss did not improve from 1.82323\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5676 - loss: 1.6830 - val_accuracy: 0.5175 - val_loss: 1.8360 - learning_rate: 0.0050\n",
            "Epoch 63/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5771 - loss: 1.6679\n",
            "Epoch 63: val_loss did not improve from 1.82323\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.5771 - loss: 1.6678 - val_accuracy: 0.5100 - val_loss: 1.8921 - learning_rate: 0.0050\n",
            "Epoch 64/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6037 - loss: 1.5849\n",
            "Epoch 64: val_loss did not improve from 1.82323\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.6037 - loss: 1.5851 - val_accuracy: 0.5222 - val_loss: 1.8267 - learning_rate: 0.0050\n",
            "Epoch 65/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5940 - loss: 1.6161\n",
            "Epoch 65: val_loss did not improve from 1.82323\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5940 - loss: 1.6162 - val_accuracy: 0.5035 - val_loss: 1.8672 - learning_rate: 0.0050\n",
            "Epoch 66/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5890 - loss: 1.6144\n",
            "Epoch 66: val_loss did not improve from 1.82323\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.5889 - loss: 1.6145 - val_accuracy: 0.5394 - val_loss: 1.8253 - learning_rate: 0.0050\n",
            "Epoch 67/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5922 - loss: 1.5940\n",
            "Epoch 67: val_loss improved from 1.82323 to 1.81777, saving model to ../output/experiments/trial_42_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5921 - loss: 1.5944 - val_accuracy: 0.5334 - val_loss: 1.8178 - learning_rate: 0.0050\n",
            "Epoch 68/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5981 - loss: 1.6239\n",
            "Epoch 68: val_loss improved from 1.81777 to 1.79174, saving model to ../output/experiments/trial_42_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.5980 - loss: 1.6240 - val_accuracy: 0.5362 - val_loss: 1.7917 - learning_rate: 0.0050\n",
            "Epoch 69/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6061 - loss: 1.5892\n",
            "Epoch 69: val_loss did not improve from 1.79174\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.6060 - loss: 1.5893 - val_accuracy: 0.5166 - val_loss: 1.8292 - learning_rate: 0.0050\n",
            "Epoch 70/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5819 - loss: 1.6458\n",
            "Epoch 70: val_loss did not improve from 1.79174\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.5819 - loss: 1.6459 - val_accuracy: 0.5152 - val_loss: 1.8437 - learning_rate: 0.0050\n",
            "Epoch 71/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5890 - loss: 1.5872\n",
            "Epoch 71: val_loss did not improve from 1.79174\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5890 - loss: 1.5872 - val_accuracy: 0.5198 - val_loss: 1.8268 - learning_rate: 0.0050\n",
            "Epoch 72/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5951 - loss: 1.5999\n",
            "Epoch 72: val_loss did not improve from 1.79174\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.5951 - loss: 1.6000 - val_accuracy: 0.5133 - val_loss: 1.8783 - learning_rate: 0.0050\n",
            "Epoch 73/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5971 - loss: 1.5982\n",
            "Epoch 73: val_loss did not improve from 1.79174\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.5971 - loss: 1.5984 - val_accuracy: 0.5119 - val_loss: 1.9168 - learning_rate: 0.0050\n",
            "Epoch 74/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6099 - loss: 1.5880\n",
            "Epoch 74: val_loss did not improve from 1.79174\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.6098 - loss: 1.5880 - val_accuracy: 0.5180 - val_loss: 1.8584 - learning_rate: 0.0050\n",
            "Epoch 75/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6045 - loss: 1.5885\n",
            "Epoch 75: val_loss did not improve from 1.79174\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.6044 - loss: 1.5887 - val_accuracy: 0.5100 - val_loss: 1.8486 - learning_rate: 0.0050\n",
            "Epoch 76/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5891 - loss: 1.6106\n",
            "Epoch 76: val_loss did not improve from 1.79174\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5891 - loss: 1.6105 - val_accuracy: 0.5287 - val_loss: 1.7953 - learning_rate: 0.0050\n",
            "Epoch 77/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6063 - loss: 1.5734\n",
            "Epoch 77: val_loss did not improve from 1.79174\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.6062 - loss: 1.5735 - val_accuracy: 0.5124 - val_loss: 1.8192 - learning_rate: 0.0050\n",
            "Epoch 78/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5878 - loss: 1.5989\n",
            "Epoch 78: val_loss did not improve from 1.79174\n",
            "\n",
            "Epoch 78: ReduceLROnPlateau reducing learning rate to 0.0025107311084866524.\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5878 - loss: 1.5990 - val_accuracy: 0.5380 - val_loss: 1.8023 - learning_rate: 0.0050\n",
            "Epoch 79/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6290 - loss: 1.5087\n",
            "Epoch 79: val_loss improved from 1.79174 to 1.68574, saving model to ../output/experiments/trial_42_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.6291 - loss: 1.5084 - val_accuracy: 0.5749 - val_loss: 1.6857 - learning_rate: 0.0025\n",
            "Epoch 80/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6698 - loss: 1.3462\n",
            "Epoch 80: val_loss did not improve from 1.68574\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.6698 - loss: 1.3463 - val_accuracy: 0.5693 - val_loss: 1.6961 - learning_rate: 0.0025\n",
            "Epoch 81/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6858 - loss: 1.2852\n",
            "Epoch 81: val_loss did not improve from 1.68574\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.6858 - loss: 1.2852 - val_accuracy: 0.5726 - val_loss: 1.7111 - learning_rate: 0.0025\n",
            "Epoch 82/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6830 - loss: 1.2860\n",
            "Epoch 82: val_loss improved from 1.68574 to 1.68443, saving model to ../output/experiments/trial_42_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.6830 - loss: 1.2861 - val_accuracy: 0.5637 - val_loss: 1.6844 - learning_rate: 0.0025\n",
            "Epoch 83/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7001 - loss: 1.2227\n",
            "Epoch 83: val_loss improved from 1.68443 to 1.66615, saving model to ../output/experiments/trial_42_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.7001 - loss: 1.2228 - val_accuracy: 0.5758 - val_loss: 1.6661 - learning_rate: 0.0025\n",
            "Epoch 84/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7055 - loss: 1.2249\n",
            "Epoch 84: val_loss did not improve from 1.66615\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.7055 - loss: 1.2249 - val_accuracy: 0.5819 - val_loss: 1.6698 - learning_rate: 0.0025\n",
            "Epoch 85/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7076 - loss: 1.2054\n",
            "Epoch 85: val_loss did not improve from 1.66615\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.7075 - loss: 1.2055 - val_accuracy: 0.5660 - val_loss: 1.6837 - learning_rate: 0.0025\n",
            "Epoch 86/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7021 - loss: 1.2119\n",
            "Epoch 86: val_loss did not improve from 1.66615\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.7021 - loss: 1.2119 - val_accuracy: 0.5698 - val_loss: 1.6830 - learning_rate: 0.0025\n",
            "Epoch 87/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7075 - loss: 1.1781\n",
            "Epoch 87: val_loss improved from 1.66615 to 1.66444, saving model to ../output/experiments/trial_42_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.7074 - loss: 1.1783 - val_accuracy: 0.5805 - val_loss: 1.6644 - learning_rate: 0.0025\n",
            "Epoch 88/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7040 - loss: 1.1760\n",
            "Epoch 88: val_loss did not improve from 1.66444\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.7040 - loss: 1.1760 - val_accuracy: 0.5623 - val_loss: 1.6693 - learning_rate: 0.0025\n",
            "Epoch 89/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7238 - loss: 1.1348\n",
            "Epoch 89: val_loss improved from 1.66444 to 1.61592, saving model to ../output/experiments/trial_42_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.7237 - loss: 1.1350 - val_accuracy: 0.5852 - val_loss: 1.6159 - learning_rate: 0.0025\n",
            "Epoch 90/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7273 - loss: 1.1152\n",
            "Epoch 90: val_loss improved from 1.61592 to 1.60281, saving model to ../output/experiments/trial_42_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.7272 - loss: 1.1154 - val_accuracy: 0.5903 - val_loss: 1.6028 - learning_rate: 0.0025\n",
            "Epoch 91/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7288 - loss: 1.1222\n",
            "Epoch 91: val_loss did not improve from 1.60281\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.7288 - loss: 1.1222 - val_accuracy: 0.5814 - val_loss: 1.6339 - learning_rate: 0.0025\n",
            "Epoch 92/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7310 - loss: 1.1083\n",
            "Epoch 92: val_loss improved from 1.60281 to 1.55065, saving model to ../output/experiments/trial_42_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.7309 - loss: 1.1083 - val_accuracy: 0.6048 - val_loss: 1.5506 - learning_rate: 0.0025\n",
            "Epoch 93/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7375 - loss: 1.0706\n",
            "Epoch 93: val_loss did not improve from 1.55065\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.7375 - loss: 1.0708 - val_accuracy: 0.6029 - val_loss: 1.5894 - learning_rate: 0.0025\n",
            "Epoch 94/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7352 - loss: 1.0919\n",
            "Epoch 94: val_loss did not improve from 1.55065\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.7352 - loss: 1.0920 - val_accuracy: 0.5880 - val_loss: 1.6040 - learning_rate: 0.0025\n",
            "Epoch 95/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7420 - loss: 1.0705\n",
            "Epoch 95: val_loss did not improve from 1.55065\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.7420 - loss: 1.0705 - val_accuracy: 0.6006 - val_loss: 1.6121 - learning_rate: 0.0025\n",
            "Epoch 96/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7557 - loss: 1.0831\n",
            "Epoch 96: val_loss did not improve from 1.55065\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.7556 - loss: 1.0831 - val_accuracy: 0.5824 - val_loss: 1.5915 - learning_rate: 0.0025\n",
            "Epoch 97/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7607 - loss: 1.0470\n",
            "Epoch 97: val_loss did not improve from 1.55065\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.7607 - loss: 1.0471 - val_accuracy: 0.5922 - val_loss: 1.6195 - learning_rate: 0.0025\n",
            "Epoch 98/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7481 - loss: 1.0822\n",
            "Epoch 98: val_loss did not improve from 1.55065\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.7481 - loss: 1.0823 - val_accuracy: 0.6015 - val_loss: 1.6164 - learning_rate: 0.0025\n",
            "Epoch 99/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7492 - loss: 1.0585\n",
            "Epoch 99: val_loss did not improve from 1.55065\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.7492 - loss: 1.0586 - val_accuracy: 0.6010 - val_loss: 1.5807 - learning_rate: 0.0025\n",
            "Epoch 100/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7619 - loss: 1.0191\n",
            "Epoch 100: val_loss did not improve from 1.55065\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.7619 - loss: 1.0192 - val_accuracy: 0.6029 - val_loss: 1.6306 - learning_rate: 0.0025\n",
            "Restoring model weights from the end of the best epoch: 92.\n",
            "å­¦ç¿’å®Œäº†ï¼å­¦ç¿’æ™‚é–“: 1128.83ç§’\n",
            "æœ€è‰¯æ¤œè¨¼Loss: 1.5506\n",
            "æœ€è‰¯æ¤œè¨¼Accuracy: 0.6048\n",
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ä¸­...\n",
            "ãƒ†ã‚¹ãƒˆLoss: 1.6068\n",
            "ãƒ†ã‚¹ãƒˆAccuracy: 0.6054\n",
            "F1-Score (macro): 0.5602\n",
            "F1-Score (weighted): 0.5997\n",
            "çµæœä¿å­˜ä¸­...\n",
            "å­¦ç¿’å±¥æ­´ä¿å­˜å®Œäº†: ../output/experiments/trial_42_w64_s16_w64_s16/results/training_history_attention.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-08 22:48:23,349] Trial 42 finished with value: 0.7887141703656803 and parameters: {'lstm_units_1': 64, 'lstm_units_2': 56, 'dense_units': 56, 'demographics_dense_units': 32, 'fusion_dense_units': 40, 'dropout_rate': 0.15000000000000002, 'dense_dropout_rate': 0.15000000000000002, 'learning_rate': 0.005021462428296131, 'batch_size': 32, 'fusion_type': 'attention'}. Best is trial 34 with value: 0.8021217206997858.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "çµæœä¿å­˜å®Œäº†: ../output/experiments/trial_42_w64_s16_w64_s16/results\n",
            "âœ… Trial 42: CMI=0.7887, Binary F1=0.9508, Fusion=attention\n",
            "\n",
            "ğŸ” Trial 43 - w64_s16\n",
            "Mixed precision enabled for better GPU performance\n",
            "GPUåˆ©ç”¨å¯èƒ½: 1å°\n",
            "ä½¿ç”¨GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
            "LSTM v2å­¦ç¿’ç’°å¢ƒåˆæœŸåŒ–å®Œäº†\n",
            "å®Ÿé¨“å: trial_43_w64_s16\n",
            "ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®š: w64_s16\n",
            "å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: ../output/experiments/trial_43_w64_s16_w64_s16\n",
            "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿: ../output/experiments/lstm_v2_w64_s16/preprocessed\n",
            "GPUåˆ©ç”¨å¯èƒ½: True\n",
            "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...\n",
            "æœ€é©åŒ–ã•ã‚ŒãŸdemographicsç‰¹å¾´é‡ã‚’ä½¿ç”¨ã—ã¾ã™\n",
            "æœ€é©åŒ–ã•ã‚ŒãŸdemographicså½¢çŠ¶: (13393, 18)\n",
            "ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†:\n",
            "  ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿: (13393, 64, 332)\n",
            "  Demographics: (13393, 18)\n",
            "  ãƒ©ãƒ™ãƒ«: (13393,)\n",
            "  ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹ (èåˆæ–¹å¼: attention)...\n",
            "ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ä¸­...\n",
            "ãƒ†ã‚¹ãƒˆã‚µã‚¤ã‚º: 0.2\n",
            "æ¤œè¨¼ã‚µã‚¤ã‚º: 0.2\n",
            "ãƒ‡ãƒ¼ã‚¿åˆ†å‰²å®Œäº†:\n",
            "  è¨“ç·´ - ã‚»ãƒ³ã‚µãƒ¼: (8571, 64, 332), Demographics: (8571, 18), ãƒ©ãƒ™ãƒ«: (8571,)\n",
            "  æ¤œè¨¼ - ã‚»ãƒ³ã‚µãƒ¼: (2143, 64, 332), Demographics: (2143, 18), ãƒ©ãƒ™ãƒ«: (2143,)\n",
            "  ãƒ†ã‚¹ãƒˆ - ã‚»ãƒ³ã‚µãƒ¼: (2679, 64, 332), Demographics: (2679, 18), ãƒ©ãƒ™ãƒ«: (2679,)\n",
            "å…¥åŠ›å½¢çŠ¶:\n",
            "  ã‚»ãƒ³ã‚µãƒ¼: (64, 332)\n",
            "  Demographics: (18,)\n",
            "  ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "GPUä¸Šã§ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆãƒ»å­¦ç¿’ã—ã¾ã™\n",
            "Mixed precision enabled for better GPU performance\n",
            "GPUåˆ©ç”¨å¯èƒ½: 1å°\n",
            "ä½¿ç”¨GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
            "LSTM v2ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†\n",
            "ã‚»ãƒ³ã‚µãƒ¼å…¥åŠ›å½¢çŠ¶: (64, 332)\n",
            "Demographicså…¥åŠ›å½¢çŠ¶: (18,)\n",
            "ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "èåˆæ–¹å¼: attention\n",
            "GPUåˆ©ç”¨å¯èƒ½: True\n",
            "LSTM v2ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ä¸­...\n",
            "ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰å®Œäº†\n",
            "ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 115,146\n",
            "\n",
            "=== ãƒ¢ãƒ‡ãƒ«ã‚µãƒãƒªãƒ¼ ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"lstm_v2_hybrid\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"lstm_v2_hybrid\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ sensor_input        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">332</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,152</span> â”‚ sensor_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_1           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> â”‚ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_1      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ lstm_bn_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_input  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">28,928</span> â”‚ lstm_dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">608</span> â”‚ demographics_inpâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_2           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_2      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ lstm_bn_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dense        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,640</span> â”‚ lstm_dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dropout      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sensor_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_weights   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,848</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attended_sensor     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sensor_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          â”‚                   â”‚            â”‚ attention_weightâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_projeâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,848</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_fusion    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ attended_sensor[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚                   â”‚            â”‚ demographics_proâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dense        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,736</span> â”‚ attention_fusionâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dropout      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ fusion_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">882</span> â”‚ fusion_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ sensor_input        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m332\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m48\u001b[0m)    â”‚     \u001b[38;5;34m73,152\u001b[0m â”‚ sensor_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_1           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m48\u001b[0m)    â”‚        \u001b[38;5;34m192\u001b[0m â”‚ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_1      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m48\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ lstm_bn_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_input  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚     \u001b[38;5;34m28,928\u001b[0m â”‚ lstm_dropout_1[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚        \u001b[38;5;34m608\u001b[0m â”‚ demographics_inpâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_2           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m256\u001b[0m â”‚ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_2      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ lstm_bn_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚      \u001b[38;5;34m1,056\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dense        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        â”‚      \u001b[38;5;34m3,640\u001b[0m â”‚ lstm_dropout_2[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dropout      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sensor_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_weights   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        â”‚      \u001b[38;5;34m1,848\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attended_sensor     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sensor_dropout[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mMultiply\u001b[0m)          â”‚                   â”‚            â”‚ attention_weightâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_projeâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        â”‚      \u001b[38;5;34m1,848\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_fusion    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ attended_sensor[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚                   â”‚            â”‚ demographics_proâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dense        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚      \u001b[38;5;34m2,736\u001b[0m â”‚ attention_fusionâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dropout      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ fusion_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (\u001b[38;5;33mDense\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        â”‚        \u001b[38;5;34m882\u001b[0m â”‚ fusion_dropout[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">115,146</span> (449.79 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m115,146\u001b[0m (449.79 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">114,922</span> (448.91 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m114,922\u001b[0m (448.91 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹...\n",
            "ã‚»ãƒ³ã‚µãƒ¼è¨“ç·´ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (8571, 64, 332)\n",
            "Demographicsè¨“ç·´ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (8571, 18)\n",
            "ã‚»ãƒ³ã‚µãƒ¼æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (2143, 64, 332)\n",
            "Demographicsæ¤œè¨¼ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (2143, 18)\n",
            "è¨“ç·´ãƒ©ãƒ™ãƒ«å½¢çŠ¶: (8571,)\n",
            "æ¤œè¨¼ãƒ©ãƒ™ãƒ«å½¢çŠ¶: (2143,)\n",
            "Epoch 1/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.1516 - loss: 2.7616\n",
            "Epoch 1: val_loss improved from inf to 2.54082, saving model to ../output/experiments/trial_43_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 47ms/step - accuracy: 0.1517 - loss: 2.7613 - val_accuracy: 0.2296 - val_loss: 2.5408 - learning_rate: 0.0073\n",
            "Epoch 2/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.2408 - loss: 2.5030\n",
            "Epoch 2: val_loss improved from 2.54082 to 2.47669, saving model to ../output/experiments/trial_43_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.2409 - loss: 2.5030 - val_accuracy: 0.2730 - val_loss: 2.4767 - learning_rate: 0.0073\n",
            "Epoch 3/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.2798 - loss: 2.4562\n",
            "Epoch 3: val_loss improved from 2.47669 to 2.44797, saving model to ../output/experiments/trial_43_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.2798 - loss: 2.4563 - val_accuracy: 0.2954 - val_loss: 2.4480 - learning_rate: 0.0073\n",
            "Epoch 4/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.2930 - loss: 2.4799\n",
            "Epoch 4: val_loss improved from 2.44797 to 2.42102, saving model to ../output/experiments/trial_43_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.2930 - loss: 2.4800 - val_accuracy: 0.3014 - val_loss: 2.4210 - learning_rate: 0.0073\n",
            "Epoch 5/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.3185 - loss: 2.4386\n",
            "Epoch 5: val_loss did not improve from 2.42102\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.3184 - loss: 2.4388 - val_accuracy: 0.3196 - val_loss: 2.4235 - learning_rate: 0.0073\n",
            "Epoch 6/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3268 - loss: 2.4656\n",
            "Epoch 6: val_loss did not improve from 2.42102\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.3268 - loss: 2.4656 - val_accuracy: 0.3154 - val_loss: 2.4921 - learning_rate: 0.0073\n",
            "Epoch 7/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3275 - loss: 2.4272\n",
            "Epoch 7: val_loss did not improve from 2.42102\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.3275 - loss: 2.4274 - val_accuracy: 0.3336 - val_loss: 2.4249 - learning_rate: 0.0073\n",
            "Epoch 8/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3321 - loss: 2.4019\n",
            "Epoch 8: val_loss improved from 2.42102 to 2.38576, saving model to ../output/experiments/trial_43_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.3321 - loss: 2.4021 - val_accuracy: 0.3350 - val_loss: 2.3858 - learning_rate: 0.0073\n",
            "Epoch 9/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3389 - loss: 2.4061\n",
            "Epoch 9: val_loss did not improve from 2.38576\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.3389 - loss: 2.4062 - val_accuracy: 0.3336 - val_loss: 2.3918 - learning_rate: 0.0073\n",
            "Epoch 10/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.3470 - loss: 2.4265\n",
            "Epoch 10: val_loss improved from 2.38576 to 2.37131, saving model to ../output/experiments/trial_43_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.3470 - loss: 2.4265 - val_accuracy: 0.3402 - val_loss: 2.3713 - learning_rate: 0.0073\n",
            "Epoch 11/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3568 - loss: 2.3811\n",
            "Epoch 11: val_loss improved from 2.37131 to 2.36203, saving model to ../output/experiments/trial_43_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.3567 - loss: 2.3811 - val_accuracy: 0.3556 - val_loss: 2.3620 - learning_rate: 0.0073\n",
            "Epoch 12/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3651 - loss: 2.3601\n",
            "Epoch 12: val_loss improved from 2.36203 to 2.31050, saving model to ../output/experiments/trial_43_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.3651 - loss: 2.3602 - val_accuracy: 0.3565 - val_loss: 2.3105 - learning_rate: 0.0073\n",
            "Epoch 13/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3729 - loss: 2.3259\n",
            "Epoch 13: val_loss improved from 2.31050 to 2.29532, saving model to ../output/experiments/trial_43_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.3729 - loss: 2.3260 - val_accuracy: 0.3728 - val_loss: 2.2953 - learning_rate: 0.0073\n",
            "Epoch 14/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3713 - loss: 2.3101\n",
            "Epoch 14: val_loss improved from 2.29532 to 2.25684, saving model to ../output/experiments/trial_43_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.3713 - loss: 2.3100 - val_accuracy: 0.3775 - val_loss: 2.2568 - learning_rate: 0.0073\n",
            "Epoch 15/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3860 - loss: 2.2737\n",
            "Epoch 15: val_loss improved from 2.25684 to 2.21102, saving model to ../output/experiments/trial_43_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.3860 - loss: 2.2738 - val_accuracy: 0.3920 - val_loss: 2.2110 - learning_rate: 0.0073\n",
            "Epoch 16/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3954 - loss: 2.2684\n",
            "Epoch 16: val_loss did not improve from 2.21102\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.3953 - loss: 2.2684 - val_accuracy: 0.3705 - val_loss: 2.2271 - learning_rate: 0.0073\n",
            "Epoch 17/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3851 - loss: 2.2439\n",
            "Epoch 17: val_loss did not improve from 2.21102\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.3851 - loss: 2.2439 - val_accuracy: 0.3724 - val_loss: 2.2386 - learning_rate: 0.0073\n",
            "Epoch 18/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4160 - loss: 2.1911\n",
            "Epoch 18: val_loss improved from 2.21102 to 2.20191, saving model to ../output/experiments/trial_43_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.4159 - loss: 2.1911 - val_accuracy: 0.3789 - val_loss: 2.2019 - learning_rate: 0.0073\n",
            "Epoch 19/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3984 - loss: 2.1972\n",
            "Epoch 19: val_loss did not improve from 2.20191\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.3983 - loss: 2.1975 - val_accuracy: 0.3448 - val_loss: 2.4282 - learning_rate: 0.0073\n",
            "Epoch 20/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3963 - loss: 2.2409\n",
            "Epoch 20: val_loss improved from 2.20191 to 2.19386, saving model to ../output/experiments/trial_43_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.3964 - loss: 2.2406 - val_accuracy: 0.3924 - val_loss: 2.1939 - learning_rate: 0.0073\n",
            "Epoch 21/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3949 - loss: 2.2028\n",
            "Epoch 21: val_loss did not improve from 2.19386\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.3949 - loss: 2.2029 - val_accuracy: 0.3770 - val_loss: 2.2090 - learning_rate: 0.0073\n",
            "Epoch 22/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4100 - loss: 2.1950\n",
            "Epoch 22: val_loss improved from 2.19386 to 2.16328, saving model to ../output/experiments/trial_43_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.4101 - loss: 2.1949 - val_accuracy: 0.3934 - val_loss: 2.1633 - learning_rate: 0.0073\n",
            "Epoch 23/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4182 - loss: 2.1494\n",
            "Epoch 23: val_loss did not improve from 2.16328\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.4181 - loss: 2.1494 - val_accuracy: 0.3966 - val_loss: 2.1758 - learning_rate: 0.0073\n",
            "Epoch 24/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.4122 - loss: 2.1500\n",
            "Epoch 24: val_loss improved from 2.16328 to 2.09105, saving model to ../output/experiments/trial_43_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.4122 - loss: 2.1501 - val_accuracy: 0.4284 - val_loss: 2.0911 - learning_rate: 0.0073\n",
            "Epoch 25/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4228 - loss: 2.1051\n",
            "Epoch 25: val_loss did not improve from 2.09105\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.4228 - loss: 2.1051 - val_accuracy: 0.4041 - val_loss: 2.1223 - learning_rate: 0.0073\n",
            "Epoch 26/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.4213 - loss: 2.0965\n",
            "Epoch 26: val_loss improved from 2.09105 to 2.08143, saving model to ../output/experiments/trial_43_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.4213 - loss: 2.0965 - val_accuracy: 0.4209 - val_loss: 2.0814 - learning_rate: 0.0073\n",
            "Epoch 27/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4286 - loss: 2.1190\n",
            "Epoch 27: val_loss improved from 2.08143 to 2.07439, saving model to ../output/experiments/trial_43_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.4287 - loss: 2.1190 - val_accuracy: 0.4148 - val_loss: 2.0744 - learning_rate: 0.0073\n",
            "Epoch 28/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.4419 - loss: 2.0680\n",
            "Epoch 28: val_loss did not improve from 2.07439\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.4419 - loss: 2.0681 - val_accuracy: 0.4167 - val_loss: 2.1220 - learning_rate: 0.0073\n",
            "Epoch 29/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.4328 - loss: 2.0909\n",
            "Epoch 29: val_loss did not improve from 2.07439\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.4328 - loss: 2.0909 - val_accuracy: 0.4083 - val_loss: 2.1300 - learning_rate: 0.0073\n",
            "Epoch 30/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4348 - loss: 2.0677\n",
            "Epoch 30: val_loss improved from 2.07439 to 2.06896, saving model to ../output/experiments/trial_43_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.4348 - loss: 2.0676 - val_accuracy: 0.4218 - val_loss: 2.0690 - learning_rate: 0.0073\n",
            "Epoch 31/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.4456 - loss: 2.0477\n",
            "Epoch 31: val_loss did not improve from 2.06896\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.4456 - loss: 2.0479 - val_accuracy: 0.4130 - val_loss: 2.0796 - learning_rate: 0.0073\n",
            "Epoch 32/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4460 - loss: 2.0559\n",
            "Epoch 32: val_loss improved from 2.06896 to 2.04706, saving model to ../output/experiments/trial_43_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.4460 - loss: 2.0560 - val_accuracy: 0.4335 - val_loss: 2.0471 - learning_rate: 0.0073\n",
            "Epoch 33/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4689 - loss: 2.0006\n",
            "Epoch 33: val_loss did not improve from 2.04706\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4688 - loss: 2.0009 - val_accuracy: 0.4307 - val_loss: 2.0585 - learning_rate: 0.0073\n",
            "Epoch 34/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4533 - loss: 2.0238\n",
            "Epoch 34: val_loss did not improve from 2.04706\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4532 - loss: 2.0240 - val_accuracy: 0.4270 - val_loss: 2.0493 - learning_rate: 0.0073\n",
            "Epoch 35/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4540 - loss: 2.0083\n",
            "Epoch 35: val_loss improved from 2.04706 to 2.02592, saving model to ../output/experiments/trial_43_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4540 - loss: 2.0084 - val_accuracy: 0.4344 - val_loss: 2.0259 - learning_rate: 0.0073\n",
            "Epoch 36/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4473 - loss: 2.0039\n",
            "Epoch 36: val_loss did not improve from 2.02592\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.4473 - loss: 2.0039 - val_accuracy: 0.4405 - val_loss: 2.0304 - learning_rate: 0.0073\n",
            "Epoch 37/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4633 - loss: 1.9820\n",
            "Epoch 37: val_loss did not improve from 2.02592\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.4632 - loss: 1.9822 - val_accuracy: 0.3910 - val_loss: 2.1953 - learning_rate: 0.0073\n",
            "Epoch 38/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4593 - loss: 1.9814\n",
            "Epoch 38: val_loss did not improve from 2.02592\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4592 - loss: 1.9816 - val_accuracy: 0.4307 - val_loss: 2.0466 - learning_rate: 0.0073\n",
            "Epoch 39/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4663 - loss: 1.9920\n",
            "Epoch 39: val_loss improved from 2.02592 to 2.02461, saving model to ../output/experiments/trial_43_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.4663 - loss: 1.9921 - val_accuracy: 0.4302 - val_loss: 2.0246 - learning_rate: 0.0073\n",
            "Epoch 40/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4571 - loss: 1.9778\n",
            "Epoch 40: val_loss did not improve from 2.02461\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.4570 - loss: 1.9780 - val_accuracy: 0.4307 - val_loss: 2.0666 - learning_rate: 0.0073\n",
            "Epoch 41/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4712 - loss: 1.9872\n",
            "Epoch 41: val_loss improved from 2.02461 to 2.02102, saving model to ../output/experiments/trial_43_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4712 - loss: 1.9873 - val_accuracy: 0.4517 - val_loss: 2.0210 - learning_rate: 0.0073\n",
            "Epoch 42/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4646 - loss: 1.9628\n",
            "Epoch 42: val_loss improved from 2.02102 to 1.97754, saving model to ../output/experiments/trial_43_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.4647 - loss: 1.9629 - val_accuracy: 0.4517 - val_loss: 1.9775 - learning_rate: 0.0073\n",
            "Epoch 43/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4869 - loss: 1.9049\n",
            "Epoch 43: val_loss improved from 1.97754 to 1.96792, saving model to ../output/experiments/trial_43_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.4868 - loss: 1.9052 - val_accuracy: 0.4545 - val_loss: 1.9679 - learning_rate: 0.0073\n",
            "Epoch 44/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4699 - loss: 1.9587\n",
            "Epoch 44: val_loss improved from 1.96792 to 1.94403, saving model to ../output/experiments/trial_43_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4700 - loss: 1.9585 - val_accuracy: 0.4489 - val_loss: 1.9440 - learning_rate: 0.0073\n",
            "Epoch 45/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4757 - loss: 1.9052\n",
            "Epoch 45: val_loss did not improve from 1.94403\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.4757 - loss: 1.9054 - val_accuracy: 0.4601 - val_loss: 1.9459 - learning_rate: 0.0073\n",
            "Epoch 46/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4794 - loss: 1.8829\n",
            "Epoch 46: val_loss did not improve from 1.94403\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.4794 - loss: 1.8830 - val_accuracy: 0.4428 - val_loss: 1.9593 - learning_rate: 0.0073\n",
            "Epoch 47/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4590 - loss: 1.9555\n",
            "Epoch 47: val_loss did not improve from 1.94403\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4590 - loss: 1.9556 - val_accuracy: 0.4396 - val_loss: 1.9983 - learning_rate: 0.0073\n",
            "Epoch 48/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4909 - loss: 1.8713\n",
            "Epoch 48: val_loss did not improve from 1.94403\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.4909 - loss: 1.8714 - val_accuracy: 0.4564 - val_loss: 1.9715 - learning_rate: 0.0073\n",
            "Epoch 49/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4750 - loss: 1.9054\n",
            "Epoch 49: val_loss did not improve from 1.94403\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.4750 - loss: 1.9055 - val_accuracy: 0.4503 - val_loss: 1.9702 - learning_rate: 0.0073\n",
            "Epoch 50/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4897 - loss: 1.8749\n",
            "Epoch 50: val_loss did not improve from 1.94403\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4897 - loss: 1.8749 - val_accuracy: 0.4452 - val_loss: 1.9716 - learning_rate: 0.0073\n",
            "Epoch 51/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4892 - loss: 1.8996\n",
            "Epoch 51: val_loss improved from 1.94403 to 1.94165, saving model to ../output/experiments/trial_43_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.4891 - loss: 1.8996 - val_accuracy: 0.4573 - val_loss: 1.9417 - learning_rate: 0.0073\n",
            "Epoch 52/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.4966 - loss: 1.8738\n",
            "Epoch 52: val_loss improved from 1.94165 to 1.89875, saving model to ../output/experiments/trial_43_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.4965 - loss: 1.8739 - val_accuracy: 0.4713 - val_loss: 1.8987 - learning_rate: 0.0073\n",
            "Epoch 53/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.4851 - loss: 1.8870\n",
            "Epoch 53: val_loss did not improve from 1.89875\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.4850 - loss: 1.8871 - val_accuracy: 0.4550 - val_loss: 1.9549 - learning_rate: 0.0073\n",
            "Epoch 54/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4852 - loss: 1.8580\n",
            "Epoch 54: val_loss did not improve from 1.89875\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4851 - loss: 1.8582 - val_accuracy: 0.4568 - val_loss: 1.9800 - learning_rate: 0.0073\n",
            "Epoch 55/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5017 - loss: 1.8708\n",
            "Epoch 55: val_loss improved from 1.89875 to 1.88859, saving model to ../output/experiments/trial_43_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.5016 - loss: 1.8708 - val_accuracy: 0.4699 - val_loss: 1.8886 - learning_rate: 0.0073\n",
            "Epoch 56/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4968 - loss: 1.8242\n",
            "Epoch 56: val_loss did not improve from 1.88859\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4968 - loss: 1.8245 - val_accuracy: 0.4596 - val_loss: 1.9409 - learning_rate: 0.0073\n",
            "Epoch 57/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4963 - loss: 1.8503\n",
            "Epoch 57: val_loss did not improve from 1.88859\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.4963 - loss: 1.8503 - val_accuracy: 0.4694 - val_loss: 1.9240 - learning_rate: 0.0073\n",
            "Epoch 58/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4995 - loss: 1.8396\n",
            "Epoch 58: val_loss did not improve from 1.88859\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4995 - loss: 1.8397 - val_accuracy: 0.4480 - val_loss: 1.9719 - learning_rate: 0.0073\n",
            "Epoch 59/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4860 - loss: 1.8861\n",
            "Epoch 59: val_loss improved from 1.88859 to 1.86524, saving model to ../output/experiments/trial_43_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.4860 - loss: 1.8859 - val_accuracy: 0.4662 - val_loss: 1.8652 - learning_rate: 0.0073\n",
            "Epoch 60/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5055 - loss: 1.8057\n",
            "Epoch 60: val_loss did not improve from 1.86524\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.5055 - loss: 1.8059 - val_accuracy: 0.4788 - val_loss: 1.8894 - learning_rate: 0.0073\n",
            "Epoch 61/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5015 - loss: 1.8185\n",
            "Epoch 61: val_loss did not improve from 1.86524\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5015 - loss: 1.8186 - val_accuracy: 0.4629 - val_loss: 1.9125 - learning_rate: 0.0073\n",
            "Epoch 62/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4955 - loss: 1.8113\n",
            "Epoch 62: val_loss did not improve from 1.86524\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.4955 - loss: 1.8113 - val_accuracy: 0.4834 - val_loss: 1.8996 - learning_rate: 0.0073\n",
            "Epoch 63/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5041 - loss: 1.7888\n",
            "Epoch 63: val_loss did not improve from 1.86524\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.5041 - loss: 1.7889 - val_accuracy: 0.4526 - val_loss: 1.9300 - learning_rate: 0.0073\n",
            "Epoch 64/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5151 - loss: 1.7750\n",
            "Epoch 64: val_loss did not improve from 1.86524\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5151 - loss: 1.7750 - val_accuracy: 0.4694 - val_loss: 1.9062 - learning_rate: 0.0073\n",
            "Epoch 65/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5135 - loss: 1.7825\n",
            "Epoch 65: val_loss improved from 1.86524 to 1.85657, saving model to ../output/experiments/trial_43_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.5135 - loss: 1.7825 - val_accuracy: 0.4830 - val_loss: 1.8566 - learning_rate: 0.0073\n",
            "Epoch 66/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5021 - loss: 1.7985\n",
            "Epoch 66: val_loss improved from 1.85657 to 1.85194, saving model to ../output/experiments/trial_43_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.5021 - loss: 1.7985 - val_accuracy: 0.4797 - val_loss: 1.8519 - learning_rate: 0.0073\n",
            "Epoch 67/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5140 - loss: 1.7906\n",
            "Epoch 67: val_loss did not improve from 1.85194\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.5140 - loss: 1.7906 - val_accuracy: 0.4736 - val_loss: 1.8613 - learning_rate: 0.0073\n",
            "Epoch 68/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5119 - loss: 1.7719\n",
            "Epoch 68: val_loss improved from 1.85194 to 1.82428, saving model to ../output/experiments/trial_43_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.5119 - loss: 1.7719 - val_accuracy: 0.4942 - val_loss: 1.8243 - learning_rate: 0.0073\n",
            "Epoch 69/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5210 - loss: 1.7596\n",
            "Epoch 69: val_loss did not improve from 1.82428\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.5209 - loss: 1.7597 - val_accuracy: 0.4564 - val_loss: 1.9240 - learning_rate: 0.0073\n",
            "Epoch 70/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5171 - loss: 1.7947\n",
            "Epoch 70: val_loss did not improve from 1.82428\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.5170 - loss: 1.7947 - val_accuracy: 0.4778 - val_loss: 1.8635 - learning_rate: 0.0073\n",
            "Epoch 71/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5218 - loss: 1.7455\n",
            "Epoch 71: val_loss did not improve from 1.82428\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5218 - loss: 1.7457 - val_accuracy: 0.4601 - val_loss: 1.9028 - learning_rate: 0.0073\n",
            "Epoch 72/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5091 - loss: 1.7795\n",
            "Epoch 72: val_loss did not improve from 1.82428\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.5091 - loss: 1.7796 - val_accuracy: 0.4676 - val_loss: 1.8843 - learning_rate: 0.0073\n",
            "Epoch 73/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5026 - loss: 1.7873\n",
            "Epoch 73: val_loss did not improve from 1.82428\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.5026 - loss: 1.7874 - val_accuracy: 0.4755 - val_loss: 1.9445 - learning_rate: 0.0073\n",
            "Epoch 74/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5241 - loss: 1.7744\n",
            "Epoch 74: val_loss did not improve from 1.82428\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 47ms/step - accuracy: 0.5241 - loss: 1.7744 - val_accuracy: 0.4867 - val_loss: 1.8593 - learning_rate: 0.0073\n",
            "Epoch 75/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5333 - loss: 1.7164\n",
            "Epoch 75: val_loss did not improve from 1.82428\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.5333 - loss: 1.7166 - val_accuracy: 0.4834 - val_loss: 1.8485 - learning_rate: 0.0073\n",
            "Epoch 76/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5276 - loss: 1.7119\n",
            "Epoch 76: val_loss improved from 1.82428 to 1.81351, saving model to ../output/experiments/trial_43_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.5276 - loss: 1.7119 - val_accuracy: 0.4853 - val_loss: 1.8135 - learning_rate: 0.0073\n",
            "Epoch 77/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5417 - loss: 1.7181\n",
            "Epoch 77: val_loss did not improve from 1.81351\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 46ms/step - accuracy: 0.5416 - loss: 1.7182 - val_accuracy: 0.4764 - val_loss: 1.9164 - learning_rate: 0.0073\n",
            "Epoch 78/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5321 - loss: 1.7366\n",
            "Epoch 78: val_loss did not improve from 1.81351\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.5320 - loss: 1.7368 - val_accuracy: 0.4722 - val_loss: 1.8877 - learning_rate: 0.0073\n",
            "Epoch 79/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5348 - loss: 1.7178\n",
            "Epoch 79: val_loss did not improve from 1.81351\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.5348 - loss: 1.7179 - val_accuracy: 0.4932 - val_loss: 1.8254 - learning_rate: 0.0073\n",
            "Epoch 80/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5118 - loss: 1.7327\n",
            "Epoch 80: val_loss did not improve from 1.81351\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.5119 - loss: 1.7327 - val_accuracy: 0.4872 - val_loss: 1.8897 - learning_rate: 0.0073\n",
            "Epoch 81/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5243 - loss: 1.7252\n",
            "Epoch 81: val_loss improved from 1.81351 to 1.78639, saving model to ../output/experiments/trial_43_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.5243 - loss: 1.7253 - val_accuracy: 0.5054 - val_loss: 1.7864 - learning_rate: 0.0073\n",
            "Epoch 82/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5372 - loss: 1.6783\n",
            "Epoch 82: val_loss did not improve from 1.78639\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.5371 - loss: 1.6786 - val_accuracy: 0.4923 - val_loss: 1.8394 - learning_rate: 0.0073\n",
            "Epoch 83/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5436 - loss: 1.6759\n",
            "Epoch 83: val_loss did not improve from 1.78639\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 47ms/step - accuracy: 0.5435 - loss: 1.6761 - val_accuracy: 0.4545 - val_loss: 1.9216 - learning_rate: 0.0073\n",
            "Epoch 84/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5246 - loss: 1.6990\n",
            "Epoch 84: val_loss did not improve from 1.78639\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.5247 - loss: 1.6991 - val_accuracy: 0.4806 - val_loss: 1.8777 - learning_rate: 0.0073\n",
            "Epoch 85/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5324 - loss: 1.6772\n",
            "Epoch 85: val_loss did not improve from 1.78639\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.5324 - loss: 1.6772 - val_accuracy: 0.4755 - val_loss: 1.8610 - learning_rate: 0.0073\n",
            "Epoch 86/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5307 - loss: 1.6786\n",
            "Epoch 86: val_loss did not improve from 1.78639\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.5307 - loss: 1.6787 - val_accuracy: 0.5058 - val_loss: 1.7903 - learning_rate: 0.0073\n",
            "Epoch 87/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5467 - loss: 1.6542\n",
            "Epoch 87: val_loss did not improve from 1.78639\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.5467 - loss: 1.6543 - val_accuracy: 0.4988 - val_loss: 1.7998 - learning_rate: 0.0073\n",
            "Epoch 88/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5318 - loss: 1.6680\n",
            "Epoch 88: val_loss did not improve from 1.78639\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.5317 - loss: 1.6682 - val_accuracy: 0.4774 - val_loss: 1.8754 - learning_rate: 0.0073\n",
            "Epoch 89/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5322 - loss: 1.6733\n",
            "Epoch 89: val_loss did not improve from 1.78639\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.5322 - loss: 1.6734 - val_accuracy: 0.4918 - val_loss: 1.8370 - learning_rate: 0.0073\n",
            "Epoch 90/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5431 - loss: 1.6610\n",
            "Epoch 90: val_loss did not improve from 1.78639\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5431 - loss: 1.6612 - val_accuracy: 0.4890 - val_loss: 1.8341 - learning_rate: 0.0073\n",
            "Epoch 91/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5289 - loss: 1.6756\n",
            "Epoch 91: val_loss did not improve from 1.78639\n",
            "\n",
            "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.003638532944023609.\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.5290 - loss: 1.6758 - val_accuracy: 0.5110 - val_loss: 1.8427 - learning_rate: 0.0073\n",
            "Epoch 92/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5598 - loss: 1.6007\n",
            "Epoch 92: val_loss improved from 1.78639 to 1.71042, saving model to ../output/experiments/trial_43_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 47ms/step - accuracy: 0.5599 - loss: 1.6003 - val_accuracy: 0.5310 - val_loss: 1.7104 - learning_rate: 0.0036\n",
            "Epoch 93/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5949 - loss: 1.4537\n",
            "Epoch 93: val_loss improved from 1.71042 to 1.66814, saving model to ../output/experiments/trial_43_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.5949 - loss: 1.4537 - val_accuracy: 0.5376 - val_loss: 1.6681 - learning_rate: 0.0036\n",
            "Epoch 94/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6096 - loss: 1.4023\n",
            "Epoch 94: val_loss improved from 1.66814 to 1.64950, saving model to ../output/experiments/trial_43_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.6095 - loss: 1.4024 - val_accuracy: 0.5231 - val_loss: 1.6495 - learning_rate: 0.0036\n",
            "Epoch 95/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5855 - loss: 1.4355\n",
            "Epoch 95: val_loss did not improve from 1.64950\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5855 - loss: 1.4353 - val_accuracy: 0.5366 - val_loss: 1.6939 - learning_rate: 0.0036\n",
            "Epoch 96/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6200 - loss: 1.3463\n",
            "Epoch 96: val_loss did not improve from 1.64950\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.6200 - loss: 1.3464 - val_accuracy: 0.5385 - val_loss: 1.6569 - learning_rate: 0.0036\n",
            "Epoch 97/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6130 - loss: 1.3479\n",
            "Epoch 97: val_loss improved from 1.64950 to 1.62669, saving model to ../output/experiments/trial_43_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.6129 - loss: 1.3480 - val_accuracy: 0.5460 - val_loss: 1.6267 - learning_rate: 0.0036\n",
            "Epoch 98/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6192 - loss: 1.3538\n",
            "Epoch 98: val_loss did not improve from 1.62669\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.6192 - loss: 1.3538 - val_accuracy: 0.5296 - val_loss: 1.6634 - learning_rate: 0.0036\n",
            "Epoch 99/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6137 - loss: 1.3299\n",
            "Epoch 99: val_loss did not improve from 1.62669\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.6137 - loss: 1.3300 - val_accuracy: 0.5427 - val_loss: 1.6318 - learning_rate: 0.0036\n",
            "Epoch 100/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6183 - loss: 1.3058\n",
            "Epoch 100: val_loss did not improve from 1.62669\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.6183 - loss: 1.3058 - val_accuracy: 0.5315 - val_loss: 1.6705 - learning_rate: 0.0036\n",
            "Restoring model weights from the end of the best epoch: 97.\n",
            "å­¦ç¿’å®Œäº†ï¼å­¦ç¿’æ™‚é–“: 1191.70ç§’\n",
            "æœ€è‰¯æ¤œè¨¼Loss: 1.6267\n",
            "æœ€è‰¯æ¤œè¨¼Accuracy: 0.5460\n",
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ä¸­...\n",
            "ãƒ†ã‚¹ãƒˆLoss: 1.5926\n",
            "ãƒ†ã‚¹ãƒˆAccuracy: 0.5435\n",
            "F1-Score (macro): 0.4806\n",
            "F1-Score (weighted): 0.5187\n",
            "çµæœä¿å­˜ä¸­...\n",
            "å­¦ç¿’å±¥æ­´ä¿å­˜å®Œäº†: ../output/experiments/trial_43_w64_s16_w64_s16/results/training_history_attention.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-08 23:08:22,708] Trial 43 finished with value: 0.744755489746033 and parameters: {'lstm_units_1': 48, 'lstm_units_2': 64, 'dense_units': 56, 'demographics_dense_units': 32, 'fusion_dense_units': 48, 'dropout_rate': 0.15000000000000002, 'dense_dropout_rate': 0.15000000000000002, 'learning_rate': 0.007277066009643046, 'batch_size': 32, 'fusion_type': 'attention'}. Best is trial 34 with value: 0.8021217206997858.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "çµæœä¿å­˜å®Œäº†: ../output/experiments/trial_43_w64_s16_w64_s16/results\n",
            "âœ… Trial 43: CMI=0.7448, Binary F1=0.9359, Fusion=attention\n",
            "\n",
            "ğŸ” Trial 44 - w64_s16\n",
            "Mixed precision enabled for better GPU performance\n",
            "GPUåˆ©ç”¨å¯èƒ½: 1å°\n",
            "ä½¿ç”¨GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
            "LSTM v2å­¦ç¿’ç’°å¢ƒåˆæœŸåŒ–å®Œäº†\n",
            "å®Ÿé¨“å: trial_44_w64_s16\n",
            "ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®š: w64_s16\n",
            "å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: ../output/experiments/trial_44_w64_s16_w64_s16\n",
            "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿: ../output/experiments/lstm_v2_w64_s16/preprocessed\n",
            "GPUåˆ©ç”¨å¯èƒ½: True\n",
            "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...\n",
            "æœ€é©åŒ–ã•ã‚ŒãŸdemographicsç‰¹å¾´é‡ã‚’ä½¿ç”¨ã—ã¾ã™\n",
            "æœ€é©åŒ–ã•ã‚ŒãŸdemographicså½¢çŠ¶: (13393, 18)\n",
            "ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†:\n",
            "  ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿: (13393, 64, 332)\n",
            "  Demographics: (13393, 18)\n",
            "  ãƒ©ãƒ™ãƒ«: (13393,)\n",
            "  ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹ (èåˆæ–¹å¼: attention)...\n",
            "ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ä¸­...\n",
            "ãƒ†ã‚¹ãƒˆã‚µã‚¤ã‚º: 0.2\n",
            "æ¤œè¨¼ã‚µã‚¤ã‚º: 0.2\n",
            "ãƒ‡ãƒ¼ã‚¿åˆ†å‰²å®Œäº†:\n",
            "  è¨“ç·´ - ã‚»ãƒ³ã‚µãƒ¼: (8571, 64, 332), Demographics: (8571, 18), ãƒ©ãƒ™ãƒ«: (8571,)\n",
            "  æ¤œè¨¼ - ã‚»ãƒ³ã‚µãƒ¼: (2143, 64, 332), Demographics: (2143, 18), ãƒ©ãƒ™ãƒ«: (2143,)\n",
            "  ãƒ†ã‚¹ãƒˆ - ã‚»ãƒ³ã‚µãƒ¼: (2679, 64, 332), Demographics: (2679, 18), ãƒ©ãƒ™ãƒ«: (2679,)\n",
            "å…¥åŠ›å½¢çŠ¶:\n",
            "  ã‚»ãƒ³ã‚µãƒ¼: (64, 332)\n",
            "  Demographics: (18,)\n",
            "  ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "GPUä¸Šã§ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆãƒ»å­¦ç¿’ã—ã¾ã™\n",
            "Mixed precision enabled for better GPU performance\n",
            "GPUåˆ©ç”¨å¯èƒ½: 1å°\n",
            "ä½¿ç”¨GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
            "LSTM v2ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†\n",
            "ã‚»ãƒ³ã‚µãƒ¼å…¥åŠ›å½¢çŠ¶: (64, 332)\n",
            "Demographicså…¥åŠ›å½¢çŠ¶: (18,)\n",
            "ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "èåˆæ–¹å¼: attention\n",
            "GPUåˆ©ç”¨å¯èƒ½: True\n",
            "LSTM v2ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ä¸­...\n",
            "ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰å®Œäº†\n",
            "ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 72,474\n",
            "\n",
            "=== ãƒ¢ãƒ‡ãƒ«ã‚µãƒãƒªãƒ¼ ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"lstm_v2_hybrid\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"lstm_v2_hybrid\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ sensor_input        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">332</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">46,720</span> â”‚ sensor_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_1           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_1      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ lstm_bn_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_input  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">15,552</span> â”‚ lstm_dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">608</span> â”‚ demographics_inpâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_2           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> â”‚ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_2      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ lstm_bn_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dense        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,352</span> â”‚ lstm_dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dropout      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sensor_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_weights   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,584</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attended_sensor     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sensor_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          â”‚                   â”‚            â”‚ attention_weightâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_projeâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,584</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_fusion    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ attended_sensor[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚                   â”‚            â”‚ demographics_proâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dense        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,960</span> â”‚ attention_fusionâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dropout      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ fusion_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">738</span> â”‚ fusion_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ sensor_input        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m332\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)    â”‚     \u001b[38;5;34m46,720\u001b[0m â”‚ sensor_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_1           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)    â”‚        \u001b[38;5;34m128\u001b[0m â”‚ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_1      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ lstm_bn_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_input  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚     \u001b[38;5;34m15,552\u001b[0m â”‚ lstm_dropout_1[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚        \u001b[38;5;34m608\u001b[0m â”‚ demographics_inpâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_2           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚        \u001b[38;5;34m192\u001b[0m â”‚ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_2      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ lstm_bn_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚      \u001b[38;5;34m1,056\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dense        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚      \u001b[38;5;34m2,352\u001b[0m â”‚ lstm_dropout_2[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dropout      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sensor_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_weights   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚      \u001b[38;5;34m1,584\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attended_sensor     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sensor_dropout[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mMultiply\u001b[0m)          â”‚                   â”‚            â”‚ attention_weightâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_projeâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚      \u001b[38;5;34m1,584\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_fusion    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ attended_sensor[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚                   â”‚            â”‚ demographics_proâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dense        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)        â”‚      \u001b[38;5;34m1,960\u001b[0m â”‚ attention_fusionâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dropout      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ fusion_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (\u001b[38;5;33mDense\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        â”‚        \u001b[38;5;34m738\u001b[0m â”‚ fusion_dropout[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">72,474</span> (283.10 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m72,474\u001b[0m (283.10 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">72,314</span> (282.48 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m72,314\u001b[0m (282.48 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> (640.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m160\u001b[0m (640.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹...\n",
            "ã‚»ãƒ³ã‚µãƒ¼è¨“ç·´ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (8571, 64, 332)\n",
            "Demographicsè¨“ç·´ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (8571, 18)\n",
            "ã‚»ãƒ³ã‚µãƒ¼æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (2143, 64, 332)\n",
            "Demographicsæ¤œè¨¼ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (2143, 18)\n",
            "è¨“ç·´ãƒ©ãƒ™ãƒ«å½¢çŠ¶: (8571,)\n",
            "æ¤œè¨¼ãƒ©ãƒ™ãƒ«å½¢çŠ¶: (2143,)\n",
            "Epoch 1/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.1474 - loss: 2.7708\n",
            "Epoch 1: val_loss improved from inf to 2.49528, saving model to ../output/experiments/trial_44_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - accuracy: 0.1475 - loss: 2.7704 - val_accuracy: 0.2305 - val_loss: 2.4953 - learning_rate: 0.0046\n",
            "Epoch 2/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2498 - loss: 2.4133\n",
            "Epoch 2: val_loss improved from 2.49528 to 2.27034, saving model to ../output/experiments/trial_44_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.2498 - loss: 2.4133 - val_accuracy: 0.2800 - val_loss: 2.2703 - learning_rate: 0.0046\n",
            "Epoch 3/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2768 - loss: 2.3012\n",
            "Epoch 3: val_loss improved from 2.27034 to 2.18196, saving model to ../output/experiments/trial_44_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.2768 - loss: 2.3012 - val_accuracy: 0.2986 - val_loss: 2.1820 - learning_rate: 0.0046\n",
            "Epoch 4/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3027 - loss: 2.2196\n",
            "Epoch 4: val_loss did not improve from 2.18196\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - accuracy: 0.3026 - loss: 2.2197 - val_accuracy: 0.2958 - val_loss: 2.2010 - learning_rate: 0.0046\n",
            "Epoch 5/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3098 - loss: 2.1756\n",
            "Epoch 5: val_loss improved from 2.18196 to 2.08862, saving model to ../output/experiments/trial_44_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - accuracy: 0.3098 - loss: 2.1757 - val_accuracy: 0.3308 - val_loss: 2.0886 - learning_rate: 0.0046\n",
            "Epoch 6/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.3313 - loss: 2.1301\n",
            "Epoch 6: val_loss did not improve from 2.08862\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.3313 - loss: 2.1301 - val_accuracy: 0.3252 - val_loss: 2.1437 - learning_rate: 0.0046\n",
            "Epoch 7/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.3449 - loss: 2.1088\n",
            "Epoch 7: val_loss did not improve from 2.08862\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.3449 - loss: 2.1089 - val_accuracy: 0.3388 - val_loss: 2.0891 - learning_rate: 0.0046\n",
            "Epoch 8/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.3418 - loss: 2.0937\n",
            "Epoch 8: val_loss improved from 2.08862 to 2.03233, saving model to ../output/experiments/trial_44_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.3418 - loss: 2.0937 - val_accuracy: 0.3551 - val_loss: 2.0323 - learning_rate: 0.0046\n",
            "Epoch 9/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.3504 - loss: 2.0689\n",
            "Epoch 9: val_loss improved from 2.03233 to 2.02598, saving model to ../output/experiments/trial_44_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - accuracy: 0.3504 - loss: 2.0689 - val_accuracy: 0.3626 - val_loss: 2.0260 - learning_rate: 0.0046\n",
            "Epoch 10/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.3661 - loss: 2.0296\n",
            "Epoch 10: val_loss did not improve from 2.02598\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.3661 - loss: 2.0296 - val_accuracy: 0.3500 - val_loss: 2.0389 - learning_rate: 0.0046\n",
            "Epoch 11/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.3691 - loss: 2.0361\n",
            "Epoch 11: val_loss improved from 2.02598 to 2.00770, saving model to ../output/experiments/trial_44_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.3691 - loss: 2.0362 - val_accuracy: 0.3705 - val_loss: 2.0077 - learning_rate: 0.0046\n",
            "Epoch 12/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.3781 - loss: 1.9921\n",
            "Epoch 12: val_loss improved from 2.00770 to 1.98862, saving model to ../output/experiments/trial_44_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.3781 - loss: 1.9921 - val_accuracy: 0.3752 - val_loss: 1.9886 - learning_rate: 0.0046\n",
            "Epoch 13/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3957 - loss: 1.9316\n",
            "Epoch 13: val_loss improved from 1.98862 to 1.94424, saving model to ../output/experiments/trial_44_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.3957 - loss: 1.9318 - val_accuracy: 0.3915 - val_loss: 1.9442 - learning_rate: 0.0046\n",
            "Epoch 14/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4079 - loss: 1.9077\n",
            "Epoch 14: val_loss did not improve from 1.94424\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.4079 - loss: 1.9078 - val_accuracy: 0.3831 - val_loss: 1.9552 - learning_rate: 0.0046\n",
            "Epoch 15/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.4143 - loss: 1.8798\n",
            "Epoch 15: val_loss improved from 1.94424 to 1.89728, saving model to ../output/experiments/trial_44_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.4143 - loss: 1.8799 - val_accuracy: 0.4125 - val_loss: 1.8973 - learning_rate: 0.0046\n",
            "Epoch 16/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.4136 - loss: 1.8949\n",
            "Epoch 16: val_loss did not improve from 1.89728\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.4135 - loss: 1.8951 - val_accuracy: 0.4050 - val_loss: 1.9215 - learning_rate: 0.0046\n",
            "Epoch 17/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.4224 - loss: 1.8822\n",
            "Epoch 17: val_loss improved from 1.89728 to 1.86957, saving model to ../output/experiments/trial_44_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.4224 - loss: 1.8822 - val_accuracy: 0.4148 - val_loss: 1.8696 - learning_rate: 0.0046\n",
            "Epoch 18/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4245 - loss: 1.8510\n",
            "Epoch 18: val_loss did not improve from 1.86957\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.4246 - loss: 1.8509 - val_accuracy: 0.4060 - val_loss: 1.9528 - learning_rate: 0.0046\n",
            "Epoch 19/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4412 - loss: 1.8190\n",
            "Epoch 19: val_loss did not improve from 1.86957\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.4411 - loss: 1.8191 - val_accuracy: 0.4265 - val_loss: 1.8766 - learning_rate: 0.0046\n",
            "Epoch 20/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4446 - loss: 1.8360\n",
            "Epoch 20: val_loss did not improve from 1.86957\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.4445 - loss: 1.8361 - val_accuracy: 0.4111 - val_loss: 1.9295 - learning_rate: 0.0046\n",
            "Epoch 21/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.4513 - loss: 1.8222\n",
            "Epoch 21: val_loss improved from 1.86957 to 1.83131, saving model to ../output/experiments/trial_44_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.4513 - loss: 1.8223 - val_accuracy: 0.4498 - val_loss: 1.8313 - learning_rate: 0.0046\n",
            "Epoch 22/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.4484 - loss: 1.7774\n",
            "Epoch 22: val_loss did not improve from 1.83131\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.4484 - loss: 1.7775 - val_accuracy: 0.4116 - val_loss: 1.8896 - learning_rate: 0.0046\n",
            "Epoch 23/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.4582 - loss: 1.7862\n",
            "Epoch 23: val_loss improved from 1.83131 to 1.83026, saving model to ../output/experiments/trial_44_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.4581 - loss: 1.7862 - val_accuracy: 0.4442 - val_loss: 1.8303 - learning_rate: 0.0046\n",
            "Epoch 24/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4730 - loss: 1.7800\n",
            "Epoch 24: val_loss improved from 1.83026 to 1.80838, saving model to ../output/experiments/trial_44_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.4730 - loss: 1.7800 - val_accuracy: 0.4386 - val_loss: 1.8084 - learning_rate: 0.0046\n",
            "Epoch 25/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4791 - loss: 1.6969\n",
            "Epoch 25: val_loss improved from 1.80838 to 1.78871, saving model to ../output/experiments/trial_44_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.4791 - loss: 1.6973 - val_accuracy: 0.4433 - val_loss: 1.7887 - learning_rate: 0.0046\n",
            "Epoch 26/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4790 - loss: 1.7371\n",
            "Epoch 26: val_loss improved from 1.78871 to 1.74886, saving model to ../output/experiments/trial_44_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.4790 - loss: 1.7371 - val_accuracy: 0.4657 - val_loss: 1.7489 - learning_rate: 0.0046\n",
            "Epoch 27/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4908 - loss: 1.6909\n",
            "Epoch 27: val_loss did not improve from 1.74886\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.4907 - loss: 1.6912 - val_accuracy: 0.4634 - val_loss: 1.7833 - learning_rate: 0.0046\n",
            "Epoch 28/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4958 - loss: 1.6489\n",
            "Epoch 28: val_loss did not improve from 1.74886\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.4958 - loss: 1.6490 - val_accuracy: 0.4522 - val_loss: 1.7825 - learning_rate: 0.0046\n",
            "Epoch 29/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4839 - loss: 1.6907\n",
            "Epoch 29: val_loss did not improve from 1.74886\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.4839 - loss: 1.6906 - val_accuracy: 0.4699 - val_loss: 1.7850 - learning_rate: 0.0046\n",
            "Epoch 30/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5032 - loss: 1.6590\n",
            "Epoch 30: val_loss did not improve from 1.74886\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.5032 - loss: 1.6591 - val_accuracy: 0.4657 - val_loss: 1.7849 - learning_rate: 0.0046\n",
            "Epoch 31/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4956 - loss: 1.6643\n",
            "Epoch 31: val_loss did not improve from 1.74886\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.4956 - loss: 1.6644 - val_accuracy: 0.4531 - val_loss: 1.8077 - learning_rate: 0.0046\n",
            "Epoch 32/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4944 - loss: 1.6789\n",
            "Epoch 32: val_loss did not improve from 1.74886\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.4945 - loss: 1.6789 - val_accuracy: 0.4662 - val_loss: 1.7894 - learning_rate: 0.0046\n",
            "Epoch 33/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5114 - loss: 1.6368\n",
            "Epoch 33: val_loss did not improve from 1.74886\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.5114 - loss: 1.6370 - val_accuracy: 0.4676 - val_loss: 1.7567 - learning_rate: 0.0046\n",
            "Epoch 34/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5165 - loss: 1.6343\n",
            "Epoch 34: val_loss did not improve from 1.74886\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.5164 - loss: 1.6345 - val_accuracy: 0.4736 - val_loss: 1.7536 - learning_rate: 0.0046\n",
            "Epoch 35/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5090 - loss: 1.6390\n",
            "Epoch 35: val_loss did not improve from 1.74886\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5089 - loss: 1.6391 - val_accuracy: 0.4760 - val_loss: 1.7965 - learning_rate: 0.0046\n",
            "Epoch 36/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5207 - loss: 1.6244\n",
            "Epoch 36: val_loss did not improve from 1.74886\n",
            "\n",
            "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.002312656491994858.\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5207 - loss: 1.6246 - val_accuracy: 0.4839 - val_loss: 1.7490 - learning_rate: 0.0046\n",
            "Epoch 37/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5355 - loss: 1.5701\n",
            "Epoch 37: val_loss improved from 1.74886 to 1.68323, saving model to ../output/experiments/trial_44_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.5355 - loss: 1.5701 - val_accuracy: 0.5049 - val_loss: 1.6832 - learning_rate: 0.0023\n",
            "Epoch 38/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5654 - loss: 1.4740\n",
            "Epoch 38: val_loss did not improve from 1.68323\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.5654 - loss: 1.4740 - val_accuracy: 0.4923 - val_loss: 1.7019 - learning_rate: 0.0023\n",
            "Epoch 39/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5843 - loss: 1.4115\n",
            "Epoch 39: val_loss did not improve from 1.68323\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.5842 - loss: 1.4117 - val_accuracy: 0.4998 - val_loss: 1.7056 - learning_rate: 0.0023\n",
            "Epoch 40/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5683 - loss: 1.4265\n",
            "Epoch 40: val_loss improved from 1.68323 to 1.64794, saving model to ../output/experiments/trial_44_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.5683 - loss: 1.4265 - val_accuracy: 0.5138 - val_loss: 1.6479 - learning_rate: 0.0023\n",
            "Epoch 41/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5797 - loss: 1.3741\n",
            "Epoch 41: val_loss did not improve from 1.64794\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5796 - loss: 1.3743 - val_accuracy: 0.5198 - val_loss: 1.6731 - learning_rate: 0.0023\n",
            "Epoch 42/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5846 - loss: 1.3720\n",
            "Epoch 42: val_loss did not improve from 1.64794\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5846 - loss: 1.3720 - val_accuracy: 0.5152 - val_loss: 1.6641 - learning_rate: 0.0023\n",
            "Epoch 43/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5934 - loss: 1.3401\n",
            "Epoch 43: val_loss did not improve from 1.64794\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.5934 - loss: 1.3401 - val_accuracy: 0.5138 - val_loss: 1.6553 - learning_rate: 0.0023\n",
            "Epoch 44/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5997 - loss: 1.3164\n",
            "Epoch 44: val_loss did not improve from 1.64794\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.5997 - loss: 1.3165 - val_accuracy: 0.5175 - val_loss: 1.6549 - learning_rate: 0.0023\n",
            "Epoch 45/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6121 - loss: 1.3196\n",
            "Epoch 45: val_loss improved from 1.64794 to 1.61318, saving model to ../output/experiments/trial_44_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.6120 - loss: 1.3198 - val_accuracy: 0.5147 - val_loss: 1.6132 - learning_rate: 0.0023\n",
            "Epoch 46/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6152 - loss: 1.2960\n",
            "Epoch 46: val_loss did not improve from 1.61318\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.6151 - loss: 1.2961 - val_accuracy: 0.5142 - val_loss: 1.6948 - learning_rate: 0.0023\n",
            "Epoch 47/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6124 - loss: 1.3061\n",
            "Epoch 47: val_loss did not improve from 1.61318\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.6123 - loss: 1.3062 - val_accuracy: 0.5282 - val_loss: 1.6285 - learning_rate: 0.0023\n",
            "Epoch 48/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6165 - loss: 1.2848\n",
            "Epoch 48: val_loss did not improve from 1.61318\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.6164 - loss: 1.2850 - val_accuracy: 0.5245 - val_loss: 1.6860 - learning_rate: 0.0023\n",
            "Epoch 49/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6217 - loss: 1.2643\n",
            "Epoch 49: val_loss did not improve from 1.61318\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.6217 - loss: 1.2643 - val_accuracy: 0.5306 - val_loss: 1.6529 - learning_rate: 0.0023\n",
            "Epoch 50/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6300 - loss: 1.2283\n",
            "Epoch 50: val_loss did not improve from 1.61318\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.6300 - loss: 1.2284 - val_accuracy: 0.5236 - val_loss: 1.6430 - learning_rate: 0.0023\n",
            "Epoch 51/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6344 - loss: 1.2606\n",
            "Epoch 51: val_loss did not improve from 1.61318\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.6343 - loss: 1.2607 - val_accuracy: 0.5296 - val_loss: 1.6167 - learning_rate: 0.0023\n",
            "Epoch 52/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6301 - loss: 1.2569\n",
            "Epoch 52: val_loss did not improve from 1.61318\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.6301 - loss: 1.2569 - val_accuracy: 0.5385 - val_loss: 1.6143 - learning_rate: 0.0023\n",
            "Epoch 53/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6250 - loss: 1.2612\n",
            "Epoch 53: val_loss did not improve from 1.61318\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.6250 - loss: 1.2611 - val_accuracy: 0.5404 - val_loss: 1.6322 - learning_rate: 0.0023\n",
            "Epoch 54/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6311 - loss: 1.2389\n",
            "Epoch 54: val_loss improved from 1.61318 to 1.60332, saving model to ../output/experiments/trial_44_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6311 - loss: 1.2389 - val_accuracy: 0.5427 - val_loss: 1.6033 - learning_rate: 0.0023\n",
            "Epoch 55/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6444 - loss: 1.2062\n",
            "Epoch 55: val_loss improved from 1.60332 to 1.60061, saving model to ../output/experiments/trial_44_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.6443 - loss: 1.2062 - val_accuracy: 0.5329 - val_loss: 1.6006 - learning_rate: 0.0023\n",
            "Epoch 56/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6289 - loss: 1.2223\n",
            "Epoch 56: val_loss did not improve from 1.60061\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6290 - loss: 1.2223 - val_accuracy: 0.5352 - val_loss: 1.6081 - learning_rate: 0.0023\n",
            "Epoch 57/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6397 - loss: 1.1901\n",
            "Epoch 57: val_loss did not improve from 1.60061\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.6397 - loss: 1.1902 - val_accuracy: 0.5301 - val_loss: 1.6659 - learning_rate: 0.0023\n",
            "Epoch 58/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6422 - loss: 1.1730\n",
            "Epoch 58: val_loss did not improve from 1.60061\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.6422 - loss: 1.1730 - val_accuracy: 0.5334 - val_loss: 1.6461 - learning_rate: 0.0023\n",
            "Epoch 59/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6474 - loss: 1.1908\n",
            "Epoch 59: val_loss did not improve from 1.60061\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.6474 - loss: 1.1908 - val_accuracy: 0.5194 - val_loss: 1.7100 - learning_rate: 0.0023\n",
            "Epoch 60/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6452 - loss: 1.1903\n",
            "Epoch 60: val_loss improved from 1.60061 to 1.59477, saving model to ../output/experiments/trial_44_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6452 - loss: 1.1903 - val_accuracy: 0.5497 - val_loss: 1.5948 - learning_rate: 0.0023\n",
            "Epoch 61/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6519 - loss: 1.1607\n",
            "Epoch 61: val_loss did not improve from 1.59477\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6519 - loss: 1.1607 - val_accuracy: 0.5558 - val_loss: 1.6425 - learning_rate: 0.0023\n",
            "Epoch 62/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6588 - loss: 1.1552\n",
            "Epoch 62: val_loss did not improve from 1.59477\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6587 - loss: 1.1555 - val_accuracy: 0.5231 - val_loss: 1.6687 - learning_rate: 0.0023\n",
            "Epoch 63/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6484 - loss: 1.1956\n",
            "Epoch 63: val_loss did not improve from 1.59477\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.6484 - loss: 1.1957 - val_accuracy: 0.5315 - val_loss: 1.6613 - learning_rate: 0.0023\n",
            "Epoch 64/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6421 - loss: 1.1814\n",
            "Epoch 64: val_loss did not improve from 1.59477\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.6421 - loss: 1.1814 - val_accuracy: 0.5446 - val_loss: 1.6185 - learning_rate: 0.0023\n",
            "Epoch 65/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6600 - loss: 1.1443\n",
            "Epoch 65: val_loss did not improve from 1.59477\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.6600 - loss: 1.1444 - val_accuracy: 0.5394 - val_loss: 1.6744 - learning_rate: 0.0023\n",
            "Epoch 66/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6526 - loss: 1.1674\n",
            "Epoch 66: val_loss did not improve from 1.59477\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6526 - loss: 1.1674 - val_accuracy: 0.5418 - val_loss: 1.6671 - learning_rate: 0.0023\n",
            "Epoch 67/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6554 - loss: 1.1696\n",
            "Epoch 67: val_loss improved from 1.59477 to 1.57694, saving model to ../output/experiments/trial_44_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.6554 - loss: 1.1697 - val_accuracy: 0.5390 - val_loss: 1.5769 - learning_rate: 0.0023\n",
            "Epoch 68/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6675 - loss: 1.1305\n",
            "Epoch 68: val_loss did not improve from 1.57694\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.6674 - loss: 1.1307 - val_accuracy: 0.5296 - val_loss: 1.6574 - learning_rate: 0.0023\n",
            "Epoch 69/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6739 - loss: 1.1384\n",
            "Epoch 69: val_loss did not improve from 1.57694\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.6739 - loss: 1.1383 - val_accuracy: 0.5469 - val_loss: 1.6375 - learning_rate: 0.0023\n",
            "Epoch 70/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6803 - loss: 1.1022\n",
            "Epoch 70: val_loss did not improve from 1.57694\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.6803 - loss: 1.1023 - val_accuracy: 0.5408 - val_loss: 1.6337 - learning_rate: 0.0023\n",
            "Epoch 71/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6762 - loss: 1.1244\n",
            "Epoch 71: val_loss did not improve from 1.57694\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6762 - loss: 1.1244 - val_accuracy: 0.5516 - val_loss: 1.6311 - learning_rate: 0.0023\n",
            "Epoch 72/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6906 - loss: 1.0769\n",
            "Epoch 72: val_loss did not improve from 1.57694\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.6905 - loss: 1.0770 - val_accuracy: 0.5492 - val_loss: 1.6890 - learning_rate: 0.0023\n",
            "Epoch 73/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6822 - loss: 1.1243\n",
            "Epoch 73: val_loss did not improve from 1.57694\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6822 - loss: 1.1242 - val_accuracy: 0.5474 - val_loss: 1.6362 - learning_rate: 0.0023\n",
            "Epoch 74/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6827 - loss: 1.1056\n",
            "Epoch 74: val_loss did not improve from 1.57694\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.6827 - loss: 1.1056 - val_accuracy: 0.5558 - val_loss: 1.6643 - learning_rate: 0.0023\n",
            "Epoch 75/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6863 - loss: 1.0999\n",
            "Epoch 75: val_loss did not improve from 1.57694\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.6862 - loss: 1.1000 - val_accuracy: 0.5450 - val_loss: 1.6349 - learning_rate: 0.0023\n",
            "Epoch 76/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6978 - loss: 1.0690\n",
            "Epoch 76: val_loss did not improve from 1.57694\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6977 - loss: 1.0691 - val_accuracy: 0.5516 - val_loss: 1.6116 - learning_rate: 0.0023\n",
            "Epoch 77/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6867 - loss: 1.0715\n",
            "Epoch 77: val_loss did not improve from 1.57694\n",
            "\n",
            "Epoch 77: ReduceLROnPlateau reducing learning rate to 0.001156328245997429.\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.6867 - loss: 1.0716 - val_accuracy: 0.5595 - val_loss: 1.6181 - learning_rate: 0.0023\n",
            "Epoch 78/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7171 - loss: 1.0119\n",
            "Epoch 78: val_loss did not improve from 1.57694\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.7171 - loss: 1.0119 - val_accuracy: 0.5721 - val_loss: 1.6388 - learning_rate: 0.0012\n",
            "Epoch 79/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7252 - loss: 0.9703\n",
            "Epoch 79: val_loss did not improve from 1.57694\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.7252 - loss: 0.9704 - val_accuracy: 0.5716 - val_loss: 1.6134 - learning_rate: 0.0012\n",
            "Epoch 80/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7386 - loss: 0.9503\n",
            "Epoch 80: val_loss did not improve from 1.57694\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.7386 - loss: 0.9503 - val_accuracy: 0.5791 - val_loss: 1.6413 - learning_rate: 0.0012\n",
            "Epoch 81/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7380 - loss: 0.9392\n",
            "Epoch 81: val_loss did not improve from 1.57694\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.7380 - loss: 0.9392 - val_accuracy: 0.5805 - val_loss: 1.6366 - learning_rate: 0.0012\n",
            "Epoch 82/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7367 - loss: 0.9378\n",
            "Epoch 82: val_loss did not improve from 1.57694\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.7367 - loss: 0.9378 - val_accuracy: 0.5777 - val_loss: 1.6961 - learning_rate: 0.0012\n",
            "Epoch 83/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7420 - loss: 0.9355\n",
            "Epoch 83: val_loss did not improve from 1.57694\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.7420 - loss: 0.9355 - val_accuracy: 0.5772 - val_loss: 1.6412 - learning_rate: 0.0012\n",
            "Epoch 84/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7496 - loss: 0.9066\n",
            "Epoch 84: val_loss did not improve from 1.57694\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.7496 - loss: 0.9067 - val_accuracy: 0.5898 - val_loss: 1.6112 - learning_rate: 0.0012\n",
            "Epoch 85/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7499 - loss: 0.9026\n",
            "Epoch 85: val_loss did not improve from 1.57694\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.7499 - loss: 0.9026 - val_accuracy: 0.5800 - val_loss: 1.7217 - learning_rate: 0.0012\n",
            "Epoch 86/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7261 - loss: 0.9613\n",
            "Epoch 86: val_loss did not improve from 1.57694\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.7262 - loss: 0.9612 - val_accuracy: 0.5847 - val_loss: 1.6716 - learning_rate: 0.0012\n",
            "Epoch 87/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7525 - loss: 0.9093\n",
            "Epoch 87: val_loss did not improve from 1.57694\n",
            "\n",
            "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0005781641229987144.\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.7526 - loss: 0.9092 - val_accuracy: 0.5763 - val_loss: 1.7153 - learning_rate: 0.0012\n",
            "Epoch 87: early stopping\n",
            "Restoring model weights from the end of the best epoch: 67.\n",
            "å­¦ç¿’å®Œäº†ï¼å­¦ç¿’æ™‚é–“: 822.32ç§’\n",
            "æœ€è‰¯æ¤œè¨¼Loss: 1.5769\n",
            "æœ€è‰¯æ¤œè¨¼Accuracy: 0.5898\n",
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ä¸­...\n",
            "ãƒ†ã‚¹ãƒˆLoss: 1.5333\n",
            "ãƒ†ã‚¹ãƒˆAccuracy: 0.5670\n",
            "F1-Score (macro): 0.5054\n",
            "F1-Score (weighted): 0.5518\n",
            "çµæœä¿å­˜ä¸­...\n",
            "å­¦ç¿’å±¥æ­´ä¿å­˜å®Œäº†: ../output/experiments/trial_44_w64_s16_w64_s16/results/training_history_attention.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-08 23:22:12,620] Trial 44 finished with value: 0.7724825122803745 and parameters: {'lstm_units_1': 32, 'lstm_units_2': 48, 'dense_units': 48, 'demographics_dense_units': 32, 'fusion_dense_units': 40, 'dropout_rate': 0.2, 'dense_dropout_rate': 0.2, 'learning_rate': 0.004625313057377727, 'batch_size': 32, 'fusion_type': 'attention'}. Best is trial 34 with value: 0.8021217206997858.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "çµæœä¿å­˜å®Œäº†: ../output/experiments/trial_44_w64_s16_w64_s16/results\n",
            "âœ… Trial 44: CMI=0.7725, Binary F1=0.9486, Fusion=attention\n",
            "\n",
            "ğŸ” Trial 45 - w64_s16\n",
            "Mixed precision enabled for better GPU performance\n",
            "GPUåˆ©ç”¨å¯èƒ½: 1å°\n",
            "ä½¿ç”¨GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
            "LSTM v2å­¦ç¿’ç’°å¢ƒåˆæœŸåŒ–å®Œäº†\n",
            "å®Ÿé¨“å: trial_45_w64_s16\n",
            "ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®š: w64_s16\n",
            "å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: ../output/experiments/trial_45_w64_s16_w64_s16\n",
            "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿: ../output/experiments/lstm_v2_w64_s16/preprocessed\n",
            "GPUåˆ©ç”¨å¯èƒ½: True\n",
            "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...\n",
            "æœ€é©åŒ–ã•ã‚ŒãŸdemographicsç‰¹å¾´é‡ã‚’ä½¿ç”¨ã—ã¾ã™\n",
            "æœ€é©åŒ–ã•ã‚ŒãŸdemographicså½¢çŠ¶: (13393, 18)\n",
            "ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†:\n",
            "  ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿: (13393, 64, 332)\n",
            "  Demographics: (13393, 18)\n",
            "  ãƒ©ãƒ™ãƒ«: (13393,)\n",
            "  ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹ (èåˆæ–¹å¼: attention)...\n",
            "ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ä¸­...\n",
            "ãƒ†ã‚¹ãƒˆã‚µã‚¤ã‚º: 0.2\n",
            "æ¤œè¨¼ã‚µã‚¤ã‚º: 0.2\n",
            "ãƒ‡ãƒ¼ã‚¿åˆ†å‰²å®Œäº†:\n",
            "  è¨“ç·´ - ã‚»ãƒ³ã‚µãƒ¼: (8571, 64, 332), Demographics: (8571, 18), ãƒ©ãƒ™ãƒ«: (8571,)\n",
            "  æ¤œè¨¼ - ã‚»ãƒ³ã‚µãƒ¼: (2143, 64, 332), Demographics: (2143, 18), ãƒ©ãƒ™ãƒ«: (2143,)\n",
            "  ãƒ†ã‚¹ãƒˆ - ã‚»ãƒ³ã‚µãƒ¼: (2679, 64, 332), Demographics: (2679, 18), ãƒ©ãƒ™ãƒ«: (2679,)\n",
            "å…¥åŠ›å½¢çŠ¶:\n",
            "  ã‚»ãƒ³ã‚µãƒ¼: (64, 332)\n",
            "  Demographics: (18,)\n",
            "  ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "GPUä¸Šã§ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆãƒ»å­¦ç¿’ã—ã¾ã™\n",
            "Mixed precision enabled for better GPU performance\n",
            "GPUåˆ©ç”¨å¯èƒ½: 1å°\n",
            "ä½¿ç”¨GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
            "LSTM v2ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†\n",
            "ã‚»ãƒ³ã‚µãƒ¼å…¥åŠ›å½¢çŠ¶: (64, 332)\n",
            "Demographicså…¥åŠ›å½¢çŠ¶: (18,)\n",
            "ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "èåˆæ–¹å¼: attention\n",
            "GPUåˆ©ç”¨å¯èƒ½: True\n",
            "LSTM v2ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ä¸­...\n",
            "ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰å®Œäº†\n",
            "ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 140,618\n",
            "\n",
            "=== ãƒ¢ãƒ‡ãƒ«ã‚µãƒãƒªãƒ¼ ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"lstm_v2_hybrid\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"lstm_v2_hybrid\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ sensor_input        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">332</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">101,632</span> â”‚ sensor_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_1           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_1      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ lstm_bn_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_input  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">27,104</span> â”‚ lstm_dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">532</span> â”‚ demographics_inpâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_2           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> â”‚ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_2      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ lstm_bn_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">812</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dense        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,192</span> â”‚ lstm_dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dropout      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sensor_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_weights   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,624</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attended_sensor     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sensor_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          â”‚                   â”‚            â”‚ attention_weightâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_projeâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,624</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_fusion    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ attended_sensor[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚                   â”‚            â”‚ demographics_proâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dense        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,736</span> â”‚ attention_fusionâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dropout      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ fusion_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">882</span> â”‚ fusion_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ sensor_input        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m332\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚    \u001b[38;5;34m101,632\u001b[0m â”‚ sensor_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_1           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚        \u001b[38;5;34m256\u001b[0m â”‚ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_1      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ lstm_bn_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_input  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        â”‚     \u001b[38;5;34m27,104\u001b[0m â”‚ lstm_dropout_1[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)        â”‚        \u001b[38;5;34m532\u001b[0m â”‚ demographics_inpâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_2           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        â”‚        \u001b[38;5;34m224\u001b[0m â”‚ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_2      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ lstm_bn_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)        â”‚        \u001b[38;5;34m812\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dense        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        â”‚      \u001b[38;5;34m3,192\u001b[0m â”‚ lstm_dropout_2[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dropout      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sensor_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_weights   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        â”‚      \u001b[38;5;34m1,624\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attended_sensor     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sensor_dropout[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mMultiply\u001b[0m)          â”‚                   â”‚            â”‚ attention_weightâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_projeâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        â”‚      \u001b[38;5;34m1,624\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_fusion    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ attended_sensor[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚                   â”‚            â”‚ demographics_proâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dense        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚      \u001b[38;5;34m2,736\u001b[0m â”‚ attention_fusionâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dropout      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ fusion_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (\u001b[38;5;33mDense\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        â”‚        \u001b[38;5;34m882\u001b[0m â”‚ fusion_dropout[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">140,618</span> (549.29 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m140,618\u001b[0m (549.29 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">140,378</span> (548.35 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m140,378\u001b[0m (548.35 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> (960.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m240\u001b[0m (960.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹...\n",
            "ã‚»ãƒ³ã‚µãƒ¼è¨“ç·´ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (8571, 64, 332)\n",
            "Demographicsè¨“ç·´ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (8571, 18)\n",
            "ã‚»ãƒ³ã‚µãƒ¼æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (2143, 64, 332)\n",
            "Demographicsæ¤œè¨¼ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (2143, 18)\n",
            "è¨“ç·´ãƒ©ãƒ™ãƒ«å½¢çŠ¶: (8571,)\n",
            "æ¤œè¨¼ãƒ©ãƒ™ãƒ«å½¢çŠ¶: (2143,)\n",
            "Epoch 1/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.1340 - loss: 2.7996\n",
            "Epoch 1: val_loss improved from inf to 2.45895, saving model to ../output/experiments/trial_45_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 47ms/step - accuracy: 0.1342 - loss: 2.7991 - val_accuracy: 0.2147 - val_loss: 2.4589 - learning_rate: 0.0023\n",
            "Epoch 2/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.2280 - loss: 2.4185\n",
            "Epoch 2: val_loss improved from 2.45895 to 2.23512, saving model to ../output/experiments/trial_45_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.2281 - loss: 2.4181 - val_accuracy: 0.2641 - val_loss: 2.2351 - learning_rate: 0.0023\n",
            "Epoch 3/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.2824 - loss: 2.2131\n",
            "Epoch 3: val_loss improved from 2.23512 to 2.06397, saving model to ../output/experiments/trial_45_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.2824 - loss: 2.2129 - val_accuracy: 0.3061 - val_loss: 2.0640 - learning_rate: 0.0023\n",
            "Epoch 4/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3159 - loss: 2.0798\n",
            "Epoch 4: val_loss improved from 2.06397 to 2.02875, saving model to ../output/experiments/trial_45_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.3159 - loss: 2.0799 - val_accuracy: 0.3378 - val_loss: 2.0287 - learning_rate: 0.0023\n",
            "Epoch 5/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3459 - loss: 2.0581\n",
            "Epoch 5: val_loss did not improve from 2.02875\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.3459 - loss: 2.0581 - val_accuracy: 0.3444 - val_loss: 2.1011 - learning_rate: 0.0023\n",
            "Epoch 6/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3436 - loss: 2.0120\n",
            "Epoch 6: val_loss improved from 2.02875 to 1.99167, saving model to ../output/experiments/trial_45_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.3436 - loss: 2.0119 - val_accuracy: 0.3607 - val_loss: 1.9917 - learning_rate: 0.0023\n",
            "Epoch 7/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3834 - loss: 1.8985\n",
            "Epoch 7: val_loss improved from 1.99167 to 1.92628, saving model to ../output/experiments/trial_45_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.3834 - loss: 1.8986 - val_accuracy: 0.3682 - val_loss: 1.9263 - learning_rate: 0.0023\n",
            "Epoch 8/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3908 - loss: 1.8649\n",
            "Epoch 8: val_loss improved from 1.92628 to 1.90978, saving model to ../output/experiments/trial_45_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.3907 - loss: 1.8650 - val_accuracy: 0.3700 - val_loss: 1.9098 - learning_rate: 0.0023\n",
            "Epoch 9/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3945 - loss: 1.8267\n",
            "Epoch 9: val_loss improved from 1.90978 to 1.86654, saving model to ../output/experiments/trial_45_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.3945 - loss: 1.8267 - val_accuracy: 0.3980 - val_loss: 1.8665 - learning_rate: 0.0023\n",
            "Epoch 10/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4340 - loss: 1.7365\n",
            "Epoch 10: val_loss did not improve from 1.86654\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4340 - loss: 1.7366 - val_accuracy: 0.3948 - val_loss: 1.9160 - learning_rate: 0.0023\n",
            "Epoch 11/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4332 - loss: 1.7517\n",
            "Epoch 11: val_loss improved from 1.86654 to 1.83362, saving model to ../output/experiments/trial_45_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4332 - loss: 1.7517 - val_accuracy: 0.4130 - val_loss: 1.8336 - learning_rate: 0.0023\n",
            "Epoch 12/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4388 - loss: 1.7104\n",
            "Epoch 12: val_loss improved from 1.83362 to 1.80914, saving model to ../output/experiments/trial_45_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.4389 - loss: 1.7104 - val_accuracy: 0.4204 - val_loss: 1.8091 - learning_rate: 0.0023\n",
            "Epoch 13/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4687 - loss: 1.6675\n",
            "Epoch 13: val_loss improved from 1.80914 to 1.78762, saving model to ../output/experiments/trial_45_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.4686 - loss: 1.6677 - val_accuracy: 0.4344 - val_loss: 1.7876 - learning_rate: 0.0023\n",
            "Epoch 14/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4739 - loss: 1.6462\n",
            "Epoch 14: val_loss improved from 1.78762 to 1.73633, saving model to ../output/experiments/trial_45_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.4739 - loss: 1.6461 - val_accuracy: 0.4620 - val_loss: 1.7363 - learning_rate: 0.0023\n",
            "Epoch 15/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5085 - loss: 1.5488\n",
            "Epoch 15: val_loss did not improve from 1.73633\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5084 - loss: 1.5490 - val_accuracy: 0.4489 - val_loss: 1.7535 - learning_rate: 0.0023\n",
            "Epoch 16/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5096 - loss: 1.5448\n",
            "Epoch 16: val_loss did not improve from 1.73633\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5096 - loss: 1.5449 - val_accuracy: 0.4564 - val_loss: 1.7674 - learning_rate: 0.0023\n",
            "Epoch 17/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5123 - loss: 1.5306\n",
            "Epoch 17: val_loss did not improve from 1.73633\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5122 - loss: 1.5310 - val_accuracy: 0.4820 - val_loss: 1.7677 - learning_rate: 0.0023\n",
            "Epoch 18/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5160 - loss: 1.5383\n",
            "Epoch 18: val_loss improved from 1.73633 to 1.72305, saving model to ../output/experiments/trial_45_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.5160 - loss: 1.5384 - val_accuracy: 0.4816 - val_loss: 1.7231 - learning_rate: 0.0023\n",
            "Epoch 19/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5356 - loss: 1.4909\n",
            "Epoch 19: val_loss improved from 1.72305 to 1.66821, saving model to ../output/experiments/trial_45_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.5355 - loss: 1.4911 - val_accuracy: 0.4914 - val_loss: 1.6682 - learning_rate: 0.0023\n",
            "Epoch 20/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5322 - loss: 1.5046\n",
            "Epoch 20: val_loss did not improve from 1.66821\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.5322 - loss: 1.5047 - val_accuracy: 0.4867 - val_loss: 1.7318 - learning_rate: 0.0023\n",
            "Epoch 21/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5447 - loss: 1.4759\n",
            "Epoch 21: val_loss did not improve from 1.66821\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.5447 - loss: 1.4760 - val_accuracy: 0.4979 - val_loss: 1.7116 - learning_rate: 0.0023\n",
            "Epoch 22/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5642 - loss: 1.4321\n",
            "Epoch 22: val_loss did not improve from 1.66821\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.5641 - loss: 1.4323 - val_accuracy: 0.4914 - val_loss: 1.7726 - learning_rate: 0.0023\n",
            "Epoch 23/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5511 - loss: 1.4893\n",
            "Epoch 23: val_loss did not improve from 1.66821\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.5512 - loss: 1.4891 - val_accuracy: 0.4904 - val_loss: 1.6831 - learning_rate: 0.0023\n",
            "Epoch 24/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5815 - loss: 1.3846\n",
            "Epoch 24: val_loss did not improve from 1.66821\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.5815 - loss: 1.3847 - val_accuracy: 0.5082 - val_loss: 1.6767 - learning_rate: 0.0023\n",
            "Epoch 25/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5899 - loss: 1.3853\n",
            "Epoch 25: val_loss did not improve from 1.66821\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.5899 - loss: 1.3855 - val_accuracy: 0.5231 - val_loss: 1.6814 - learning_rate: 0.0023\n",
            "Epoch 26/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6063 - loss: 1.3513\n",
            "Epoch 26: val_loss did not improve from 1.66821\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.6063 - loss: 1.3514 - val_accuracy: 0.4886 - val_loss: 1.7791 - learning_rate: 0.0023\n",
            "Epoch 27/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5965 - loss: 1.3851\n",
            "Epoch 27: val_loss did not improve from 1.66821\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.5964 - loss: 1.3851 - val_accuracy: 0.5175 - val_loss: 1.6868 - learning_rate: 0.0023\n",
            "Epoch 28/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5956 - loss: 1.3730\n",
            "Epoch 28: val_loss did not improve from 1.66821\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.5955 - loss: 1.3731 - val_accuracy: 0.5114 - val_loss: 1.6938 - learning_rate: 0.0023\n",
            "Epoch 29/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5724 - loss: 1.4860\n",
            "Epoch 29: val_loss did not improve from 1.66821\n",
            "\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0011680718744173646.\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.5723 - loss: 1.4860 - val_accuracy: 0.5105 - val_loss: 1.7219 - learning_rate: 0.0023\n",
            "Epoch 30/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6101 - loss: 1.3344\n",
            "Epoch 30: val_loss improved from 1.66821 to 1.65583, saving model to ../output/experiments/trial_45_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.6102 - loss: 1.3341 - val_accuracy: 0.5506 - val_loss: 1.6558 - learning_rate: 0.0012\n",
            "Epoch 31/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6388 - loss: 1.2265\n",
            "Epoch 31: val_loss did not improve from 1.65583\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.6389 - loss: 1.2264 - val_accuracy: 0.5506 - val_loss: 1.6626 - learning_rate: 0.0012\n",
            "Epoch 32/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6612 - loss: 1.1670\n",
            "Epoch 32: val_loss did not improve from 1.65583\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.6612 - loss: 1.1670 - val_accuracy: 0.5460 - val_loss: 1.6672 - learning_rate: 0.0012\n",
            "Epoch 33/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6919 - loss: 1.1178\n",
            "Epoch 33: val_loss did not improve from 1.65583\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.6918 - loss: 1.1180 - val_accuracy: 0.5609 - val_loss: 1.6866 - learning_rate: 0.0012\n",
            "Epoch 34/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6959 - loss: 1.1233\n",
            "Epoch 34: val_loss did not improve from 1.65583\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.6959 - loss: 1.1233 - val_accuracy: 0.5464 - val_loss: 1.6771 - learning_rate: 0.0012\n",
            "Epoch 35/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7021 - loss: 1.0802\n",
            "Epoch 35: val_loss did not improve from 1.65583\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.7021 - loss: 1.0802 - val_accuracy: 0.5702 - val_loss: 1.6702 - learning_rate: 0.0012\n",
            "Epoch 36/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6966 - loss: 1.0612\n",
            "Epoch 36: val_loss did not improve from 1.65583\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.6967 - loss: 1.0613 - val_accuracy: 0.5539 - val_loss: 1.7174 - learning_rate: 0.0012\n",
            "Epoch 37/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7156 - loss: 1.0269\n",
            "Epoch 37: val_loss did not improve from 1.65583\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.7156 - loss: 1.0270 - val_accuracy: 0.5632 - val_loss: 1.6994 - learning_rate: 0.0012\n",
            "Epoch 38/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7204 - loss: 1.0224\n",
            "Epoch 38: val_loss did not improve from 1.65583\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.7204 - loss: 1.0224 - val_accuracy: 0.5562 - val_loss: 1.7806 - learning_rate: 0.0012\n",
            "Epoch 39/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7142 - loss: 1.0284\n",
            "Epoch 39: val_loss did not improve from 1.65583\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.7142 - loss: 1.0283 - val_accuracy: 0.5670 - val_loss: 1.7202 - learning_rate: 0.0012\n",
            "Epoch 40/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7285 - loss: 0.9941\n",
            "Epoch 40: val_loss did not improve from 1.65583\n",
            "\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0005840359372086823.\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.7285 - loss: 0.9943 - val_accuracy: 0.5852 - val_loss: 1.7141 - learning_rate: 0.0012\n",
            "Epoch 41/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7492 - loss: 0.9426\n",
            "Epoch 41: val_loss did not improve from 1.65583\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.7493 - loss: 0.9426 - val_accuracy: 0.5875 - val_loss: 1.6753 - learning_rate: 5.8404e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7652 - loss: 0.9045\n",
            "Epoch 42: val_loss did not improve from 1.65583\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.7652 - loss: 0.9046 - val_accuracy: 0.5908 - val_loss: 1.7353 - learning_rate: 5.8404e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7797 - loss: 0.8823\n",
            "Epoch 43: val_loss did not improve from 1.65583\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.7797 - loss: 0.8823 - val_accuracy: 0.6048 - val_loss: 1.7098 - learning_rate: 5.8404e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7779 - loss: 0.8728\n",
            "Epoch 44: val_loss did not improve from 1.65583\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.7779 - loss: 0.8728 - val_accuracy: 0.5950 - val_loss: 1.7454 - learning_rate: 5.8404e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7843 - loss: 0.8527\n",
            "Epoch 45: val_loss did not improve from 1.65583\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.7843 - loss: 0.8527 - val_accuracy: 0.5898 - val_loss: 1.7551 - learning_rate: 5.8404e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7953 - loss: 0.8349\n",
            "Epoch 46: val_loss did not improve from 1.65583\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.7953 - loss: 0.8349 - val_accuracy: 0.6052 - val_loss: 1.7636 - learning_rate: 5.8404e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7959 - loss: 0.8191\n",
            "Epoch 47: val_loss did not improve from 1.65583\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.7959 - loss: 0.8191 - val_accuracy: 0.5987 - val_loss: 1.8088 - learning_rate: 5.8404e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8043 - loss: 0.7902\n",
            "Epoch 48: val_loss did not improve from 1.65583\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.8043 - loss: 0.7903 - val_accuracy: 0.5880 - val_loss: 1.8396 - learning_rate: 5.8404e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7949 - loss: 0.8037\n",
            "Epoch 49: val_loss did not improve from 1.65583\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.7949 - loss: 0.8038 - val_accuracy: 0.6001 - val_loss: 1.8184 - learning_rate: 5.8404e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7924 - loss: 0.8132\n",
            "Epoch 50: val_loss did not improve from 1.65583\n",
            "\n",
            "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00029201796860434115.\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.7924 - loss: 0.8132 - val_accuracy: 0.5922 - val_loss: 1.8077 - learning_rate: 5.8404e-04\n",
            "Epoch 50: early stopping\n",
            "Restoring model weights from the end of the best epoch: 30.\n",
            "å­¦ç¿’å®Œäº†ï¼å­¦ç¿’æ™‚é–“: 588.94ç§’\n",
            "æœ€è‰¯æ¤œè¨¼Loss: 1.6558\n",
            "æœ€è‰¯æ¤œè¨¼Accuracy: 0.6052\n",
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ä¸­...\n",
            "ãƒ†ã‚¹ãƒˆLoss: 1.6559\n",
            "ãƒ†ã‚¹ãƒˆAccuracy: 0.5286\n",
            "F1-Score (macro): 0.4671\n",
            "F1-Score (weighted): 0.5062\n",
            "çµæœä¿å­˜ä¸­...\n",
            "å­¦ç¿’å±¥æ­´ä¿å­˜å®Œäº†: ../output/experiments/trial_45_w64_s16_w64_s16/results/training_history_attention.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-08 23:32:09,342] Trial 45 finished with value: 0.7315136534909046 and parameters: {'lstm_units_1': 64, 'lstm_units_2': 56, 'dense_units': 56, 'demographics_dense_units': 28, 'fusion_dense_units': 48, 'dropout_rate': 0.1, 'dense_dropout_rate': 0.15000000000000002, 'learning_rate': 0.002336143693851732, 'batch_size': 32, 'fusion_type': 'attention'}. Best is trial 34 with value: 0.8021217206997858.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "çµæœä¿å­˜å®Œäº†: ../output/experiments/trial_45_w64_s16_w64_s16/results\n",
            "âœ… Trial 45: CMI=0.7315, Binary F1=0.9334, Fusion=attention\n",
            "\n",
            "ğŸ” Trial 46 - w64_s16\n",
            "Mixed precision enabled for better GPU performance\n",
            "GPUåˆ©ç”¨å¯èƒ½: 1å°\n",
            "ä½¿ç”¨GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
            "LSTM v2å­¦ç¿’ç’°å¢ƒåˆæœŸåŒ–å®Œäº†\n",
            "å®Ÿé¨“å: trial_46_w64_s16\n",
            "ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®š: w64_s16\n",
            "å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: ../output/experiments/trial_46_w64_s16_w64_s16\n",
            "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿: ../output/experiments/lstm_v2_w64_s16/preprocessed\n",
            "GPUåˆ©ç”¨å¯èƒ½: True\n",
            "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...\n",
            "æœ€é©åŒ–ã•ã‚ŒãŸdemographicsç‰¹å¾´é‡ã‚’ä½¿ç”¨ã—ã¾ã™\n",
            "æœ€é©åŒ–ã•ã‚ŒãŸdemographicså½¢çŠ¶: (13393, 18)\n",
            "ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†:\n",
            "  ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿: (13393, 64, 332)\n",
            "  Demographics: (13393, 18)\n",
            "  ãƒ©ãƒ™ãƒ«: (13393,)\n",
            "  ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹ (èåˆæ–¹å¼: attention)...\n",
            "ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ä¸­...\n",
            "ãƒ†ã‚¹ãƒˆã‚µã‚¤ã‚º: 0.2\n",
            "æ¤œè¨¼ã‚µã‚¤ã‚º: 0.2\n",
            "ãƒ‡ãƒ¼ã‚¿åˆ†å‰²å®Œäº†:\n",
            "  è¨“ç·´ - ã‚»ãƒ³ã‚µãƒ¼: (8571, 64, 332), Demographics: (8571, 18), ãƒ©ãƒ™ãƒ«: (8571,)\n",
            "  æ¤œè¨¼ - ã‚»ãƒ³ã‚µãƒ¼: (2143, 64, 332), Demographics: (2143, 18), ãƒ©ãƒ™ãƒ«: (2143,)\n",
            "  ãƒ†ã‚¹ãƒˆ - ã‚»ãƒ³ã‚µãƒ¼: (2679, 64, 332), Demographics: (2679, 18), ãƒ©ãƒ™ãƒ«: (2679,)\n",
            "å…¥åŠ›å½¢çŠ¶:\n",
            "  ã‚»ãƒ³ã‚µãƒ¼: (64, 332)\n",
            "  Demographics: (18,)\n",
            "  ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "GPUä¸Šã§ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆãƒ»å­¦ç¿’ã—ã¾ã™\n",
            "Mixed precision enabled for better GPU performance\n",
            "GPUåˆ©ç”¨å¯èƒ½: 1å°\n",
            "ä½¿ç”¨GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
            "LSTM v2ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†\n",
            "ã‚»ãƒ³ã‚µãƒ¼å…¥åŠ›å½¢çŠ¶: (64, 332)\n",
            "Demographicså…¥åŠ›å½¢çŠ¶: (18,)\n",
            "ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "èåˆæ–¹å¼: attention\n",
            "GPUåˆ©ç”¨å¯èƒ½: True\n",
            "LSTM v2ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ä¸­...\n",
            "ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰å®Œäº†\n",
            "ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 181,042\n",
            "\n",
            "=== ãƒ¢ãƒ‡ãƒ«ã‚µãƒãƒªãƒ¼ ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"lstm_v2_hybrid\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"lstm_v2_hybrid\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ sensor_input        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">332</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">132,160</span> â”‚ sensor_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_1           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> â”‚ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_1      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ lstm_bn_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_input  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">37,120</span> â”‚ lstm_dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">608</span> â”‚ demographics_inpâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_2           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_2      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ lstm_bn_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dense        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,120</span> â”‚ lstm_dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dropout      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sensor_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_weights   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,584</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attended_sensor     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sensor_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          â”‚                   â”‚            â”‚ attention_weightâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_projeâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,584</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_fusion    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ attended_sensor[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚                   â”‚            â”‚ demographics_proâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dense        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,352</span> â”‚ attention_fusionâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dropout      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ fusion_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">882</span> â”‚ fusion_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ sensor_input        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m332\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m80\u001b[0m)    â”‚    \u001b[38;5;34m132,160\u001b[0m â”‚ sensor_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_1           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m80\u001b[0m)    â”‚        \u001b[38;5;34m320\u001b[0m â”‚ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_1      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m80\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ lstm_bn_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_input  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚     \u001b[38;5;34m37,120\u001b[0m â”‚ lstm_dropout_1[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚        \u001b[38;5;34m608\u001b[0m â”‚ demographics_inpâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_2           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m256\u001b[0m â”‚ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_2      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ lstm_bn_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚      \u001b[38;5;34m1,056\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dense        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚      \u001b[38;5;34m3,120\u001b[0m â”‚ lstm_dropout_2[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dropout      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sensor_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_weights   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚      \u001b[38;5;34m1,584\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attended_sensor     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sensor_dropout[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mMultiply\u001b[0m)          â”‚                   â”‚            â”‚ attention_weightâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_projeâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚      \u001b[38;5;34m1,584\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_fusion    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ attended_sensor[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚                   â”‚            â”‚ demographics_proâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dense        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚      \u001b[38;5;34m2,352\u001b[0m â”‚ attention_fusionâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dropout      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ fusion_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (\u001b[38;5;33mDense\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        â”‚        \u001b[38;5;34m882\u001b[0m â”‚ fusion_dropout[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">181,042</span> (707.20 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m181,042\u001b[0m (707.20 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">180,754</span> (706.07 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m180,754\u001b[0m (706.07 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> (1.12 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m288\u001b[0m (1.12 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹...\n",
            "ã‚»ãƒ³ã‚µãƒ¼è¨“ç·´ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (8571, 64, 332)\n",
            "Demographicsè¨“ç·´ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (8571, 18)\n",
            "ã‚»ãƒ³ã‚µãƒ¼æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (2143, 64, 332)\n",
            "Demographicsæ¤œè¨¼ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (2143, 18)\n",
            "è¨“ç·´ãƒ©ãƒ™ãƒ«å½¢çŠ¶: (8571,)\n",
            "æ¤œè¨¼ãƒ©ãƒ™ãƒ«å½¢çŠ¶: (2143,)\n",
            "Epoch 1/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.1230 - loss: 2.8226\n",
            "Epoch 1: val_loss improved from inf to 2.54275, saving model to ../output/experiments/trial_46_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.1232 - loss: 2.8217 - val_accuracy: 0.2361 - val_loss: 2.5427 - learning_rate: 0.0030\n",
            "Epoch 2/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2410 - loss: 2.4370\n",
            "Epoch 2: val_loss improved from 2.54275 to 2.25096, saving model to ../output/experiments/trial_46_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.2411 - loss: 2.4365 - val_accuracy: 0.2804 - val_loss: 2.2510 - learning_rate: 0.0030\n",
            "Epoch 3/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2933 - loss: 2.2090\n",
            "Epoch 3: val_loss improved from 2.25096 to 2.09300, saving model to ../output/experiments/trial_46_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.2934 - loss: 2.2088 - val_accuracy: 0.3089 - val_loss: 2.0930 - learning_rate: 0.0030\n",
            "Epoch 4/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.3190 - loss: 2.1292\n",
            "Epoch 4: val_loss improved from 2.09300 to 2.02752, saving model to ../output/experiments/trial_46_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.3191 - loss: 2.1290 - val_accuracy: 0.3523 - val_loss: 2.0275 - learning_rate: 0.0030\n",
            "Epoch 5/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3517 - loss: 2.0167\n",
            "Epoch 5: val_loss did not improve from 2.02752\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.3517 - loss: 2.0167 - val_accuracy: 0.3425 - val_loss: 2.0314 - learning_rate: 0.0030\n",
            "Epoch 6/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.3678 - loss: 1.9377\n",
            "Epoch 6: val_loss did not improve from 2.02752\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.3678 - loss: 1.9381 - val_accuracy: 0.3444 - val_loss: 2.0305 - learning_rate: 0.0030\n",
            "Epoch 7/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3786 - loss: 1.9445\n",
            "Epoch 7: val_loss improved from 2.02752 to 2.01503, saving model to ../output/experiments/trial_46_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.3786 - loss: 1.9446 - val_accuracy: 0.3495 - val_loss: 2.0150 - learning_rate: 0.0030\n",
            "Epoch 8/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.3827 - loss: 1.9199\n",
            "Epoch 8: val_loss improved from 2.01503 to 1.98259, saving model to ../output/experiments/trial_46_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.3828 - loss: 1.9197 - val_accuracy: 0.3878 - val_loss: 1.9826 - learning_rate: 0.0030\n",
            "Epoch 9/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3991 - loss: 1.8416\n",
            "Epoch 9: val_loss improved from 1.98259 to 1.90417, saving model to ../output/experiments/trial_46_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.3990 - loss: 1.8421 - val_accuracy: 0.3924 - val_loss: 1.9042 - learning_rate: 0.0030\n",
            "Epoch 10/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4158 - loss: 1.8256\n",
            "Epoch 10: val_loss improved from 1.90417 to 1.83409, saving model to ../output/experiments/trial_46_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 41ms/step - accuracy: 0.4159 - loss: 1.8255 - val_accuracy: 0.4060 - val_loss: 1.8341 - learning_rate: 0.0030\n",
            "Epoch 11/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4378 - loss: 1.7424\n",
            "Epoch 11: val_loss did not improve from 1.83409\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.4378 - loss: 1.7427 - val_accuracy: 0.4008 - val_loss: 1.8701 - learning_rate: 0.0030\n",
            "Epoch 12/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4442 - loss: 1.7497\n",
            "Epoch 12: val_loss did not improve from 1.83409\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.4442 - loss: 1.7497 - val_accuracy: 0.4172 - val_loss: 1.8718 - learning_rate: 0.0030\n",
            "Epoch 13/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4555 - loss: 1.6713\n",
            "Epoch 13: val_loss did not improve from 1.83409\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.4555 - loss: 1.6719 - val_accuracy: 0.4344 - val_loss: 1.8386 - learning_rate: 0.0030\n",
            "Epoch 14/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4726 - loss: 1.6909\n",
            "Epoch 14: val_loss did not improve from 1.83409\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.4726 - loss: 1.6909 - val_accuracy: 0.4480 - val_loss: 1.8406 - learning_rate: 0.0030\n",
            "Epoch 15/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4757 - loss: 1.6272\n",
            "Epoch 15: val_loss did not improve from 1.83409\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.4757 - loss: 1.6277 - val_accuracy: 0.4368 - val_loss: 1.8727 - learning_rate: 0.0030\n",
            "Epoch 16/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4918 - loss: 1.6238\n",
            "Epoch 16: val_loss did not improve from 1.83409\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.4918 - loss: 1.6238 - val_accuracy: 0.4433 - val_loss: 1.8617 - learning_rate: 0.0030\n",
            "Epoch 17/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4935 - loss: 1.6190\n",
            "Epoch 17: val_loss improved from 1.83409 to 1.81631, saving model to ../output/experiments/trial_46_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.4935 - loss: 1.6190 - val_accuracy: 0.4587 - val_loss: 1.8163 - learning_rate: 0.0030\n",
            "Epoch 18/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5259 - loss: 1.5840\n",
            "Epoch 18: val_loss did not improve from 1.81631\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.5258 - loss: 1.5841 - val_accuracy: 0.4442 - val_loss: 1.8202 - learning_rate: 0.0030\n",
            "Epoch 19/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5146 - loss: 1.5755\n",
            "Epoch 19: val_loss improved from 1.81631 to 1.78208, saving model to ../output/experiments/trial_46_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.5146 - loss: 1.5755 - val_accuracy: 0.4690 - val_loss: 1.7821 - learning_rate: 0.0030\n",
            "Epoch 20/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5305 - loss: 1.5053\n",
            "Epoch 20: val_loss improved from 1.78208 to 1.74490, saving model to ../output/experiments/trial_46_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.5305 - loss: 1.5055 - val_accuracy: 0.4806 - val_loss: 1.7449 - learning_rate: 0.0030\n",
            "Epoch 21/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5386 - loss: 1.4704\n",
            "Epoch 21: val_loss did not improve from 1.74490\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.5386 - loss: 1.4706 - val_accuracy: 0.4592 - val_loss: 1.7874 - learning_rate: 0.0030\n",
            "Epoch 22/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5280 - loss: 1.5228\n",
            "Epoch 22: val_loss did not improve from 1.74490\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.5279 - loss: 1.5229 - val_accuracy: 0.4853 - val_loss: 1.7525 - learning_rate: 0.0030\n",
            "Epoch 23/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5611 - loss: 1.4564\n",
            "Epoch 23: val_loss did not improve from 1.74490\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.5611 - loss: 1.4564 - val_accuracy: 0.4760 - val_loss: 1.7581 - learning_rate: 0.0030\n",
            "Epoch 24/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5590 - loss: 1.4468\n",
            "Epoch 24: val_loss did not improve from 1.74490\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.5589 - loss: 1.4471 - val_accuracy: 0.4732 - val_loss: 1.8632 - learning_rate: 0.0030\n",
            "Epoch 25/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5542 - loss: 1.4959\n",
            "Epoch 25: val_loss did not improve from 1.74490\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.5541 - loss: 1.4960 - val_accuracy: 0.4928 - val_loss: 1.7585 - learning_rate: 0.0030\n",
            "Epoch 26/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5638 - loss: 1.4685\n",
            "Epoch 26: val_loss did not improve from 1.74490\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.5637 - loss: 1.4689 - val_accuracy: 0.4848 - val_loss: 1.7615 - learning_rate: 0.0030\n",
            "Epoch 27/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5848 - loss: 1.4361\n",
            "Epoch 27: val_loss improved from 1.74490 to 1.72557, saving model to ../output/experiments/trial_46_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 41ms/step - accuracy: 0.5846 - loss: 1.4364 - val_accuracy: 0.5166 - val_loss: 1.7256 - learning_rate: 0.0030\n",
            "Epoch 28/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5919 - loss: 1.3989\n",
            "Epoch 28: val_loss did not improve from 1.72557\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.5919 - loss: 1.3989 - val_accuracy: 0.5128 - val_loss: 1.7792 - learning_rate: 0.0030\n",
            "Epoch 29/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6072 - loss: 1.3786\n",
            "Epoch 29: val_loss did not improve from 1.72557\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.6070 - loss: 1.3790 - val_accuracy: 0.5142 - val_loss: 1.7407 - learning_rate: 0.0030\n",
            "Epoch 30/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5953 - loss: 1.3936\n",
            "Epoch 30: val_loss did not improve from 1.72557\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.5952 - loss: 1.3938 - val_accuracy: 0.5063 - val_loss: 1.7335 - learning_rate: 0.0030\n",
            "Epoch 31/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6003 - loss: 1.3919\n",
            "Epoch 31: val_loss did not improve from 1.72557\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.6002 - loss: 1.3921 - val_accuracy: 0.5217 - val_loss: 1.7375 - learning_rate: 0.0030\n",
            "Epoch 32/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6033 - loss: 1.3654\n",
            "Epoch 32: val_loss did not improve from 1.72557\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.6033 - loss: 1.3656 - val_accuracy: 0.5194 - val_loss: 1.8160 - learning_rate: 0.0030\n",
            "Epoch 33/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6056 - loss: 1.3816\n",
            "Epoch 33: val_loss improved from 1.72557 to 1.72227, saving model to ../output/experiments/trial_46_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.6056 - loss: 1.3816 - val_accuracy: 0.5315 - val_loss: 1.7223 - learning_rate: 0.0030\n",
            "Epoch 34/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6162 - loss: 1.3445\n",
            "Epoch 34: val_loss did not improve from 1.72227\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.6162 - loss: 1.3446 - val_accuracy: 0.5166 - val_loss: 1.7721 - learning_rate: 0.0030\n",
            "Epoch 35/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6307 - loss: 1.3140\n",
            "Epoch 35: val_loss did not improve from 1.72227\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.6306 - loss: 1.3143 - val_accuracy: 0.5208 - val_loss: 1.7462 - learning_rate: 0.0030\n",
            "Epoch 36/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6180 - loss: 1.3497\n",
            "Epoch 36: val_loss did not improve from 1.72227\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.6180 - loss: 1.3497 - val_accuracy: 0.5208 - val_loss: 1.7564 - learning_rate: 0.0030\n",
            "Epoch 37/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6289 - loss: 1.3051\n",
            "Epoch 37: val_loss did not improve from 1.72227\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.6288 - loss: 1.3052 - val_accuracy: 0.5175 - val_loss: 1.7491 - learning_rate: 0.0030\n",
            "Epoch 38/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6281 - loss: 1.3107\n",
            "Epoch 38: val_loss did not improve from 1.72227\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.6281 - loss: 1.3108 - val_accuracy: 0.5343 - val_loss: 1.8234 - learning_rate: 0.0030\n",
            "Epoch 39/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6389 - loss: 1.3289\n",
            "Epoch 39: val_loss did not improve from 1.72227\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.6388 - loss: 1.3291 - val_accuracy: 0.5282 - val_loss: 1.7412 - learning_rate: 0.0030\n",
            "Epoch 40/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6467 - loss: 1.2651\n",
            "Epoch 40: val_loss did not improve from 1.72227\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.6467 - loss: 1.2654 - val_accuracy: 0.5371 - val_loss: 1.7747 - learning_rate: 0.0030\n",
            "Epoch 41/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6508 - loss: 1.2918\n",
            "Epoch 41: val_loss did not improve from 1.72227\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.6507 - loss: 1.2921 - val_accuracy: 0.5231 - val_loss: 1.7970 - learning_rate: 0.0030\n",
            "Epoch 42/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6500 - loss: 1.2757\n",
            "Epoch 42: val_loss did not improve from 1.72227\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.6500 - loss: 1.2758 - val_accuracy: 0.5301 - val_loss: 1.7732 - learning_rate: 0.0030\n",
            "Epoch 43/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6726 - loss: 1.2529\n",
            "Epoch 43: val_loss did not improve from 1.72227\n",
            "\n",
            "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0014962988207116723.\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.6725 - loss: 1.2529 - val_accuracy: 0.5590 - val_loss: 1.7567 - learning_rate: 0.0030\n",
            "Epoch 44/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7009 - loss: 1.1693\n",
            "Epoch 44: val_loss improved from 1.72227 to 1.70005, saving model to ../output/experiments/trial_46_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.7010 - loss: 1.1692 - val_accuracy: 0.5716 - val_loss: 1.7000 - learning_rate: 0.0015\n",
            "Epoch 45/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7300 - loss: 1.0672\n",
            "Epoch 45: val_loss did not improve from 1.70005\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.7300 - loss: 1.0674 - val_accuracy: 0.5810 - val_loss: 1.7375 - learning_rate: 0.0015\n",
            "Epoch 46/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7430 - loss: 1.0377\n",
            "Epoch 46: val_loss did not improve from 1.70005\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.7430 - loss: 1.0378 - val_accuracy: 0.5898 - val_loss: 1.7150 - learning_rate: 0.0015\n",
            "Epoch 47/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7486 - loss: 1.0040\n",
            "Epoch 47: val_loss improved from 1.70005 to 1.69605, saving model to ../output/experiments/trial_46_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 41ms/step - accuracy: 0.7485 - loss: 1.0043 - val_accuracy: 0.5917 - val_loss: 1.6960 - learning_rate: 0.0015\n",
            "Epoch 48/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7551 - loss: 1.0132\n",
            "Epoch 48: val_loss did not improve from 1.69605\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.7550 - loss: 1.0133 - val_accuracy: 0.6029 - val_loss: 1.7108 - learning_rate: 0.0015\n",
            "Epoch 49/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7565 - loss: 0.9807\n",
            "Epoch 49: val_loss did not improve from 1.69605\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.7564 - loss: 0.9809 - val_accuracy: 0.5908 - val_loss: 1.7245 - learning_rate: 0.0015\n",
            "Epoch 50/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7634 - loss: 0.9776\n",
            "Epoch 50: val_loss did not improve from 1.69605\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.7633 - loss: 0.9778 - val_accuracy: 0.5964 - val_loss: 1.7474 - learning_rate: 0.0015\n",
            "Epoch 51/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7729 - loss: 0.9581\n",
            "Epoch 51: val_loss did not improve from 1.69605\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.7729 - loss: 0.9581 - val_accuracy: 0.5992 - val_loss: 1.7927 - learning_rate: 0.0015\n",
            "Epoch 52/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7726 - loss: 0.9408\n",
            "Epoch 52: val_loss did not improve from 1.69605\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.7726 - loss: 0.9408 - val_accuracy: 0.6006 - val_loss: 1.7470 - learning_rate: 0.0015\n",
            "Epoch 53/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7937 - loss: 0.8924\n",
            "Epoch 53: val_loss did not improve from 1.69605\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.7935 - loss: 0.8928 - val_accuracy: 0.5856 - val_loss: 1.8509 - learning_rate: 0.0015\n",
            "Epoch 54/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7770 - loss: 0.9406\n",
            "Epoch 54: val_loss did not improve from 1.69605\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.7770 - loss: 0.9407 - val_accuracy: 0.5898 - val_loss: 1.7804 - learning_rate: 0.0015\n",
            "Epoch 55/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7811 - loss: 0.9118\n",
            "Epoch 55: val_loss did not improve from 1.69605\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.7811 - loss: 0.9119 - val_accuracy: 0.5996 - val_loss: 1.7497 - learning_rate: 0.0015\n",
            "Epoch 56/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7952 - loss: 0.8791\n",
            "Epoch 56: val_loss did not improve from 1.69605\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.7952 - loss: 0.8792 - val_accuracy: 0.5964 - val_loss: 1.8466 - learning_rate: 0.0015\n",
            "Epoch 57/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8050 - loss: 0.8667\n",
            "Epoch 57: val_loss did not improve from 1.69605\n",
            "\n",
            "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.0007481494103558362.\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.8050 - loss: 0.8667 - val_accuracy: 0.6038 - val_loss: 1.8502 - learning_rate: 0.0015\n",
            "Epoch 58/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8166 - loss: 0.8253\n",
            "Epoch 58: val_loss did not improve from 1.69605\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.8165 - loss: 0.8254 - val_accuracy: 0.6113 - val_loss: 1.7953 - learning_rate: 7.4815e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8254 - loss: 0.7867\n",
            "Epoch 59: val_loss did not improve from 1.69605\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.8254 - loss: 0.7868 - val_accuracy: 0.6178 - val_loss: 1.8158 - learning_rate: 7.4815e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8378 - loss: 0.7776\n",
            "Epoch 60: val_loss did not improve from 1.69605\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.8378 - loss: 0.7775 - val_accuracy: 0.6178 - val_loss: 1.8638 - learning_rate: 7.4815e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8389 - loss: 0.7524\n",
            "Epoch 61: val_loss did not improve from 1.69605\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.8388 - loss: 0.7525 - val_accuracy: 0.6197 - val_loss: 1.8709 - learning_rate: 7.4815e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8414 - loss: 0.7462\n",
            "Epoch 62: val_loss did not improve from 1.69605\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.8414 - loss: 0.7462 - val_accuracy: 0.6183 - val_loss: 1.8836 - learning_rate: 7.4815e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8444 - loss: 0.7408\n",
            "Epoch 63: val_loss did not improve from 1.69605\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.8444 - loss: 0.7408 - val_accuracy: 0.6183 - val_loss: 1.9634 - learning_rate: 7.4815e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8393 - loss: 0.7535\n",
            "Epoch 64: val_loss did not improve from 1.69605\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.8393 - loss: 0.7533 - val_accuracy: 0.6253 - val_loss: 1.9104 - learning_rate: 7.4815e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8561 - loss: 0.7161\n",
            "Epoch 65: val_loss did not improve from 1.69605\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.8561 - loss: 0.7161 - val_accuracy: 0.6318 - val_loss: 1.8594 - learning_rate: 7.4815e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8522 - loss: 0.7058\n",
            "Epoch 66: val_loss did not improve from 1.69605\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.8522 - loss: 0.7059 - val_accuracy: 0.6230 - val_loss: 1.9428 - learning_rate: 7.4815e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m133/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8531 - loss: 0.7183\n",
            "Epoch 67: val_loss did not improve from 1.69605\n",
            "\n",
            "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.0003740747051779181.\n",
            "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.8531 - loss: 0.7184 - val_accuracy: 0.6188 - val_loss: 1.9795 - learning_rate: 7.4815e-04\n",
            "Epoch 67: early stopping\n",
            "Restoring model weights from the end of the best epoch: 47.\n",
            "å­¦ç¿’å®Œäº†ï¼å­¦ç¿’æ™‚é–“: 361.58ç§’\n",
            "æœ€è‰¯æ¤œè¨¼Loss: 1.6960\n",
            "æœ€è‰¯æ¤œè¨¼Accuracy: 0.6318\n",
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ä¸­...\n",
            "ãƒ†ã‚¹ãƒˆLoss: 1.7523\n",
            "ãƒ†ã‚¹ãƒˆAccuracy: 0.5868\n",
            "F1-Score (macro): 0.5388\n",
            "F1-Score (weighted): 0.5808\n",
            "çµæœä¿å­˜ä¸­...\n",
            "å­¦ç¿’å±¥æ­´ä¿å­˜å®Œäº†: ../output/experiments/trial_46_w64_s16_w64_s16/results/training_history_attention.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-08 23:38:18,460] Trial 46 finished with value: 0.7794787917878894 and parameters: {'lstm_units_1': 80, 'lstm_units_2': 64, 'dense_units': 48, 'demographics_dense_units': 32, 'fusion_dense_units': 48, 'dropout_rate': 0.15000000000000002, 'dense_dropout_rate': 0.2, 'learning_rate': 0.002992597546734423, 'batch_size': 64, 'fusion_type': 'attention'}. Best is trial 34 with value: 0.8021217206997858.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "çµæœä¿å­˜å®Œäº†: ../output/experiments/trial_46_w64_s16_w64_s16/results\n",
            "âœ… Trial 46: CMI=0.7795, Binary F1=0.9452, Fusion=attention\n",
            "\n",
            "ğŸ” Trial 47 - w64_s16\n",
            "Mixed precision enabled for better GPU performance\n",
            "GPUåˆ©ç”¨å¯èƒ½: 1å°\n",
            "ä½¿ç”¨GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
            "LSTM v2å­¦ç¿’ç’°å¢ƒåˆæœŸåŒ–å®Œäº†\n",
            "å®Ÿé¨“å: trial_47_w64_s16\n",
            "ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®š: w64_s16\n",
            "å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: ../output/experiments/trial_47_w64_s16_w64_s16\n",
            "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿: ../output/experiments/lstm_v2_w64_s16/preprocessed\n",
            "GPUåˆ©ç”¨å¯èƒ½: True\n",
            "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...\n",
            "æœ€é©åŒ–ã•ã‚ŒãŸdemographicsç‰¹å¾´é‡ã‚’ä½¿ç”¨ã—ã¾ã™\n",
            "æœ€é©åŒ–ã•ã‚ŒãŸdemographicså½¢çŠ¶: (13393, 18)\n",
            "ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†:\n",
            "  ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿: (13393, 64, 332)\n",
            "  Demographics: (13393, 18)\n",
            "  ãƒ©ãƒ™ãƒ«: (13393,)\n",
            "  ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹ (èåˆæ–¹å¼: attention)...\n",
            "ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ä¸­...\n",
            "ãƒ†ã‚¹ãƒˆã‚µã‚¤ã‚º: 0.2\n",
            "æ¤œè¨¼ã‚µã‚¤ã‚º: 0.2\n",
            "ãƒ‡ãƒ¼ã‚¿åˆ†å‰²å®Œäº†:\n",
            "  è¨“ç·´ - ã‚»ãƒ³ã‚µãƒ¼: (8571, 64, 332), Demographics: (8571, 18), ãƒ©ãƒ™ãƒ«: (8571,)\n",
            "  æ¤œè¨¼ - ã‚»ãƒ³ã‚µãƒ¼: (2143, 64, 332), Demographics: (2143, 18), ãƒ©ãƒ™ãƒ«: (2143,)\n",
            "  ãƒ†ã‚¹ãƒˆ - ã‚»ãƒ³ã‚µãƒ¼: (2679, 64, 332), Demographics: (2679, 18), ãƒ©ãƒ™ãƒ«: (2679,)\n",
            "å…¥åŠ›å½¢çŠ¶:\n",
            "  ã‚»ãƒ³ã‚µãƒ¼: (64, 332)\n",
            "  Demographics: (18,)\n",
            "  ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "GPUä¸Šã§ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆãƒ»å­¦ç¿’ã—ã¾ã™\n",
            "Mixed precision enabled for better GPU performance\n",
            "GPUåˆ©ç”¨å¯èƒ½: 1å°\n",
            "ä½¿ç”¨GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
            "LSTM v2ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†\n",
            "ã‚»ãƒ³ã‚µãƒ¼å…¥åŠ›å½¢çŠ¶: (64, 332)\n",
            "Demographicså…¥åŠ›å½¢çŠ¶: (18,)\n",
            "ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "èåˆæ–¹å¼: attention\n",
            "GPUåˆ©ç”¨å¯èƒ½: True\n",
            "LSTM v2ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ä¸­...\n",
            "ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰å®Œäº†\n",
            "ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 100,802\n",
            "\n",
            "=== ãƒ¢ãƒ‡ãƒ«ã‚µãƒãƒªãƒ¼ ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"lstm_v2_hybrid\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"lstm_v2_hybrid\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ sensor_input        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">332</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,152</span> â”‚ sensor_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_1           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> â”‚ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_1      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ lstm_bn_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_input  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,624</span> â”‚ lstm_dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">608</span> â”‚ demographics_inpâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_2           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> â”‚ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_2      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ lstm_bn_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dense        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,960</span> â”‚ lstm_dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dropout      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sensor_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_weights   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,320</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attended_sensor     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sensor_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          â”‚                   â”‚            â”‚ attention_weightâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_projeâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,320</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_fusion    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ attended_sensor[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚                   â”‚            â”‚ demographics_proâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dense        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,640</span> â”‚ attention_fusionâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dropout      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ fusion_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">738</span> â”‚ fusion_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ sensor_input        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m332\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m48\u001b[0m)    â”‚     \u001b[38;5;34m73,152\u001b[0m â”‚ sensor_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_1           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m48\u001b[0m)    â”‚        \u001b[38;5;34m192\u001b[0m â”‚ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_1      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m48\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ lstm_bn_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_input  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚     \u001b[38;5;34m18,624\u001b[0m â”‚ lstm_dropout_1[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚        \u001b[38;5;34m608\u001b[0m â”‚ demographics_inpâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_2           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚        \u001b[38;5;34m192\u001b[0m â”‚ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_2      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ lstm_bn_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚      \u001b[38;5;34m1,056\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dense        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)        â”‚      \u001b[38;5;34m1,960\u001b[0m â”‚ lstm_dropout_2[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dropout      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sensor_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_weights   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)        â”‚      \u001b[38;5;34m1,320\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attended_sensor     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sensor_dropout[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mMultiply\u001b[0m)          â”‚                   â”‚            â”‚ attention_weightâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_projeâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)        â”‚      \u001b[38;5;34m1,320\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_fusion    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ attended_sensor[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚                   â”‚            â”‚ demographics_proâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dense        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)        â”‚      \u001b[38;5;34m1,640\u001b[0m â”‚ attention_fusionâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dropout      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ fusion_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (\u001b[38;5;33mDense\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        â”‚        \u001b[38;5;34m738\u001b[0m â”‚ fusion_dropout[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">100,802</span> (393.76 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m100,802\u001b[0m (393.76 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">100,610</span> (393.01 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m100,610\u001b[0m (393.01 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹...\n",
            "ã‚»ãƒ³ã‚µãƒ¼è¨“ç·´ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (8571, 64, 332)\n",
            "Demographicsè¨“ç·´ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (8571, 18)\n",
            "ã‚»ãƒ³ã‚µãƒ¼æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (2143, 64, 332)\n",
            "Demographicsæ¤œè¨¼ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (2143, 18)\n",
            "è¨“ç·´ãƒ©ãƒ™ãƒ«å½¢çŠ¶: (8571,)\n",
            "æ¤œè¨¼ãƒ©ãƒ™ãƒ«å½¢çŠ¶: (2143,)\n",
            "Epoch 1/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.1180 - loss: 2.8537\n",
            "Epoch 1: val_loss improved from inf to 2.53968, saving model to ../output/experiments/trial_47_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 46ms/step - accuracy: 0.1181 - loss: 2.8534 - val_accuracy: 0.1881 - val_loss: 2.5397 - learning_rate: 0.0020\n",
            "Epoch 2/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.2171 - loss: 2.5115\n",
            "Epoch 2: val_loss improved from 2.53968 to 2.29171, saving model to ../output/experiments/trial_47_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.2171 - loss: 2.5114 - val_accuracy: 0.2576 - val_loss: 2.2917 - learning_rate: 0.0020\n",
            "Epoch 3/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.2614 - loss: 2.3004\n",
            "Epoch 3: val_loss improved from 2.29171 to 2.08129, saving model to ../output/experiments/trial_47_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.2615 - loss: 2.3002 - val_accuracy: 0.2963 - val_loss: 2.0813 - learning_rate: 0.0020\n",
            "Epoch 4/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.2878 - loss: 2.1428\n",
            "Epoch 4: val_loss improved from 2.08129 to 2.01995, saving model to ../output/experiments/trial_47_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.2879 - loss: 2.1427 - val_accuracy: 0.3369 - val_loss: 2.0199 - learning_rate: 0.0020\n",
            "Epoch 5/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3216 - loss: 2.0410\n",
            "Epoch 5: val_loss improved from 2.01995 to 1.99431, saving model to ../output/experiments/trial_47_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.3216 - loss: 2.0411 - val_accuracy: 0.3378 - val_loss: 1.9943 - learning_rate: 0.0020\n",
            "Epoch 6/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3431 - loss: 1.9838\n",
            "Epoch 6: val_loss improved from 1.99431 to 1.92623, saving model to ../output/experiments/trial_47_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.3431 - loss: 1.9837 - val_accuracy: 0.3504 - val_loss: 1.9262 - learning_rate: 0.0020\n",
            "Epoch 7/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3789 - loss: 1.8812\n",
            "Epoch 7: val_loss improved from 1.92623 to 1.87738, saving model to ../output/experiments/trial_47_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.3788 - loss: 1.8813 - val_accuracy: 0.3654 - val_loss: 1.8774 - learning_rate: 0.0020\n",
            "Epoch 8/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3909 - loss: 1.8051\n",
            "Epoch 8: val_loss improved from 1.87738 to 1.84442, saving model to ../output/experiments/trial_47_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.3909 - loss: 1.8052 - val_accuracy: 0.3924 - val_loss: 1.8444 - learning_rate: 0.0020\n",
            "Epoch 9/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4117 - loss: 1.7231\n",
            "Epoch 9: val_loss improved from 1.84442 to 1.79617, saving model to ../output/experiments/trial_47_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.4115 - loss: 1.7235 - val_accuracy: 0.3985 - val_loss: 1.7962 - learning_rate: 0.0020\n",
            "Epoch 10/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4029 - loss: 1.7566\n",
            "Epoch 10: val_loss did not improve from 1.79617\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.4029 - loss: 1.7567 - val_accuracy: 0.4004 - val_loss: 1.8311 - learning_rate: 0.0020\n",
            "Epoch 11/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4259 - loss: 1.7513\n",
            "Epoch 11: val_loss improved from 1.79617 to 1.73885, saving model to ../output/experiments/trial_47_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.4259 - loss: 1.7510 - val_accuracy: 0.4158 - val_loss: 1.7388 - learning_rate: 0.0020\n",
            "Epoch 12/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4317 - loss: 1.6582\n",
            "Epoch 12: val_loss improved from 1.73885 to 1.69971, saving model to ../output/experiments/trial_47_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.4317 - loss: 1.6582 - val_accuracy: 0.4335 - val_loss: 1.6997 - learning_rate: 0.0020\n",
            "Epoch 13/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4550 - loss: 1.6133\n",
            "Epoch 13: val_loss did not improve from 1.69971\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.4550 - loss: 1.6133 - val_accuracy: 0.4400 - val_loss: 1.7546 - learning_rate: 0.0020\n",
            "Epoch 14/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4714 - loss: 1.5885\n",
            "Epoch 14: val_loss did not improve from 1.69971\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.4714 - loss: 1.5886 - val_accuracy: 0.4349 - val_loss: 1.7002 - learning_rate: 0.0020\n",
            "Epoch 15/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4746 - loss: 1.5493\n",
            "Epoch 15: val_loss improved from 1.69971 to 1.68188, saving model to ../output/experiments/trial_47_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.4746 - loss: 1.5493 - val_accuracy: 0.4386 - val_loss: 1.6819 - learning_rate: 0.0020\n",
            "Epoch 16/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4929 - loss: 1.5177\n",
            "Epoch 16: val_loss improved from 1.68188 to 1.67080, saving model to ../output/experiments/trial_47_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.4929 - loss: 1.5178 - val_accuracy: 0.4671 - val_loss: 1.6708 - learning_rate: 0.0020\n",
            "Epoch 17/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4793 - loss: 1.5141\n",
            "Epoch 17: val_loss improved from 1.67080 to 1.64204, saving model to ../output/experiments/trial_47_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4793 - loss: 1.5142 - val_accuracy: 0.4648 - val_loss: 1.6420 - learning_rate: 0.0020\n",
            "Epoch 18/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5108 - loss: 1.4398\n",
            "Epoch 18: val_loss did not improve from 1.64204\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5108 - loss: 1.4400 - val_accuracy: 0.4858 - val_loss: 1.6613 - learning_rate: 0.0020\n",
            "Epoch 19/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5080 - loss: 1.4618\n",
            "Epoch 19: val_loss improved from 1.64204 to 1.60841, saving model to ../output/experiments/trial_47_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.5080 - loss: 1.4618 - val_accuracy: 0.4718 - val_loss: 1.6084 - learning_rate: 0.0020\n",
            "Epoch 20/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5128 - loss: 1.4314\n",
            "Epoch 20: val_loss did not improve from 1.60841\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5128 - loss: 1.4316 - val_accuracy: 0.4484 - val_loss: 1.7458 - learning_rate: 0.0020\n",
            "Epoch 21/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5123 - loss: 1.4674\n",
            "Epoch 21: val_loss did not improve from 1.60841\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.5124 - loss: 1.4674 - val_accuracy: 0.4844 - val_loss: 1.6290 - learning_rate: 0.0020\n",
            "Epoch 22/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5312 - loss: 1.4075\n",
            "Epoch 22: val_loss improved from 1.60841 to 1.60697, saving model to ../output/experiments/trial_47_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5312 - loss: 1.4076 - val_accuracy: 0.4956 - val_loss: 1.6070 - learning_rate: 0.0020\n",
            "Epoch 23/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5516 - loss: 1.3622\n",
            "Epoch 23: val_loss did not improve from 1.60697\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.5516 - loss: 1.3624 - val_accuracy: 0.4988 - val_loss: 1.6168 - learning_rate: 0.0020\n",
            "Epoch 24/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5632 - loss: 1.3355\n",
            "Epoch 24: val_loss did not improve from 1.60697\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.5631 - loss: 1.3357 - val_accuracy: 0.4830 - val_loss: 1.6411 - learning_rate: 0.0020\n",
            "Epoch 25/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5446 - loss: 1.3961\n",
            "Epoch 25: val_loss did not improve from 1.60697\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5446 - loss: 1.3960 - val_accuracy: 0.5044 - val_loss: 1.6749 - learning_rate: 0.0020\n",
            "Epoch 26/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5713 - loss: 1.3013\n",
            "Epoch 26: val_loss improved from 1.60697 to 1.60511, saving model to ../output/experiments/trial_47_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.5713 - loss: 1.3014 - val_accuracy: 0.5189 - val_loss: 1.6051 - learning_rate: 0.0020\n",
            "Epoch 27/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5733 - loss: 1.3123\n",
            "Epoch 27: val_loss improved from 1.60511 to 1.58703, saving model to ../output/experiments/trial_47_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.5732 - loss: 1.3124 - val_accuracy: 0.5077 - val_loss: 1.5870 - learning_rate: 0.0020\n",
            "Epoch 28/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5656 - loss: 1.3594\n",
            "Epoch 28: val_loss improved from 1.58703 to 1.57818, saving model to ../output/experiments/trial_47_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.5656 - loss: 1.3593 - val_accuracy: 0.5152 - val_loss: 1.5782 - learning_rate: 0.0020\n",
            "Epoch 29/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5932 - loss: 1.2634\n",
            "Epoch 29: val_loss did not improve from 1.57818\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.5932 - loss: 1.2638 - val_accuracy: 0.4909 - val_loss: 1.6123 - learning_rate: 0.0020\n",
            "Epoch 30/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5800 - loss: 1.2774\n",
            "Epoch 30: val_loss did not improve from 1.57818\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.5800 - loss: 1.2775 - val_accuracy: 0.5180 - val_loss: 1.6109 - learning_rate: 0.0020\n",
            "Epoch 31/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5886 - loss: 1.2857\n",
            "Epoch 31: val_loss did not improve from 1.57818\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.5886 - loss: 1.2857 - val_accuracy: 0.5138 - val_loss: 1.6310 - learning_rate: 0.0020\n",
            "Epoch 32/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6156 - loss: 1.2231\n",
            "Epoch 32: val_loss did not improve from 1.57818\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.6156 - loss: 1.2231 - val_accuracy: 0.5236 - val_loss: 1.5853 - learning_rate: 0.0020\n",
            "Epoch 33/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6088 - loss: 1.2216\n",
            "Epoch 33: val_loss did not improve from 1.57818\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.6088 - loss: 1.2217 - val_accuracy: 0.5040 - val_loss: 1.6935 - learning_rate: 0.0020\n",
            "Epoch 34/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6086 - loss: 1.2268\n",
            "Epoch 34: val_loss did not improve from 1.57818\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.6087 - loss: 1.2268 - val_accuracy: 0.5203 - val_loss: 1.6122 - learning_rate: 0.0020\n",
            "Epoch 35/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6141 - loss: 1.2281\n",
            "Epoch 35: val_loss did not improve from 1.57818\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.6141 - loss: 1.2282 - val_accuracy: 0.5296 - val_loss: 1.5929 - learning_rate: 0.0020\n",
            "Epoch 36/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6028 - loss: 1.2833\n",
            "Epoch 36: val_loss did not improve from 1.57818\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.6027 - loss: 1.2834 - val_accuracy: 0.5184 - val_loss: 1.6111 - learning_rate: 0.0020\n",
            "Epoch 37/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6130 - loss: 1.2564\n",
            "Epoch 37: val_loss did not improve from 1.57818\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.6130 - loss: 1.2564 - val_accuracy: 0.5329 - val_loss: 1.6097 - learning_rate: 0.0020\n",
            "Epoch 38/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6223 - loss: 1.2083\n",
            "Epoch 38: val_loss did not improve from 1.57818\n",
            "\n",
            "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0009797140955924988.\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.6223 - loss: 1.2084 - val_accuracy: 0.5357 - val_loss: 1.5983 - learning_rate: 0.0020\n",
            "Epoch 39/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6395 - loss: 1.1412\n",
            "Epoch 39: val_loss did not improve from 1.57818\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.6395 - loss: 1.1412 - val_accuracy: 0.5432 - val_loss: 1.5928 - learning_rate: 9.7971e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6608 - loss: 1.0992\n",
            "Epoch 40: val_loss did not improve from 1.57818\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.6609 - loss: 1.0991 - val_accuracy: 0.5558 - val_loss: 1.5987 - learning_rate: 9.7971e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6858 - loss: 1.0431\n",
            "Epoch 41: val_loss did not improve from 1.57818\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.6858 - loss: 1.0432 - val_accuracy: 0.5586 - val_loss: 1.6122 - learning_rate: 9.7971e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6803 - loss: 1.0470\n",
            "Epoch 42: val_loss did not improve from 1.57818\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.6803 - loss: 1.0469 - val_accuracy: 0.5623 - val_loss: 1.5967 - learning_rate: 9.7971e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6884 - loss: 1.0256\n",
            "Epoch 43: val_loss did not improve from 1.57818\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.6884 - loss: 1.0256 - val_accuracy: 0.5558 - val_loss: 1.6321 - learning_rate: 9.7971e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6961 - loss: 0.9802\n",
            "Epoch 44: val_loss did not improve from 1.57818\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.6960 - loss: 0.9802 - val_accuracy: 0.5749 - val_loss: 1.6345 - learning_rate: 9.7971e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7050 - loss: 0.9925\n",
            "Epoch 45: val_loss did not improve from 1.57818\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.7050 - loss: 0.9927 - val_accuracy: 0.5553 - val_loss: 1.7092 - learning_rate: 9.7971e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6983 - loss: 0.9869\n",
            "Epoch 46: val_loss did not improve from 1.57818\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.6983 - loss: 0.9869 - val_accuracy: 0.5679 - val_loss: 1.6237 - learning_rate: 9.7971e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7151 - loss: 0.9477\n",
            "Epoch 47: val_loss did not improve from 1.57818\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.7151 - loss: 0.9479 - val_accuracy: 0.5637 - val_loss: 1.6190 - learning_rate: 9.7971e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7148 - loss: 0.9639\n",
            "Epoch 48: val_loss did not improve from 1.57818\n",
            "\n",
            "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0004898570477962494.\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.7148 - loss: 0.9639 - val_accuracy: 0.5670 - val_loss: 1.6840 - learning_rate: 9.7971e-04\n",
            "Epoch 48: early stopping\n",
            "Restoring model weights from the end of the best epoch: 28.\n",
            "å­¦ç¿’å®Œäº†ï¼å­¦ç¿’æ™‚é–“: 550.98ç§’\n",
            "æœ€è‰¯æ¤œè¨¼Loss: 1.5782\n",
            "æœ€è‰¯æ¤œè¨¼Accuracy: 0.5749\n",
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ä¸­...\n",
            "ãƒ†ã‚¹ãƒˆLoss: 1.5940\n",
            "ãƒ†ã‚¹ãƒˆAccuracy: 0.5304\n",
            "F1-Score (macro): 0.4824\n",
            "F1-Score (weighted): 0.5157\n",
            "çµæœä¿å­˜ä¸­...\n",
            "å­¦ç¿’å±¥æ­´ä¿å­˜å®Œäº†: ../output/experiments/trial_47_w64_s16_w64_s16/results/training_history_attention.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-08 23:47:37,102] Trial 47 finished with value: 0.7220290283726606 and parameters: {'lstm_units_1': 48, 'lstm_units_2': 48, 'dense_units': 40, 'demographics_dense_units': 32, 'fusion_dense_units': 40, 'dropout_rate': 0.1, 'dense_dropout_rate': 0.25, 'learning_rate': 0.00195942824082167, 'batch_size': 32, 'fusion_type': 'attention'}. Best is trial 34 with value: 0.8021217206997858.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "çµæœä¿å­˜å®Œäº†: ../output/experiments/trial_47_w64_s16_w64_s16/results\n",
            "âœ… Trial 47: CMI=0.7220, Binary F1=0.9270, Fusion=attention\n",
            "\n",
            "ğŸ” Trial 48 - w64_s16\n",
            "Mixed precision enabled for better GPU performance\n",
            "GPUåˆ©ç”¨å¯èƒ½: 1å°\n",
            "ä½¿ç”¨GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
            "LSTM v2å­¦ç¿’ç’°å¢ƒåˆæœŸåŒ–å®Œäº†\n",
            "å®Ÿé¨“å: trial_48_w64_s16\n",
            "ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®š: w64_s16\n",
            "å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: ../output/experiments/trial_48_w64_s16_w64_s16\n",
            "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿: ../output/experiments/lstm_v2_w64_s16/preprocessed\n",
            "GPUåˆ©ç”¨å¯èƒ½: True\n",
            "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...\n",
            "æœ€é©åŒ–ã•ã‚ŒãŸdemographicsç‰¹å¾´é‡ã‚’ä½¿ç”¨ã—ã¾ã™\n",
            "æœ€é©åŒ–ã•ã‚ŒãŸdemographicså½¢çŠ¶: (13393, 18)\n",
            "ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†:\n",
            "  ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿: (13393, 64, 332)\n",
            "  Demographics: (13393, 18)\n",
            "  ãƒ©ãƒ™ãƒ«: (13393,)\n",
            "  ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹ (èåˆæ–¹å¼: attention)...\n",
            "ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ä¸­...\n",
            "ãƒ†ã‚¹ãƒˆã‚µã‚¤ã‚º: 0.2\n",
            "æ¤œè¨¼ã‚µã‚¤ã‚º: 0.2\n",
            "ãƒ‡ãƒ¼ã‚¿åˆ†å‰²å®Œäº†:\n",
            "  è¨“ç·´ - ã‚»ãƒ³ã‚µãƒ¼: (8571, 64, 332), Demographics: (8571, 18), ãƒ©ãƒ™ãƒ«: (8571,)\n",
            "  æ¤œè¨¼ - ã‚»ãƒ³ã‚µãƒ¼: (2143, 64, 332), Demographics: (2143, 18), ãƒ©ãƒ™ãƒ«: (2143,)\n",
            "  ãƒ†ã‚¹ãƒˆ - ã‚»ãƒ³ã‚µãƒ¼: (2679, 64, 332), Demographics: (2679, 18), ãƒ©ãƒ™ãƒ«: (2679,)\n",
            "å…¥åŠ›å½¢çŠ¶:\n",
            "  ã‚»ãƒ³ã‚µãƒ¼: (64, 332)\n",
            "  Demographics: (18,)\n",
            "  ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "GPUä¸Šã§ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆãƒ»å­¦ç¿’ã—ã¾ã™\n",
            "Mixed precision enabled for better GPU performance\n",
            "GPUåˆ©ç”¨å¯èƒ½: 1å°\n",
            "ä½¿ç”¨GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
            "LSTM v2ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†\n",
            "ã‚»ãƒ³ã‚µãƒ¼å…¥åŠ›å½¢çŠ¶: (64, 332)\n",
            "Demographicså…¥åŠ›å½¢çŠ¶: (18,)\n",
            "ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "èåˆæ–¹å¼: attention\n",
            "GPUåˆ©ç”¨å¯èƒ½: True\n",
            "LSTM v2ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ä¸­...\n",
            "ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰å®Œäº†\n",
            "ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 174,106\n",
            "\n",
            "=== ãƒ¢ãƒ‡ãƒ«ã‚µãƒãƒªãƒ¼ ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"lstm_v2_hybrid\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"lstm_v2_hybrid\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ sensor_input        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">332</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">132,160</span> â”‚ sensor_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_1           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> â”‚ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_1      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ lstm_bn_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_input  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">30,688</span> â”‚ lstm_dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">532</span> â”‚ demographics_inpâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_2           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> â”‚ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_2      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ lstm_bn_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">812</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dense        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,648</span> â”‚ lstm_dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dropout      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sensor_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_weights   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,856</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attended_sensor     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sensor_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          â”‚                   â”‚            â”‚ attention_weightâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_projeâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,856</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_fusion    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ attended_sensor[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚                   â”‚            â”‚ demographics_proâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dense        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,560</span> â”‚ attention_fusionâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dropout      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ fusion_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">450</span> â”‚ fusion_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ sensor_input        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m332\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m80\u001b[0m)    â”‚    \u001b[38;5;34m132,160\u001b[0m â”‚ sensor_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_1           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m80\u001b[0m)    â”‚        \u001b[38;5;34m320\u001b[0m â”‚ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_1      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m80\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ lstm_bn_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_input  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        â”‚     \u001b[38;5;34m30,688\u001b[0m â”‚ lstm_dropout_1[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)        â”‚        \u001b[38;5;34m532\u001b[0m â”‚ demographics_inpâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_2           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        â”‚        \u001b[38;5;34m224\u001b[0m â”‚ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_2      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ lstm_bn_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)        â”‚        \u001b[38;5;34m812\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dense        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚      \u001b[38;5;34m3,648\u001b[0m â”‚ lstm_dropout_2[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dropout      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sensor_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_weights   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚      \u001b[38;5;34m1,856\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attended_sensor     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sensor_dropout[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mMultiply\u001b[0m)          â”‚                   â”‚            â”‚ attention_weightâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_projeâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚      \u001b[38;5;34m1,856\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_fusion    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ attended_sensor[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚                   â”‚            â”‚ demographics_proâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dense        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)        â”‚      \u001b[38;5;34m1,560\u001b[0m â”‚ attention_fusionâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dropout      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ fusion_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (\u001b[38;5;33mDense\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        â”‚        \u001b[38;5;34m450\u001b[0m â”‚ fusion_dropout[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">174,106</span> (680.10 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m174,106\u001b[0m (680.10 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">173,834</span> (679.04 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m173,834\u001b[0m (679.04 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> (1.06 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m272\u001b[0m (1.06 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹...\n",
            "ã‚»ãƒ³ã‚µãƒ¼è¨“ç·´ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (8571, 64, 332)\n",
            "Demographicsè¨“ç·´ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (8571, 18)\n",
            "ã‚»ãƒ³ã‚µãƒ¼æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (2143, 64, 332)\n",
            "Demographicsæ¤œè¨¼ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (2143, 18)\n",
            "è¨“ç·´ãƒ©ãƒ™ãƒ«å½¢çŠ¶: (8571,)\n",
            "æ¤œè¨¼ãƒ©ãƒ™ãƒ«å½¢çŠ¶: (2143,)\n",
            "Epoch 1/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.0538 - loss: 2.9698\n",
            "Epoch 1: val_loss improved from inf to 2.89740, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 47ms/step - accuracy: 0.0539 - loss: 2.9697 - val_accuracy: 0.1176 - val_loss: 2.8974 - learning_rate: 1.0940e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.1100 - loss: 2.8916\n",
            "Epoch 2: val_loss improved from 2.89740 to 2.83983, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.1100 - loss: 2.8915 - val_accuracy: 0.1265 - val_loss: 2.8398 - learning_rate: 1.0940e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.1215 - loss: 2.8394\n",
            "Epoch 3: val_loss improved from 2.83983 to 2.79629, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.1216 - loss: 2.8394 - val_accuracy: 0.1381 - val_loss: 2.7963 - learning_rate: 1.0940e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.1457 - loss: 2.7936\n",
            "Epoch 4: val_loss improved from 2.79629 to 2.73451, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.1457 - loss: 2.7936 - val_accuracy: 0.1708 - val_loss: 2.7345 - learning_rate: 1.0940e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.1747 - loss: 2.7333\n",
            "Epoch 5: val_loss improved from 2.73451 to 2.64240, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.1747 - loss: 2.7333 - val_accuracy: 0.2175 - val_loss: 2.6424 - learning_rate: 1.0940e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.2115 - loss: 2.6461\n",
            "Epoch 6: val_loss improved from 2.64240 to 2.53878, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.2114 - loss: 2.6460 - val_accuracy: 0.2277 - val_loss: 2.5388 - learning_rate: 1.0940e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2262 - loss: 2.5528\n",
            "Epoch 7: val_loss improved from 2.53878 to 2.45993, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.2262 - loss: 2.5527 - val_accuracy: 0.2389 - val_loss: 2.4599 - learning_rate: 1.0940e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.2303 - loss: 2.4781\n",
            "Epoch 8: val_loss improved from 2.45993 to 2.40171, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.2304 - loss: 2.4780 - val_accuracy: 0.2427 - val_loss: 2.4017 - learning_rate: 1.0940e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.2428 - loss: 2.3951\n",
            "Epoch 9: val_loss improved from 2.40171 to 2.34913, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.2428 - loss: 2.3951 - val_accuracy: 0.2497 - val_loss: 2.3491 - learning_rate: 1.0940e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.2444 - loss: 2.3650\n",
            "Epoch 10: val_loss improved from 2.34913 to 2.32725, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.2444 - loss: 2.3648 - val_accuracy: 0.2552 - val_loss: 2.3272 - learning_rate: 1.0940e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.2641 - loss: 2.3113\n",
            "Epoch 11: val_loss improved from 2.32725 to 2.28558, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.2641 - loss: 2.3113 - val_accuracy: 0.2678 - val_loss: 2.2856 - learning_rate: 1.0940e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.2572 - loss: 2.2899\n",
            "Epoch 12: val_loss improved from 2.28558 to 2.25711, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.2573 - loss: 2.2898 - val_accuracy: 0.2739 - val_loss: 2.2571 - learning_rate: 1.0940e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.2797 - loss: 2.2313\n",
            "Epoch 13: val_loss improved from 2.25711 to 2.24011, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.2797 - loss: 2.2313 - val_accuracy: 0.2898 - val_loss: 2.2401 - learning_rate: 1.0940e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.2725 - loss: 2.2126\n",
            "Epoch 14: val_loss did not improve from 2.24011\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.2725 - loss: 2.2126 - val_accuracy: 0.2860 - val_loss: 2.2527 - learning_rate: 1.0940e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.2853 - loss: 2.1770\n",
            "Epoch 15: val_loss improved from 2.24011 to 2.22722, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.2853 - loss: 2.1770 - val_accuracy: 0.2898 - val_loss: 2.2272 - learning_rate: 1.0940e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.2970 - loss: 2.1484\n",
            "Epoch 16: val_loss improved from 2.22722 to 2.19716, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.2970 - loss: 2.1485 - val_accuracy: 0.2916 - val_loss: 2.1972 - learning_rate: 1.0940e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.2994 - loss: 2.1362\n",
            "Epoch 17: val_loss improved from 2.19716 to 2.17319, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.2994 - loss: 2.1362 - val_accuracy: 0.2940 - val_loss: 2.1732 - learning_rate: 1.0940e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.2959 - loss: 2.1206\n",
            "Epoch 18: val_loss did not improve from 2.17319\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.2960 - loss: 2.1206 - val_accuracy: 0.3000 - val_loss: 2.1793 - learning_rate: 1.0940e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3026 - loss: 2.0840\n",
            "Epoch 19: val_loss improved from 2.17319 to 2.15444, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.3026 - loss: 2.0840 - val_accuracy: 0.2986 - val_loss: 2.1544 - learning_rate: 1.0940e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2994 - loss: 2.0663\n",
            "Epoch 20: val_loss improved from 2.15444 to 2.14062, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.2994 - loss: 2.0663 - val_accuracy: 0.3038 - val_loss: 2.1406 - learning_rate: 1.0940e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3178 - loss: 2.0159\n",
            "Epoch 21: val_loss improved from 2.14062 to 2.11613, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.3177 - loss: 2.0160 - val_accuracy: 0.3066 - val_loss: 2.1161 - learning_rate: 1.0940e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.3159 - loss: 2.0291\n",
            "Epoch 22: val_loss improved from 2.11613 to 2.11185, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.3159 - loss: 2.0291 - val_accuracy: 0.3126 - val_loss: 2.1118 - learning_rate: 1.0940e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3190 - loss: 2.0109\n",
            "Epoch 23: val_loss improved from 2.11185 to 2.09530, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.3190 - loss: 2.0108 - val_accuracy: 0.3070 - val_loss: 2.0953 - learning_rate: 1.0940e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3245 - loss: 1.9804\n",
            "Epoch 24: val_loss did not improve from 2.09530\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.3244 - loss: 1.9804 - val_accuracy: 0.3098 - val_loss: 2.1047 - learning_rate: 1.0940e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.3315 - loss: 1.9615\n",
            "Epoch 25: val_loss improved from 2.09530 to 2.07753, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.3315 - loss: 1.9617 - val_accuracy: 0.3066 - val_loss: 2.0775 - learning_rate: 1.0940e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3341 - loss: 1.9542\n",
            "Epoch 26: val_loss improved from 2.07753 to 2.07118, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.3340 - loss: 1.9542 - val_accuracy: 0.3159 - val_loss: 2.0712 - learning_rate: 1.0940e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3260 - loss: 1.9532\n",
            "Epoch 27: val_loss improved from 2.07118 to 2.04418, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.3260 - loss: 1.9532 - val_accuracy: 0.3192 - val_loss: 2.0442 - learning_rate: 1.0940e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.3538 - loss: 1.9116\n",
            "Epoch 28: val_loss did not improve from 2.04418\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.3537 - loss: 1.9117 - val_accuracy: 0.3173 - val_loss: 2.0737 - learning_rate: 1.0940e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3357 - loss: 1.9038\n",
            "Epoch 29: val_loss did not improve from 2.04418\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.3357 - loss: 1.9038 - val_accuracy: 0.3150 - val_loss: 2.0460 - learning_rate: 1.0940e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3437 - loss: 1.8856\n",
            "Epoch 30: val_loss improved from 2.04418 to 2.02091, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.3437 - loss: 1.8856 - val_accuracy: 0.3215 - val_loss: 2.0209 - learning_rate: 1.0940e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.3420 - loss: 1.8867\n",
            "Epoch 31: val_loss improved from 2.02091 to 2.01608, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.3420 - loss: 1.8867 - val_accuracy: 0.3257 - val_loss: 2.0161 - learning_rate: 1.0940e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.3313 - loss: 1.8723\n",
            "Epoch 32: val_loss improved from 2.01608 to 1.99984, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.3313 - loss: 1.8723 - val_accuracy: 0.3327 - val_loss: 1.9998 - learning_rate: 1.0940e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3423 - loss: 1.8662\n",
            "Epoch 33: val_loss improved from 1.99984 to 1.98529, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.3423 - loss: 1.8662 - val_accuracy: 0.3369 - val_loss: 1.9853 - learning_rate: 1.0940e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3552 - loss: 1.8095\n",
            "Epoch 34: val_loss improved from 1.98529 to 1.98209, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.3552 - loss: 1.8097 - val_accuracy: 0.3369 - val_loss: 1.9821 - learning_rate: 1.0940e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3611 - loss: 1.8047\n",
            "Epoch 35: val_loss did not improve from 1.98209\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.3611 - loss: 1.8047 - val_accuracy: 0.3388 - val_loss: 1.9993 - learning_rate: 1.0940e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3498 - loss: 1.8122\n",
            "Epoch 36: val_loss did not improve from 1.98209\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.3498 - loss: 1.8122 - val_accuracy: 0.3453 - val_loss: 1.9972 - learning_rate: 1.0940e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3698 - loss: 1.7760\n",
            "Epoch 37: val_loss improved from 1.98209 to 1.97152, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.3697 - loss: 1.7761 - val_accuracy: 0.3453 - val_loss: 1.9715 - learning_rate: 1.0940e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3697 - loss: 1.7753\n",
            "Epoch 38: val_loss improved from 1.97152 to 1.96273, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.3697 - loss: 1.7753 - val_accuracy: 0.3481 - val_loss: 1.9627 - learning_rate: 1.0940e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3694 - loss: 1.7530\n",
            "Epoch 39: val_loss improved from 1.96273 to 1.94384, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.3694 - loss: 1.7530 - val_accuracy: 0.3495 - val_loss: 1.9438 - learning_rate: 1.0940e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3737 - loss: 1.7471\n",
            "Epoch 40: val_loss did not improve from 1.94384\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.3737 - loss: 1.7472 - val_accuracy: 0.3588 - val_loss: 1.9644 - learning_rate: 1.0940e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3738 - loss: 1.7750\n",
            "Epoch 41: val_loss did not improve from 1.94384\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.3738 - loss: 1.7749 - val_accuracy: 0.3504 - val_loss: 2.0022 - learning_rate: 1.0940e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3731 - loss: 1.7294\n",
            "Epoch 42: val_loss did not improve from 1.94384\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.3731 - loss: 1.7294 - val_accuracy: 0.3574 - val_loss: 1.9608 - learning_rate: 1.0940e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3800 - loss: 1.7009\n",
            "Epoch 43: val_loss did not improve from 1.94384\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.3800 - loss: 1.7009 - val_accuracy: 0.3579 - val_loss: 1.9651 - learning_rate: 1.0940e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3827 - loss: 1.7421\n",
            "Epoch 44: val_loss improved from 1.94384 to 1.91526, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.3827 - loss: 1.7421 - val_accuracy: 0.3700 - val_loss: 1.9153 - learning_rate: 1.0940e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3864 - loss: 1.6924\n",
            "Epoch 45: val_loss did not improve from 1.91526\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.3864 - loss: 1.6924 - val_accuracy: 0.3672 - val_loss: 1.9212 - learning_rate: 1.0940e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3894 - loss: 1.6654\n",
            "Epoch 46: val_loss improved from 1.91526 to 1.90528, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.3894 - loss: 1.6655 - val_accuracy: 0.3700 - val_loss: 1.9053 - learning_rate: 1.0940e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4069 - loss: 1.6504\n",
            "Epoch 47: val_loss improved from 1.90528 to 1.89612, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.4069 - loss: 1.6504 - val_accuracy: 0.3733 - val_loss: 1.8961 - learning_rate: 1.0940e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3954 - loss: 1.6601\n",
            "Epoch 48: val_loss did not improve from 1.89612\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.3954 - loss: 1.6601 - val_accuracy: 0.3756 - val_loss: 1.9251 - learning_rate: 1.0940e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4091 - loss: 1.6536\n",
            "Epoch 49: val_loss did not improve from 1.89612\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.4090 - loss: 1.6536 - val_accuracy: 0.3808 - val_loss: 1.8978 - learning_rate: 1.0940e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4147 - loss: 1.6205\n",
            "Epoch 50: val_loss improved from 1.89612 to 1.85436, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.4147 - loss: 1.6205 - val_accuracy: 0.3845 - val_loss: 1.8544 - learning_rate: 1.0940e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4194 - loss: 1.5991\n",
            "Epoch 51: val_loss did not improve from 1.85436\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.4194 - loss: 1.5992 - val_accuracy: 0.3705 - val_loss: 1.8813 - learning_rate: 1.0940e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4153 - loss: 1.6085\n",
            "Epoch 52: val_loss did not improve from 1.85436\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.4153 - loss: 1.6085 - val_accuracy: 0.3873 - val_loss: 1.8665 - learning_rate: 1.0940e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4133 - loss: 1.6010\n",
            "Epoch 53: val_loss did not improve from 1.85436\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.4133 - loss: 1.6010 - val_accuracy: 0.3817 - val_loss: 1.8683 - learning_rate: 1.0940e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4241 - loss: 1.5548\n",
            "Epoch 54: val_loss did not improve from 1.85436\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4241 - loss: 1.5549 - val_accuracy: 0.3906 - val_loss: 1.8793 - learning_rate: 1.0940e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4255 - loss: 1.5689\n",
            "Epoch 55: val_loss did not improve from 1.85436\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.4255 - loss: 1.5689 - val_accuracy: 0.3906 - val_loss: 1.8786 - learning_rate: 1.0940e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4415 - loss: 1.5273\n",
            "Epoch 56: val_loss did not improve from 1.85436\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.4415 - loss: 1.5273 - val_accuracy: 0.3999 - val_loss: 1.8841 - learning_rate: 1.0940e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4295 - loss: 1.5485\n",
            "Epoch 57: val_loss did not improve from 1.85436\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.4295 - loss: 1.5486 - val_accuracy: 0.3892 - val_loss: 1.8748 - learning_rate: 1.0940e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4293 - loss: 1.5258\n",
            "Epoch 58: val_loss did not improve from 1.85436\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.4293 - loss: 1.5259 - val_accuracy: 0.3957 - val_loss: 1.8624 - learning_rate: 1.0940e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4350 - loss: 1.5278\n",
            "Epoch 59: val_loss did not improve from 1.85436\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.4350 - loss: 1.5278 - val_accuracy: 0.3929 - val_loss: 1.8814 - learning_rate: 1.0940e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4403 - loss: 1.5102\n",
            "Epoch 60: val_loss did not improve from 1.85436\n",
            "\n",
            "Epoch 60: ReduceLROnPlateau reducing learning rate to 5.470160613185726e-05.\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.4403 - loss: 1.5101 - val_accuracy: 0.3999 - val_loss: 1.8719 - learning_rate: 1.0940e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4575 - loss: 1.4578\n",
            "Epoch 61: val_loss improved from 1.85436 to 1.84585, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.4575 - loss: 1.4579 - val_accuracy: 0.4060 - val_loss: 1.8459 - learning_rate: 5.4702e-05\n",
            "Epoch 62/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4574 - loss: 1.4644\n",
            "Epoch 62: val_loss did not improve from 1.84585\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.4574 - loss: 1.4644 - val_accuracy: 0.4046 - val_loss: 1.8514 - learning_rate: 5.4702e-05\n",
            "Epoch 63/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4612 - loss: 1.4479\n",
            "Epoch 63: val_loss did not improve from 1.84585\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.4612 - loss: 1.4479 - val_accuracy: 0.4088 - val_loss: 1.8464 - learning_rate: 5.4702e-05\n",
            "Epoch 64/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4568 - loss: 1.4484\n",
            "Epoch 64: val_loss improved from 1.84585 to 1.84431, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4568 - loss: 1.4484 - val_accuracy: 0.4106 - val_loss: 1.8443 - learning_rate: 5.4702e-05\n",
            "Epoch 65/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4585 - loss: 1.4497\n",
            "Epoch 65: val_loss did not improve from 1.84431\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.4586 - loss: 1.4496 - val_accuracy: 0.4167 - val_loss: 1.8601 - learning_rate: 5.4702e-05\n",
            "Epoch 66/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4696 - loss: 1.4238\n",
            "Epoch 66: val_loss did not improve from 1.84431\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.4695 - loss: 1.4238 - val_accuracy: 0.4106 - val_loss: 1.8821 - learning_rate: 5.4702e-05\n",
            "Epoch 67/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4587 - loss: 1.4291\n",
            "Epoch 67: val_loss improved from 1.84431 to 1.82038, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.4587 - loss: 1.4291 - val_accuracy: 0.4139 - val_loss: 1.8204 - learning_rate: 5.4702e-05\n",
            "Epoch 68/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4741 - loss: 1.4301\n",
            "Epoch 68: val_loss did not improve from 1.82038\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4741 - loss: 1.4301 - val_accuracy: 0.4186 - val_loss: 1.8395 - learning_rate: 5.4702e-05\n",
            "Epoch 69/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4661 - loss: 1.4158\n",
            "Epoch 69: val_loss did not improve from 1.82038\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.4661 - loss: 1.4158 - val_accuracy: 0.4209 - val_loss: 1.8413 - learning_rate: 5.4702e-05\n",
            "Epoch 70/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4757 - loss: 1.4064\n",
            "Epoch 70: val_loss did not improve from 1.82038\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.4757 - loss: 1.4064 - val_accuracy: 0.4223 - val_loss: 1.8323 - learning_rate: 5.4702e-05\n",
            "Epoch 71/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4684 - loss: 1.4337\n",
            "Epoch 71: val_loss did not improve from 1.82038\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.4684 - loss: 1.4336 - val_accuracy: 0.4176 - val_loss: 1.8992 - learning_rate: 5.4702e-05\n",
            "Epoch 72/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4704 - loss: 1.4202\n",
            "Epoch 72: val_loss did not improve from 1.82038\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.4704 - loss: 1.4201 - val_accuracy: 0.4293 - val_loss: 1.8344 - learning_rate: 5.4702e-05\n",
            "Epoch 73/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4694 - loss: 1.4114\n",
            "Epoch 73: val_loss did not improve from 1.82038\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.4694 - loss: 1.4114 - val_accuracy: 0.4340 - val_loss: 1.8359 - learning_rate: 5.4702e-05\n",
            "Epoch 74/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4857 - loss: 1.3837\n",
            "Epoch 74: val_loss improved from 1.82038 to 1.81828, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.4856 - loss: 1.3837 - val_accuracy: 0.4330 - val_loss: 1.8183 - learning_rate: 5.4702e-05\n",
            "Epoch 75/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4831 - loss: 1.3657\n",
            "Epoch 75: val_loss did not improve from 1.81828\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.4832 - loss: 1.3657 - val_accuracy: 0.4316 - val_loss: 1.8389 - learning_rate: 5.4702e-05\n",
            "Epoch 76/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4813 - loss: 1.3822\n",
            "Epoch 76: val_loss improved from 1.81828 to 1.80296, saving model to ../output/experiments/trial_48_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4813 - loss: 1.3822 - val_accuracy: 0.4358 - val_loss: 1.8030 - learning_rate: 5.4702e-05\n",
            "Epoch 77/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4943 - loss: 1.3754\n",
            "Epoch 77: val_loss did not improve from 1.80296\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.4943 - loss: 1.3754 - val_accuracy: 0.4377 - val_loss: 1.8356 - learning_rate: 5.4702e-05\n",
            "Epoch 78/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4797 - loss: 1.3721\n",
            "Epoch 78: val_loss did not improve from 1.80296\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4797 - loss: 1.3720 - val_accuracy: 0.4344 - val_loss: 1.8634 - learning_rate: 5.4702e-05\n",
            "Epoch 79/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4828 - loss: 1.3644\n",
            "Epoch 79: val_loss did not improve from 1.80296\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4829 - loss: 1.3644 - val_accuracy: 0.4452 - val_loss: 1.8396 - learning_rate: 5.4702e-05\n",
            "Epoch 80/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4806 - loss: 1.3545\n",
            "Epoch 80: val_loss did not improve from 1.80296\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.4806 - loss: 1.3546 - val_accuracy: 0.4232 - val_loss: 1.8785 - learning_rate: 5.4702e-05\n",
            "Epoch 81/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5003 - loss: 1.3492\n",
            "Epoch 81: val_loss did not improve from 1.80296\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.5003 - loss: 1.3492 - val_accuracy: 0.4288 - val_loss: 1.8504 - learning_rate: 5.4702e-05\n",
            "Epoch 82/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5000 - loss: 1.3478\n",
            "Epoch 82: val_loss did not improve from 1.80296\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.5000 - loss: 1.3477 - val_accuracy: 0.4368 - val_loss: 1.8234 - learning_rate: 5.4702e-05\n",
            "Epoch 83/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4976 - loss: 1.3348\n",
            "Epoch 83: val_loss did not improve from 1.80296\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.4976 - loss: 1.3347 - val_accuracy: 0.4419 - val_loss: 1.8166 - learning_rate: 5.4702e-05\n",
            "Epoch 84/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5019 - loss: 1.3153\n",
            "Epoch 84: val_loss did not improve from 1.80296\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5019 - loss: 1.3153 - val_accuracy: 0.4410 - val_loss: 1.8502 - learning_rate: 5.4702e-05\n",
            "Epoch 85/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5032 - loss: 1.3206\n",
            "Epoch 85: val_loss did not improve from 1.80296\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5032 - loss: 1.3207 - val_accuracy: 0.4400 - val_loss: 1.8303 - learning_rate: 5.4702e-05\n",
            "Epoch 86/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5110 - loss: 1.3233\n",
            "Epoch 86: val_loss did not improve from 1.80296\n",
            "\n",
            "Epoch 86: ReduceLROnPlateau reducing learning rate to 2.735080306592863e-05.\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5110 - loss: 1.3233 - val_accuracy: 0.4377 - val_loss: 1.8559 - learning_rate: 5.4702e-05\n",
            "Epoch 87/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5093 - loss: 1.2905\n",
            "Epoch 87: val_loss did not improve from 1.80296\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5093 - loss: 1.2906 - val_accuracy: 0.4424 - val_loss: 1.8217 - learning_rate: 2.7351e-05\n",
            "Epoch 88/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5273 - loss: 1.2805\n",
            "Epoch 88: val_loss did not improve from 1.80296\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.5272 - loss: 1.2806 - val_accuracy: 0.4447 - val_loss: 1.8265 - learning_rate: 2.7351e-05\n",
            "Epoch 89/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5081 - loss: 1.2911\n",
            "Epoch 89: val_loss did not improve from 1.80296\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5081 - loss: 1.2911 - val_accuracy: 0.4466 - val_loss: 1.8048 - learning_rate: 2.7351e-05\n",
            "Epoch 90/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5216 - loss: 1.2826\n",
            "Epoch 90: val_loss did not improve from 1.80296\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.5216 - loss: 1.2826 - val_accuracy: 0.4452 - val_loss: 1.8199 - learning_rate: 2.7351e-05\n",
            "Epoch 91/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5117 - loss: 1.2938\n",
            "Epoch 91: val_loss did not improve from 1.80296\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.5117 - loss: 1.2938 - val_accuracy: 0.4419 - val_loss: 1.8479 - learning_rate: 2.7351e-05\n",
            "Epoch 92/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5117 - loss: 1.2975\n",
            "Epoch 92: val_loss did not improve from 1.80296\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.5117 - loss: 1.2974 - val_accuracy: 0.4447 - val_loss: 1.8214 - learning_rate: 2.7351e-05\n",
            "Epoch 93/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5141 - loss: 1.2720\n",
            "Epoch 93: val_loss did not improve from 1.80296\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5141 - loss: 1.2721 - val_accuracy: 0.4470 - val_loss: 1.8258 - learning_rate: 2.7351e-05\n",
            "Epoch 94/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5251 - loss: 1.2595\n",
            "Epoch 94: val_loss did not improve from 1.80296\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5250 - loss: 1.2597 - val_accuracy: 0.4503 - val_loss: 1.8215 - learning_rate: 2.7351e-05\n",
            "Epoch 95/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5180 - loss: 1.2726\n",
            "Epoch 95: val_loss did not improve from 1.80296\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.5180 - loss: 1.2726 - val_accuracy: 0.4484 - val_loss: 1.8269 - learning_rate: 2.7351e-05\n",
            "Epoch 96/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5099 - loss: 1.2686\n",
            "Epoch 96: val_loss did not improve from 1.80296\n",
            "\n",
            "Epoch 96: ReduceLROnPlateau reducing learning rate to 1.3675401532964315e-05.\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5099 - loss: 1.2686 - val_accuracy: 0.4508 - val_loss: 1.8330 - learning_rate: 2.7351e-05\n",
            "Epoch 96: early stopping\n",
            "Restoring model weights from the end of the best epoch: 76.\n",
            "å­¦ç¿’å®Œäº†ï¼å­¦ç¿’æ™‚é–“: 1087.53ç§’\n",
            "æœ€è‰¯æ¤œè¨¼Loss: 1.8030\n",
            "æœ€è‰¯æ¤œè¨¼Accuracy: 0.4508\n",
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ä¸­...\n",
            "ãƒ†ã‚¹ãƒˆLoss: 1.8238\n",
            "ãƒ†ã‚¹ãƒˆAccuracy: 0.4334\n",
            "F1-Score (macro): 0.2869\n",
            "F1-Score (weighted): 0.3790\n",
            "çµæœä¿å­˜ä¸­...\n",
            "å­¦ç¿’å±¥æ­´ä¿å­˜å®Œäº†: ../output/experiments/trial_48_w64_s16_w64_s16/results/training_history_attention.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-09 00:05:52,613] Trial 48 finished with value: 0.6413863994735794 and parameters: {'lstm_units_1': 80, 'lstm_units_2': 56, 'dense_units': 64, 'demographics_dense_units': 28, 'fusion_dense_units': 24, 'dropout_rate': 0.25, 'dense_dropout_rate': 0.15000000000000002, 'learning_rate': 0.0001094032110611736, 'batch_size': 32, 'fusion_type': 'attention'}. Best is trial 34 with value: 0.8021217206997858.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "çµæœä¿å­˜å®Œäº†: ../output/experiments/trial_48_w64_s16_w64_s16/results\n",
            "âœ… Trial 48: CMI=0.6414, Binary F1=0.8853, Fusion=attention\n",
            "\n",
            "ğŸ” Trial 49 - w64_s16\n",
            "Mixed precision enabled for better GPU performance\n",
            "GPUåˆ©ç”¨å¯èƒ½: 1å°\n",
            "ä½¿ç”¨GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
            "LSTM v2å­¦ç¿’ç’°å¢ƒåˆæœŸåŒ–å®Œäº†\n",
            "å®Ÿé¨“å: trial_49_w64_s16\n",
            "ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®š: w64_s16\n",
            "å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: ../output/experiments/trial_49_w64_s16_w64_s16\n",
            "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿: ../output/experiments/lstm_v2_w64_s16/preprocessed\n",
            "GPUåˆ©ç”¨å¯èƒ½: True\n",
            "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...\n",
            "æœ€é©åŒ–ã•ã‚ŒãŸdemographicsç‰¹å¾´é‡ã‚’ä½¿ç”¨ã—ã¾ã™\n",
            "æœ€é©åŒ–ã•ã‚ŒãŸdemographicså½¢çŠ¶: (13393, 18)\n",
            "ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†:\n",
            "  ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿: (13393, 64, 332)\n",
            "  Demographics: (13393, 18)\n",
            "  ãƒ©ãƒ™ãƒ«: (13393,)\n",
            "  ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹ (èåˆæ–¹å¼: attention)...\n",
            "ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ä¸­...\n",
            "ãƒ†ã‚¹ãƒˆã‚µã‚¤ã‚º: 0.2\n",
            "æ¤œè¨¼ã‚µã‚¤ã‚º: 0.2\n",
            "ãƒ‡ãƒ¼ã‚¿åˆ†å‰²å®Œäº†:\n",
            "  è¨“ç·´ - ã‚»ãƒ³ã‚µãƒ¼: (8571, 64, 332), Demographics: (8571, 18), ãƒ©ãƒ™ãƒ«: (8571,)\n",
            "  æ¤œè¨¼ - ã‚»ãƒ³ã‚µãƒ¼: (2143, 64, 332), Demographics: (2143, 18), ãƒ©ãƒ™ãƒ«: (2143,)\n",
            "  ãƒ†ã‚¹ãƒˆ - ã‚»ãƒ³ã‚µãƒ¼: (2679, 64, 332), Demographics: (2679, 18), ãƒ©ãƒ™ãƒ«: (2679,)\n",
            "å…¥åŠ›å½¢çŠ¶:\n",
            "  ã‚»ãƒ³ã‚µãƒ¼: (64, 332)\n",
            "  Demographics: (18,)\n",
            "  ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "GPUä¸Šã§ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆãƒ»å­¦ç¿’ã—ã¾ã™\n",
            "Mixed precision enabled for better GPU performance\n",
            "GPUåˆ©ç”¨å¯èƒ½: 1å°\n",
            "ä½¿ç”¨GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
            "LSTM v2ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†\n",
            "ã‚»ãƒ³ã‚µãƒ¼å…¥åŠ›å½¢çŠ¶: (64, 332)\n",
            "Demographicså…¥åŠ›å½¢çŠ¶: (18,)\n",
            "ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "èåˆæ–¹å¼: attention\n",
            "GPUåˆ©ç”¨å¯èƒ½: True\n",
            "LSTM v2ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ä¸­...\n",
            "ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰å®Œäº†\n",
            "ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 178,826\n",
            "\n",
            "=== ãƒ¢ãƒ‡ãƒ«ã‚µãƒãƒªãƒ¼ ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"lstm_v2_hybrid\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"lstm_v2_hybrid\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ sensor_input        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">332</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">164,736</span> â”‚ sensor_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_1           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> â”‚ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_1      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ lstm_bn_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_input  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,232</span> â”‚ lstm_dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">228</span> â”‚ demographics_inpâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_2           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> â”‚ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_2      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ lstm_bn_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dense        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">952</span> â”‚ lstm_dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dropout      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sensor_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_weights   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">728</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attended_sensor     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sensor_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          â”‚                   â”‚            â”‚ attention_weightâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_projeâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">728</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_fusion    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ attended_sensor[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚                   â”‚            â”‚ demographics_proâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dense        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,736</span> â”‚ attention_fusionâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dropout      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ fusion_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">882</span> â”‚ fusion_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ sensor_input        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m332\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m96\u001b[0m)    â”‚    \u001b[38;5;34m164,736\u001b[0m â”‚ sensor_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_1           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m96\u001b[0m)    â”‚        \u001b[38;5;34m384\u001b[0m â”‚ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_1      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m96\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ lstm_bn_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_input  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        â”‚      \u001b[38;5;34m7,232\u001b[0m â”‚ lstm_dropout_1[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)        â”‚        \u001b[38;5;34m228\u001b[0m â”‚ demographics_inpâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_2           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        â”‚         \u001b[38;5;34m64\u001b[0m â”‚ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_2      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ lstm_bn_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)        â”‚        \u001b[38;5;34m156\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dense        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        â”‚        \u001b[38;5;34m952\u001b[0m â”‚ lstm_dropout_2[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dropout      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sensor_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_weights   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        â”‚        \u001b[38;5;34m728\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attended_sensor     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sensor_dropout[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mMultiply\u001b[0m)          â”‚                   â”‚            â”‚ attention_weightâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_projeâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        â”‚        \u001b[38;5;34m728\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_fusion    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ attended_sensor[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚                   â”‚            â”‚ demographics_proâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dense        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚      \u001b[38;5;34m2,736\u001b[0m â”‚ attention_fusionâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dropout      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ fusion_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (\u001b[38;5;33mDense\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        â”‚        \u001b[38;5;34m882\u001b[0m â”‚ fusion_dropout[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">178,826</span> (698.54 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m178,826\u001b[0m (698.54 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">178,602</span> (697.66 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m178,602\u001b[0m (697.66 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹...\n",
            "ã‚»ãƒ³ã‚µãƒ¼è¨“ç·´ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (8571, 64, 332)\n",
            "Demographicsè¨“ç·´ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (8571, 18)\n",
            "ã‚»ãƒ³ã‚µãƒ¼æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (2143, 64, 332)\n",
            "Demographicsæ¤œè¨¼ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (2143, 18)\n",
            "è¨“ç·´ãƒ©ãƒ™ãƒ«å½¢çŠ¶: (8571,)\n",
            "æ¤œè¨¼ãƒ©ãƒ™ãƒ«å½¢çŠ¶: (2143,)\n",
            "Epoch 1/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.1471 - loss: 2.8130\n",
            "Epoch 1: val_loss improved from inf to 2.79268, saving model to ../output/experiments/trial_49_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 0.1473 - loss: 2.8126 - val_accuracy: 0.1932 - val_loss: 2.7927 - learning_rate: 0.0077\n",
            "Epoch 2/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.2107 - loss: 2.6965\n",
            "Epoch 2: val_loss improved from 2.79268 to 2.64006, saving model to ../output/experiments/trial_49_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.2107 - loss: 2.6965 - val_accuracy: 0.2720 - val_loss: 2.6401 - learning_rate: 0.0077\n",
            "Epoch 3/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.2635 - loss: 2.6742\n",
            "Epoch 3: val_loss did not improve from 2.64006\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.2634 - loss: 2.6745 - val_accuracy: 0.2800 - val_loss: 2.6709 - learning_rate: 0.0077\n",
            "Epoch 4/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.2740 - loss: 2.7334\n",
            "Epoch 4: val_loss did not improve from 2.64006\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.2740 - loss: 2.7334 - val_accuracy: 0.2907 - val_loss: 2.6646 - learning_rate: 0.0077\n",
            "Epoch 5/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.2789 - loss: 2.7037\n",
            "Epoch 5: val_loss did not improve from 2.64006\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.2789 - loss: 2.7039 - val_accuracy: 0.2739 - val_loss: 2.7459 - learning_rate: 0.0077\n",
            "Epoch 6/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2854 - loss: 2.6997\n",
            "Epoch 6: val_loss did not improve from 2.64006\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.2854 - loss: 2.6998 - val_accuracy: 0.2837 - val_loss: 2.6554 - learning_rate: 0.0077\n",
            "Epoch 7/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2937 - loss: 2.6811\n",
            "Epoch 7: val_loss improved from 2.64006 to 2.61501, saving model to ../output/experiments/trial_49_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.2937 - loss: 2.6812 - val_accuracy: 0.2986 - val_loss: 2.6150 - learning_rate: 0.0077\n",
            "Epoch 8/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2905 - loss: 2.6334\n",
            "Epoch 8: val_loss did not improve from 2.61501\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.2905 - loss: 2.6334 - val_accuracy: 0.2898 - val_loss: 2.6607 - learning_rate: 0.0077\n",
            "Epoch 9/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.3021 - loss: 2.6424\n",
            "Epoch 9: val_loss improved from 2.61501 to 2.60808, saving model to ../output/experiments/trial_49_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.3021 - loss: 2.6425 - val_accuracy: 0.3159 - val_loss: 2.6081 - learning_rate: 0.0077\n",
            "Epoch 10/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2991 - loss: 2.6498\n",
            "Epoch 10: val_loss did not improve from 2.60808\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.2992 - loss: 2.6499 - val_accuracy: 0.3070 - val_loss: 2.6584 - learning_rate: 0.0077\n",
            "Epoch 11/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2972 - loss: 2.6587\n",
            "Epoch 11: val_loss improved from 2.60808 to 2.57706, saving model to ../output/experiments/trial_49_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.2972 - loss: 2.6586 - val_accuracy: 0.3220 - val_loss: 2.5771 - learning_rate: 0.0077\n",
            "Epoch 12/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3141 - loss: 2.5760\n",
            "Epoch 12: val_loss improved from 2.57706 to 2.55535, saving model to ../output/experiments/trial_49_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.3141 - loss: 2.5760 - val_accuracy: 0.3108 - val_loss: 2.5554 - learning_rate: 0.0077\n",
            "Epoch 13/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3144 - loss: 2.5884\n",
            "Epoch 13: val_loss did not improve from 2.55535\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.3144 - loss: 2.5885 - val_accuracy: 0.3089 - val_loss: 2.5641 - learning_rate: 0.0077\n",
            "Epoch 14/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3354 - loss: 2.5488\n",
            "Epoch 14: val_loss improved from 2.55535 to 2.51503, saving model to ../output/experiments/trial_49_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.3354 - loss: 2.5488 - val_accuracy: 0.3327 - val_loss: 2.5150 - learning_rate: 0.0077\n",
            "Epoch 15/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3344 - loss: 2.5656\n",
            "Epoch 15: val_loss improved from 2.51503 to 2.50760, saving model to ../output/experiments/trial_49_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.3345 - loss: 2.5656 - val_accuracy: 0.3294 - val_loss: 2.5076 - learning_rate: 0.0077\n",
            "Epoch 16/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3544 - loss: 2.4724\n",
            "Epoch 16: val_loss improved from 2.50760 to 2.44256, saving model to ../output/experiments/trial_49_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.3544 - loss: 2.4725 - val_accuracy: 0.3290 - val_loss: 2.4426 - learning_rate: 0.0077\n",
            "Epoch 17/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3436 - loss: 2.4654\n",
            "Epoch 17: val_loss did not improve from 2.44256\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.3436 - loss: 2.4654 - val_accuracy: 0.3518 - val_loss: 2.4492 - learning_rate: 0.0077\n",
            "Epoch 18/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3537 - loss: 2.4396\n",
            "Epoch 18: val_loss improved from 2.44256 to 2.42599, saving model to ../output/experiments/trial_49_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.3537 - loss: 2.4397 - val_accuracy: 0.3579 - val_loss: 2.4260 - learning_rate: 0.0077\n",
            "Epoch 19/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3650 - loss: 2.4199\n",
            "Epoch 19: val_loss improved from 2.42599 to 2.36957, saving model to ../output/experiments/trial_49_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.3650 - loss: 2.4199 - val_accuracy: 0.3658 - val_loss: 2.3696 - learning_rate: 0.0077\n",
            "Epoch 20/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3613 - loss: 2.4105\n",
            "Epoch 20: val_loss improved from 2.36957 to 2.34045, saving model to ../output/experiments/trial_49_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.3614 - loss: 2.4104 - val_accuracy: 0.3770 - val_loss: 2.3405 - learning_rate: 0.0077\n",
            "Epoch 21/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3752 - loss: 2.3700\n",
            "Epoch 21: val_loss improved from 2.34045 to 2.27992, saving model to ../output/experiments/trial_49_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.3752 - loss: 2.3701 - val_accuracy: 0.3948 - val_loss: 2.2799 - learning_rate: 0.0077\n",
            "Epoch 22/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3909 - loss: 2.3319\n",
            "Epoch 22: val_loss did not improve from 2.27992\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.3909 - loss: 2.3320 - val_accuracy: 0.3901 - val_loss: 2.2998 - learning_rate: 0.0077\n",
            "Epoch 23/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3875 - loss: 2.3452\n",
            "Epoch 23: val_loss did not improve from 2.27992\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.3875 - loss: 2.3452 - val_accuracy: 0.3957 - val_loss: 2.3091 - learning_rate: 0.0077\n",
            "Epoch 24/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3893 - loss: 2.3056\n",
            "Epoch 24: val_loss improved from 2.27992 to 2.21913, saving model to ../output/experiments/trial_49_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.3893 - loss: 2.3057 - val_accuracy: 0.3910 - val_loss: 2.2191 - learning_rate: 0.0077\n",
            "Epoch 25/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4089 - loss: 2.2332\n",
            "Epoch 25: val_loss did not improve from 2.21913\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.4089 - loss: 2.2333 - val_accuracy: 0.3859 - val_loss: 2.2367 - learning_rate: 0.0077\n",
            "Epoch 26/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4096 - loss: 2.2504\n",
            "Epoch 26: val_loss did not improve from 2.21913\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.4094 - loss: 2.2508 - val_accuracy: 0.3957 - val_loss: 2.2608 - learning_rate: 0.0077\n",
            "Epoch 27/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3865 - loss: 2.2823\n",
            "Epoch 27: val_loss improved from 2.21913 to 2.18581, saving model to ../output/experiments/trial_49_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.3865 - loss: 2.2823 - val_accuracy: 0.3990 - val_loss: 2.1858 - learning_rate: 0.0077\n",
            "Epoch 28/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4110 - loss: 2.2237\n",
            "Epoch 28: val_loss did not improve from 2.18581\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.4110 - loss: 2.2238 - val_accuracy: 0.3761 - val_loss: 2.2752 - learning_rate: 0.0077\n",
            "Epoch 29/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4181 - loss: 2.1952\n",
            "Epoch 29: val_loss did not improve from 2.18581\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.4180 - loss: 2.1955 - val_accuracy: 0.4041 - val_loss: 2.2258 - learning_rate: 0.0077\n",
            "Epoch 30/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3943 - loss: 2.2287\n",
            "Epoch 30: val_loss did not improve from 2.18581\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.3943 - loss: 2.2287 - val_accuracy: 0.4102 - val_loss: 2.2399 - learning_rate: 0.0077\n",
            "Epoch 31/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4167 - loss: 2.1963\n",
            "Epoch 31: val_loss improved from 2.18581 to 2.15441, saving model to ../output/experiments/trial_49_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.4167 - loss: 2.1962 - val_accuracy: 0.4214 - val_loss: 2.1544 - learning_rate: 0.0077\n",
            "Epoch 32/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4202 - loss: 2.1606\n",
            "Epoch 32: val_loss did not improve from 2.15441\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.4202 - loss: 2.1607 - val_accuracy: 0.4237 - val_loss: 2.1622 - learning_rate: 0.0077\n",
            "Epoch 33/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4393 - loss: 2.1426\n",
            "Epoch 33: val_loss improved from 2.15441 to 2.10992, saving model to ../output/experiments/trial_49_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4392 - loss: 2.1426 - val_accuracy: 0.4354 - val_loss: 2.1099 - learning_rate: 0.0077\n",
            "Epoch 34/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4307 - loss: 2.1431\n",
            "Epoch 34: val_loss did not improve from 2.10992\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.4307 - loss: 2.1432 - val_accuracy: 0.4148 - val_loss: 2.1841 - learning_rate: 0.0077\n",
            "Epoch 35/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4253 - loss: 2.1872\n",
            "Epoch 35: val_loss improved from 2.10992 to 2.10029, saving model to ../output/experiments/trial_49_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4254 - loss: 2.1870 - val_accuracy: 0.4396 - val_loss: 2.1003 - learning_rate: 0.0077\n",
            "Epoch 36/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4182 - loss: 2.1375\n",
            "Epoch 36: val_loss did not improve from 2.10029\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4182 - loss: 2.1374 - val_accuracy: 0.4256 - val_loss: 2.1196 - learning_rate: 0.0077\n",
            "Epoch 37/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4360 - loss: 2.0866\n",
            "Epoch 37: val_loss did not improve from 2.10029\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.4360 - loss: 2.0867 - val_accuracy: 0.4228 - val_loss: 2.1015 - learning_rate: 0.0077\n",
            "Epoch 38/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4506 - loss: 2.0885\n",
            "Epoch 38: val_loss did not improve from 2.10029\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.4505 - loss: 2.0886 - val_accuracy: 0.4237 - val_loss: 2.1098 - learning_rate: 0.0077\n",
            "Epoch 39/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4428 - loss: 2.0443\n",
            "Epoch 39: val_loss did not improve from 2.10029\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.4427 - loss: 2.0444 - val_accuracy: 0.4125 - val_loss: 2.1346 - learning_rate: 0.0077\n",
            "Epoch 40/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4387 - loss: 2.1082\n",
            "Epoch 40: val_loss did not improve from 2.10029\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.4387 - loss: 2.1081 - val_accuracy: 0.4158 - val_loss: 2.1640 - learning_rate: 0.0077\n",
            "Epoch 41/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4521 - loss: 2.0597\n",
            "Epoch 41: val_loss improved from 2.10029 to 2.09360, saving model to ../output/experiments/trial_49_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.4521 - loss: 2.0598 - val_accuracy: 0.4232 - val_loss: 2.0936 - learning_rate: 0.0077\n",
            "Epoch 42/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4463 - loss: 2.0602\n",
            "Epoch 42: val_loss did not improve from 2.09360\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.4463 - loss: 2.0602 - val_accuracy: 0.4372 - val_loss: 2.0977 - learning_rate: 0.0077\n",
            "Epoch 43/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4592 - loss: 2.0183\n",
            "Epoch 43: val_loss improved from 2.09360 to 2.08693, saving model to ../output/experiments/trial_49_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.4591 - loss: 2.0184 - val_accuracy: 0.4349 - val_loss: 2.0869 - learning_rate: 0.0077\n",
            "Epoch 44/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4583 - loss: 2.0083\n",
            "Epoch 44: val_loss improved from 2.08693 to 2.07713, saving model to ../output/experiments/trial_49_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4583 - loss: 2.0084 - val_accuracy: 0.4368 - val_loss: 2.0771 - learning_rate: 0.0077\n",
            "Epoch 45/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4546 - loss: 2.0123\n",
            "Epoch 45: val_loss did not improve from 2.07713\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4546 - loss: 2.0124 - val_accuracy: 0.4172 - val_loss: 2.0886 - learning_rate: 0.0077\n",
            "Epoch 46/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4696 - loss: 2.0037\n",
            "Epoch 46: val_loss improved from 2.07713 to 2.01659, saving model to ../output/experiments/trial_49_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.4695 - loss: 2.0040 - val_accuracy: 0.4480 - val_loss: 2.0166 - learning_rate: 0.0077\n",
            "Epoch 47/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4634 - loss: 2.0082\n",
            "Epoch 47: val_loss did not improve from 2.01659\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.4633 - loss: 2.0082 - val_accuracy: 0.4246 - val_loss: 2.0375 - learning_rate: 0.0077\n",
            "Epoch 48/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4616 - loss: 1.9910\n",
            "Epoch 48: val_loss did not improve from 2.01659\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.4616 - loss: 1.9910 - val_accuracy: 0.4242 - val_loss: 2.1150 - learning_rate: 0.0077\n",
            "Epoch 49/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4569 - loss: 2.0043\n",
            "Epoch 49: val_loss improved from 2.01659 to 2.01162, saving model to ../output/experiments/trial_49_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4570 - loss: 2.0042 - val_accuracy: 0.4531 - val_loss: 2.0116 - learning_rate: 0.0077\n",
            "Epoch 50/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4567 - loss: 1.9968\n",
            "Epoch 50: val_loss did not improve from 2.01162\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.4567 - loss: 1.9969 - val_accuracy: 0.4391 - val_loss: 2.0701 - learning_rate: 0.0077\n",
            "Epoch 51/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4665 - loss: 1.9747\n",
            "Epoch 51: val_loss did not improve from 2.01162\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.4665 - loss: 1.9748 - val_accuracy: 0.4321 - val_loss: 2.1205 - learning_rate: 0.0077\n",
            "Epoch 52/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4725 - loss: 2.0447\n",
            "Epoch 52: val_loss did not improve from 2.01162\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4725 - loss: 2.0445 - val_accuracy: 0.4540 - val_loss: 2.0194 - learning_rate: 0.0077\n",
            "Epoch 53/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4551 - loss: 2.0098\n",
            "Epoch 53: val_loss did not improve from 2.01162\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.4552 - loss: 2.0099 - val_accuracy: 0.4354 - val_loss: 2.0567 - learning_rate: 0.0077\n",
            "Epoch 54/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4832 - loss: 1.9565\n",
            "Epoch 54: val_loss did not improve from 2.01162\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.4831 - loss: 1.9567 - val_accuracy: 0.4340 - val_loss: 2.0136 - learning_rate: 0.0077\n",
            "Epoch 55/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4837 - loss: 1.9467\n",
            "Epoch 55: val_loss did not improve from 2.01162\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.4836 - loss: 1.9468 - val_accuracy: 0.4405 - val_loss: 2.0503 - learning_rate: 0.0077\n",
            "Epoch 56/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4757 - loss: 1.9336\n",
            "Epoch 56: val_loss did not improve from 2.01162\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.4757 - loss: 1.9338 - val_accuracy: 0.4606 - val_loss: 2.0226 - learning_rate: 0.0077\n",
            "Epoch 57/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4675 - loss: 1.9538\n",
            "Epoch 57: val_loss did not improve from 2.01162\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.4675 - loss: 1.9538 - val_accuracy: 0.4358 - val_loss: 2.0152 - learning_rate: 0.0077\n",
            "Epoch 58/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4727 - loss: 1.9348\n",
            "Epoch 58: val_loss did not improve from 2.01162\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.4727 - loss: 1.9350 - val_accuracy: 0.4386 - val_loss: 2.0547 - learning_rate: 0.0077\n",
            "Epoch 59/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4845 - loss: 1.9370\n",
            "Epoch 59: val_loss improved from 2.01162 to 1.99116, saving model to ../output/experiments/trial_49_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.4845 - loss: 1.9371 - val_accuracy: 0.4587 - val_loss: 1.9912 - learning_rate: 0.0077\n",
            "Epoch 60/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4781 - loss: 1.9068\n",
            "Epoch 60: val_loss did not improve from 1.99116\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.4780 - loss: 1.9071 - val_accuracy: 0.4400 - val_loss: 2.0482 - learning_rate: 0.0077\n",
            "Epoch 61/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4678 - loss: 1.9497\n",
            "Epoch 61: val_loss did not improve from 1.99116\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.4678 - loss: 1.9498 - val_accuracy: 0.4354 - val_loss: 2.0454 - learning_rate: 0.0077\n",
            "Epoch 62/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4816 - loss: 1.8836\n",
            "Epoch 62: val_loss did not improve from 1.99116\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4815 - loss: 1.8837 - val_accuracy: 0.4480 - val_loss: 2.0093 - learning_rate: 0.0077\n",
            "Epoch 63/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4777 - loss: 1.8963\n",
            "Epoch 63: val_loss improved from 1.99116 to 1.92576, saving model to ../output/experiments/trial_49_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.4777 - loss: 1.8964 - val_accuracy: 0.4503 - val_loss: 1.9258 - learning_rate: 0.0077\n",
            "Epoch 64/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4832 - loss: 1.8839\n",
            "Epoch 64: val_loss did not improve from 1.92576\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.4831 - loss: 1.8841 - val_accuracy: 0.4489 - val_loss: 1.9454 - learning_rate: 0.0077\n",
            "Epoch 65/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4854 - loss: 1.8566\n",
            "Epoch 65: val_loss improved from 1.92576 to 1.92032, saving model to ../output/experiments/trial_49_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.4853 - loss: 1.8566 - val_accuracy: 0.4615 - val_loss: 1.9203 - learning_rate: 0.0077\n",
            "Epoch 66/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4794 - loss: 1.8811\n",
            "Epoch 66: val_loss did not improve from 1.92032\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4794 - loss: 1.8812 - val_accuracy: 0.4526 - val_loss: 1.9647 - learning_rate: 0.0077\n",
            "Epoch 67/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4787 - loss: 1.8885\n",
            "Epoch 67: val_loss did not improve from 1.92032\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.4787 - loss: 1.8885 - val_accuracy: 0.4396 - val_loss: 1.9983 - learning_rate: 0.0077\n",
            "Epoch 68/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4982 - loss: 1.8588\n",
            "Epoch 68: val_loss did not improve from 1.92032\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.4980 - loss: 1.8591 - val_accuracy: 0.4377 - val_loss: 1.9973 - learning_rate: 0.0077\n",
            "Epoch 69/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4801 - loss: 1.8407\n",
            "Epoch 69: val_loss did not improve from 1.92032\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.4801 - loss: 1.8408 - val_accuracy: 0.4568 - val_loss: 1.9402 - learning_rate: 0.0077\n",
            "Epoch 70/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4708 - loss: 1.8963\n",
            "Epoch 70: val_loss did not improve from 1.92032\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.4708 - loss: 1.8963 - val_accuracy: 0.4400 - val_loss: 1.9798 - learning_rate: 0.0077\n",
            "Epoch 71/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4806 - loss: 1.8728\n",
            "Epoch 71: val_loss improved from 1.92032 to 1.91792, saving model to ../output/experiments/trial_49_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.4805 - loss: 1.8732 - val_accuracy: 0.4708 - val_loss: 1.9179 - learning_rate: 0.0077\n",
            "Epoch 72/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4843 - loss: 1.8627\n",
            "Epoch 72: val_loss did not improve from 1.91792\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.4843 - loss: 1.8627 - val_accuracy: 0.4522 - val_loss: 2.0174 - learning_rate: 0.0077\n",
            "Epoch 73/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4924 - loss: 1.8794\n",
            "Epoch 73: val_loss improved from 1.91792 to 1.90047, saving model to ../output/experiments/trial_49_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.4924 - loss: 1.8794 - val_accuracy: 0.4732 - val_loss: 1.9005 - learning_rate: 0.0077\n",
            "Epoch 74/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5001 - loss: 1.7616\n",
            "Epoch 74: val_loss did not improve from 1.90047\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5001 - loss: 1.7618 - val_accuracy: 0.4410 - val_loss: 1.9762 - learning_rate: 0.0077\n",
            "Epoch 75/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4939 - loss: 1.8158\n",
            "Epoch 75: val_loss did not improve from 1.90047\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.4938 - loss: 1.8160 - val_accuracy: 0.4568 - val_loss: 1.9769 - learning_rate: 0.0077\n",
            "Epoch 76/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4818 - loss: 1.8507\n",
            "Epoch 76: val_loss did not improve from 1.90047\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.4817 - loss: 1.8508 - val_accuracy: 0.4606 - val_loss: 1.9365 - learning_rate: 0.0077\n",
            "Epoch 77/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4767 - loss: 1.8256\n",
            "Epoch 77: val_loss did not improve from 1.90047\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.4767 - loss: 1.8257 - val_accuracy: 0.4274 - val_loss: 1.9796 - learning_rate: 0.0077\n",
            "Epoch 78/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4923 - loss: 1.8430\n",
            "Epoch 78: val_loss improved from 1.90047 to 1.89786, saving model to ../output/experiments/trial_49_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.4923 - loss: 1.8430 - val_accuracy: 0.4610 - val_loss: 1.8979 - learning_rate: 0.0077\n",
            "Epoch 79/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4936 - loss: 1.7986\n",
            "Epoch 79: val_loss did not improve from 1.89786\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.4936 - loss: 1.7986 - val_accuracy: 0.4536 - val_loss: 1.9979 - learning_rate: 0.0077\n",
            "Epoch 80/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4917 - loss: 1.8438\n",
            "Epoch 80: val_loss did not improve from 1.89786\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.4917 - loss: 1.8439 - val_accuracy: 0.4685 - val_loss: 1.9154 - learning_rate: 0.0077\n",
            "Epoch 81/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5007 - loss: 1.8186\n",
            "Epoch 81: val_loss did not improve from 1.89786\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.5006 - loss: 1.8187 - val_accuracy: 0.4582 - val_loss: 1.9233 - learning_rate: 0.0077\n",
            "Epoch 82/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4980 - loss: 1.7892\n",
            "Epoch 82: val_loss improved from 1.89786 to 1.89056, saving model to ../output/experiments/trial_49_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.4980 - loss: 1.7894 - val_accuracy: 0.4629 - val_loss: 1.8906 - learning_rate: 0.0077\n",
            "Epoch 83/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5127 - loss: 1.7466\n",
            "Epoch 83: val_loss improved from 1.89056 to 1.88236, saving model to ../output/experiments/trial_49_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.5127 - loss: 1.7466 - val_accuracy: 0.4652 - val_loss: 1.8824 - learning_rate: 0.0077\n",
            "Epoch 84/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4910 - loss: 1.8002\n",
            "Epoch 84: val_loss improved from 1.88236 to 1.88019, saving model to ../output/experiments/trial_49_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.4910 - loss: 1.8001 - val_accuracy: 0.4806 - val_loss: 1.8802 - learning_rate: 0.0077\n",
            "Epoch 85/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5023 - loss: 1.7481\n",
            "Epoch 85: val_loss did not improve from 1.88019\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.5023 - loss: 1.7483 - val_accuracy: 0.4624 - val_loss: 1.8864 - learning_rate: 0.0077\n",
            "Epoch 86/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4984 - loss: 1.7550\n",
            "Epoch 86: val_loss did not improve from 1.88019\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.4984 - loss: 1.7551 - val_accuracy: 0.4620 - val_loss: 1.8820 - learning_rate: 0.0077\n",
            "Epoch 87/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5027 - loss: 1.7655\n",
            "Epoch 87: val_loss did not improve from 1.88019\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.5027 - loss: 1.7656 - val_accuracy: 0.4573 - val_loss: 1.9240 - learning_rate: 0.0077\n",
            "Epoch 88/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4925 - loss: 1.7652\n",
            "Epoch 88: val_loss did not improve from 1.88019\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.4925 - loss: 1.7652 - val_accuracy: 0.4694 - val_loss: 1.9278 - learning_rate: 0.0077\n",
            "Epoch 89/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5065 - loss: 1.7709\n",
            "Epoch 89: val_loss did not improve from 1.88019\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5065 - loss: 1.7711 - val_accuracy: 0.4531 - val_loss: 1.9473 - learning_rate: 0.0077\n",
            "Epoch 90/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4973 - loss: 1.7615\n",
            "Epoch 90: val_loss improved from 1.88019 to 1.84487, saving model to ../output/experiments/trial_49_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.4973 - loss: 1.7617 - val_accuracy: 0.4643 - val_loss: 1.8449 - learning_rate: 0.0077\n",
            "Epoch 91/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4980 - loss: 1.7555\n",
            "Epoch 91: val_loss did not improve from 1.84487\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.4980 - loss: 1.7556 - val_accuracy: 0.4708 - val_loss: 1.8616 - learning_rate: 0.0077\n",
            "Epoch 92/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5104 - loss: 1.7278\n",
            "Epoch 92: val_loss did not improve from 1.84487\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.5104 - loss: 1.7280 - val_accuracy: 0.4680 - val_loss: 1.8573 - learning_rate: 0.0077\n",
            "Epoch 93/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5006 - loss: 1.7446\n",
            "Epoch 93: val_loss did not improve from 1.84487\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.5006 - loss: 1.7449 - val_accuracy: 0.4736 - val_loss: 1.8748 - learning_rate: 0.0077\n",
            "Epoch 94/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4965 - loss: 1.7716\n",
            "Epoch 94: val_loss did not improve from 1.84487\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.4965 - loss: 1.7716 - val_accuracy: 0.4680 - val_loss: 1.9244 - learning_rate: 0.0077\n",
            "Epoch 95/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5062 - loss: 1.7553\n",
            "Epoch 95: val_loss did not improve from 1.84487\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.5061 - loss: 1.7554 - val_accuracy: 0.4634 - val_loss: 1.9037 - learning_rate: 0.0077\n",
            "Epoch 96/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5087 - loss: 1.7514\n",
            "Epoch 96: val_loss did not improve from 1.84487\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.5086 - loss: 1.7516 - val_accuracy: 0.4536 - val_loss: 1.9201 - learning_rate: 0.0077\n",
            "Epoch 97/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5119 - loss: 1.7622\n",
            "Epoch 97: val_loss did not improve from 1.84487\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.5119 - loss: 1.7622 - val_accuracy: 0.4727 - val_loss: 1.8918 - learning_rate: 0.0077\n",
            "Epoch 98/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5009 - loss: 1.7760\n",
            "Epoch 98: val_loss did not improve from 1.84487\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.5010 - loss: 1.7760 - val_accuracy: 0.4671 - val_loss: 1.8630 - learning_rate: 0.0077\n",
            "Epoch 99/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5195 - loss: 1.7041\n",
            "Epoch 99: val_loss did not improve from 1.84487\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.5194 - loss: 1.7044 - val_accuracy: 0.4764 - val_loss: 1.8592 - learning_rate: 0.0077\n",
            "Epoch 100/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5031 - loss: 1.7612\n",
            "Epoch 100: val_loss improved from 1.84487 to 1.83986, saving model to ../output/experiments/trial_49_w64_s16_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5032 - loss: 1.7612 - val_accuracy: 0.4690 - val_loss: 1.8399 - learning_rate: 0.0077\n",
            "Restoring model weights from the end of the best epoch: 100.\n",
            "å­¦ç¿’å®Œäº†ï¼å­¦ç¿’æ™‚é–“: 1081.91ç§’\n",
            "æœ€è‰¯æ¤œè¨¼Loss: 1.8399\n",
            "æœ€è‰¯æ¤œè¨¼Accuracy: 0.4806\n",
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ä¸­...\n",
            "ãƒ†ã‚¹ãƒˆLoss: 1.7632\n",
            "ãƒ†ã‚¹ãƒˆAccuracy: 0.4979\n",
            "F1-Score (macro): 0.4199\n",
            "F1-Score (weighted): 0.4551\n",
            "çµæœä¿å­˜ä¸­...\n",
            "å­¦ç¿’å±¥æ­´ä¿å­˜å®Œäº†: ../output/experiments/trial_49_w64_s16_w64_s16/results/training_history_attention.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-09 00:24:02,832] Trial 49 finished with value: 0.7078839968657851 and parameters: {'lstm_units_1': 96, 'lstm_units_2': 16, 'dense_units': 56, 'demographics_dense_units': 12, 'fusion_dense_units': 48, 'dropout_rate': 0.1, 'dense_dropout_rate': 0.2, 'learning_rate': 0.007728680341602161, 'batch_size': 32, 'fusion_type': 'attention'}. Best is trial 34 with value: 0.8021217206997858.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "çµæœä¿å­˜å®Œäº†: ../output/experiments/trial_49_w64_s16_w64_s16/results\n",
            "âœ… Trial 49: CMI=0.7079, Binary F1=0.9320, Fusion=attention\n",
            "âœ… w64_s16 æœ€é©åŒ–å®Œäº†\n",
            "æœ€è‰¯CMIã‚¹ã‚³ã‚¢: 0.8021\n",
            "æœ€è‰¯Fusionæ–¹å¼: attention\n",
            "\n",
            "ğŸ‰ å…¨ã¦ã®æœ€é©åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸï¼\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
          ]
        }
      ],
      "source": [
        "# å„ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®šã§ã®æœ€é©åŒ–å®Ÿè¡Œ\n",
        "all_studies = {}\n",
        "optimization_results = {}\n",
        "\n",
        "print(f\"ğŸš€ åŒ…æ‹¬çš„æœ€é©åŒ–é–‹å§‹\")\n",
        "print(f\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
        "\n",
        "# WINDOW_CONFIGS = [\"w64_s16\", \"w128_s32\"]  # æ¯”è¼ƒã™ã‚‹ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º\n",
        "# WINDOW_CONFIGS = [\"w128_s32\"]  # æ¯”è¼ƒã™ã‚‹ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º\n",
        "WINDOW_CONFIGS = [\"w64_s16\"]  # æ¯”è¼ƒã™ã‚‹ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º\n",
        "for window_config in WINDOW_CONFIGS:\n",
        "    print(f\"\\nğŸ“Š {window_config} ã§ã®æœ€é©åŒ–é–‹å§‹\")\n",
        "    print(f\"{'='*50}\")\n",
        "    \n",
        "    # Studyåã¨Storageè¨­å®š\n",
        "    study_name = f\"{STUDY_BASE_NAME}_{window_config}\"\n",
        "    storage_url = f\"sqlite:///{RESULTS_DIR}/{study_name}.db\"\n",
        "    \n",
        "    # Optunaã‚¹ã‚¿ãƒ‡ã‚£ã®ä½œæˆ\n",
        "    study = optuna.create_study(\n",
        "        direction='maximize',\n",
        "        study_name=study_name,\n",
        "        storage=storage_url,\n",
        "        sampler=optuna.samplers.TPESampler(seed=42),\n",
        "        load_if_exists=True\n",
        "    )\n",
        "    \n",
        "    print(f\"Studyå: {study_name}\")\n",
        "    print(f\"æ—¢å­˜è©¦è¡Œæ•°: {len(study.trials)}\")\n",
        "    \n",
        "    # æ®‹ã‚Šè©¦è¡Œæ•°ã‚’è¨ˆç®—\n",
        "    remaining_trials = max(0, N_TRIALS_PER_CONFIG - len(study.trials))\n",
        "    if remaining_trials > 0:\n",
        "        print(f\"å®Ÿè¡Œã™ã‚‹è©¦è¡Œæ•°: {remaining_trials}\")\n",
        "        \n",
        "        # Objectiveé–¢æ•°ã‚’ä½œæˆ\n",
        "        objective_func = create_objective_function(window_config)\n",
        "        \n",
        "        # æœ€é©åŒ–å®Ÿè¡Œ\n",
        "        study.optimize(objective_func, n_trials=remaining_trials)\n",
        "        \n",
        "        print(f\"âœ… {window_config} æœ€é©åŒ–å®Œäº†\")\n",
        "    else:\n",
        "        print(f\"â­ï¸ {window_config} ã¯æ—¢ã«å®Œäº†æ¸ˆã¿\")\n",
        "    \n",
        "    # çµæœã‚’ä¿å­˜\n",
        "    all_studies[window_config] = study\n",
        "    \n",
        "    if study.best_trial:\n",
        "        optimization_results[window_config] = {\n",
        "            'best_cmi_score': study.best_value,\n",
        "            'best_params': study.best_params,\n",
        "            'best_trial_attrs': study.best_trial.user_attrs,\n",
        "            'n_trials': len(study.trials)\n",
        "        }\n",
        "        print(f\"æœ€è‰¯CMIã‚¹ã‚³ã‚¢: {study.best_value:.4f}\")\n",
        "        print(f\"æœ€è‰¯Fusionæ–¹å¼: {study.best_trial.user_attrs.get('fusion_type', 'N/A')}\")\n",
        "    else:\n",
        "        print(f\"âŒ {window_config}: æˆåŠŸã—ãŸè©¦è¡ŒãŒã‚ã‚Šã¾ã›ã‚“\")\n",
        "\n",
        "print(f\"\\nğŸ‰ å…¨ã¦ã®æœ€é©åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸï¼\")\n",
        "print(f\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¯ æœ€è‰¯è¨­å®šã®ç‰¹å®š\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
            "w64_s16: CMI Score = 0.8021\n",
            "\n",
            "ğŸ† å…¨ä½“æœ€è‰¯è¨­å®š: w64_s16\n",
            "ğŸ† å…¨ä½“æœ€è‰¯CMIã‚¹ã‚³ã‚¢: 0.8021\n",
            "\n",
            "ğŸ“‹ æœ€è‰¯è¨­å®šã®è©³ç´°:\n",
            "  ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®š: w64_s16\n",
            "  Fusionæ–¹å¼: attention\n",
            "  CMI Score: 0.8021\n",
            "  Binary F1: 0.9528\n",
            "  Macro F1: 0.6514\n",
            "  Test Accuracy: 0.6211\n",
            "\n",
            "ğŸ”§ æœ€è‰¯ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:\n",
            "  lstm_units_1: 80\n",
            "  lstm_units_2: 64\n",
            "  dense_units: 48\n",
            "  demographics_dense_units: 24\n",
            "  fusion_dense_units: 48\n",
            "  dropout_rate: 0.15000000000000002\n",
            "  dense_dropout_rate: 0.15000000000000002\n",
            "  learning_rate: 0.003602554208760558\n",
            "  batch_size: 32\n",
            "  fusion_type: attention\n",
            "\n",
            "ğŸ“Š ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºæ¯”è¼ƒ:\n",
            "w64_s16:\n",
            "  CMI: 0.8021\n",
            "  Binary F1: 0.9528\n",
            "  Macro F1: 0.6514\n",
            "  Fusion: attention\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ğŸ¯ æœ€è‰¯è¨­å®šã®ç‰¹å®šã¨æ¯”è¼ƒåˆ†æ\n",
        "print(\"ğŸ¯ æœ€è‰¯è¨­å®šã®ç‰¹å®š\")\n",
        "print(\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
        "\n",
        "# å…¨è¨­å®šã®ä¸­ã§æœ€é«˜æ€§èƒ½ã‚’ç‰¹å®š\n",
        "best_overall_config = None\n",
        "best_overall_score = 0.0\n",
        "\n",
        "for window_config, results in optimization_results.items():\n",
        "    score = results['best_cmi_score']\n",
        "    print(f\"{window_config}: CMI Score = {score:.4f}\")\n",
        "    \n",
        "    if score > best_overall_score:\n",
        "        best_overall_score = score\n",
        "        best_overall_config = window_config\n",
        "\n",
        "print(f\"\\nğŸ† å…¨ä½“æœ€è‰¯è¨­å®š: {best_overall_config}\")\n",
        "print(f\"ğŸ† å…¨ä½“æœ€è‰¯CMIã‚¹ã‚³ã‚¢: {best_overall_score:.4f}\")\n",
        "\n",
        "if best_overall_config:\n",
        "    best_results = optimization_results[best_overall_config]\n",
        "    print(f\"\\nğŸ“‹ æœ€è‰¯è¨­å®šã®è©³ç´°:\")\n",
        "    print(f\"  ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®š: {best_overall_config}\")\n",
        "    print(f\"  Fusionæ–¹å¼: {best_results['best_trial_attrs'].get('fusion_type', 'N/A')}\")\n",
        "    print(f\"  CMI Score: {best_results['best_cmi_score']:.4f}\")\n",
        "    print(f\"  Binary F1: {best_results['best_trial_attrs'].get('binary_f1', 'N/A'):.4f}\")\n",
        "    print(f\"  Macro F1: {best_results['best_trial_attrs'].get('macro_f1', 'N/A'):.4f}\")\n",
        "    print(f\"  Test Accuracy: {best_results['best_trial_attrs'].get('test_accuracy', 'N/A'):.4f}\")\n",
        "    \n",
        "    print(f\"\\nğŸ”§ æœ€è‰¯ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:\")\n",
        "    for key, value in best_results['best_params'].items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "\n",
        "# ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºåˆ¥ã®æ¯”è¼ƒ\n",
        "print(f\"\\nğŸ“Š ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºæ¯”è¼ƒ:\")\n",
        "for window_config in WINDOW_CONFIGS:\n",
        "    if window_config in optimization_results:\n",
        "        results = optimization_results[window_config]\n",
        "        attrs = results['best_trial_attrs']\n",
        "        print(f\"{window_config}:\")\n",
        "        print(f\"  CMI: {results['best_cmi_score']:.4f}\")\n",
        "        print(f\"  Binary F1: {attrs.get('binary_f1', 0):.4f}\")\n",
        "        print(f\"  Macro F1: {attrs.get('macro_f1', 0):.4f}\")\n",
        "        print(f\"  Fusion: {attrs.get('fusion_type', 'N/A')}\")\n",
        "        print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“ˆ åŒ…æ‹¬çš„çµæœå¯è¦–åŒ–\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x1500 with 6 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… åŒ…æ‹¬çš„çµæœã‚°ãƒ©ãƒ•ã‚’ä¿å­˜: ../results/comprehensive_optimization/comprehensive_optimization_results.png\n"
          ]
        }
      ],
      "source": [
        "# ğŸ“ˆ åŒ…æ‹¬çš„çµæœå¯è¦–åŒ–\n",
        "print(\"ğŸ“ˆ åŒ…æ‹¬çš„çµæœå¯è¦–åŒ–\")\n",
        "print(\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
        "\n",
        "# å¤§ããªãƒ•ã‚£ã‚®ãƒ¥ã‚¢ã‚’ä½œæˆ\n",
        "fig = plt.figure(figsize=(20, 15))\n",
        "\n",
        "# ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆé…ç½®: 3è¡Œ3åˆ—\n",
        "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
        "\n",
        "# 1. ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºåˆ¥æœ€é©åŒ–å±¥æ­´\n",
        "ax1 = fig.add_subplot(gs[0, :2])\n",
        "colors = ['blue', 'red', 'green', 'orange']\n",
        "for i, (window_config, study) in enumerate(all_studies.items()):\n",
        "    trials_values = [trial.value for trial in study.trials if trial.value is not None]\n",
        "    if trials_values:\n",
        "        ax1.plot(trials_values, label=f'{window_config}', color=colors[i % len(colors)], alpha=0.7)\n",
        "ax1.set_title('Optimization History by Window Size', fontsize=14, fontweight='bold')\n",
        "ax1.set_xlabel('Trial')\n",
        "ax1.set_ylabel('CMI Score')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# 2. ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºåˆ¥CMIã‚¹ã‚³ã‚¢æ¯”è¼ƒ\n",
        "ax2 = fig.add_subplot(gs[0, 2])\n",
        "window_names = []\n",
        "cmi_scores = []\n",
        "for window_config in WINDOW_CONFIGS:\n",
        "    if window_config in optimization_results:\n",
        "        window_names.append(window_config)\n",
        "        cmi_scores.append(optimization_results[window_config]['best_cmi_score'])\n",
        "\n",
        "if window_names:\n",
        "    bars = ax2.bar(window_names, cmi_scores, color=['skyblue', 'lightcoral'])\n",
        "    ax2.set_title('Best CMI Score\\nby Window Size', fontsize=12, fontweight='bold')\n",
        "    ax2.set_ylabel('CMI Score')\n",
        "    ax2.set_ylim(0, max(cmi_scores) * 1.1)\n",
        "    \n",
        "    # å€¤ã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º\n",
        "    for bar, score in zip(bars, cmi_scores):\n",
        "        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
        "                f'{score:.3f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# 3-4. å„ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã§ã®Fusionæ–¹å¼åˆ¥ã‚¹ã‚³ã‚¢åˆ†å¸ƒ\n",
        "for i, (window_config, study) in enumerate(all_studies.items()):\n",
        "    ax = fig.add_subplot(gs[1, i])\n",
        "    \n",
        "    # Fusionæ–¹å¼åˆ¥ã«ã‚¹ã‚³ã‚¢ã‚’é›†è¨ˆ\n",
        "    fusion_scores = {ft: [] for ft in FUSION_TYPES}\n",
        "    for trial in study.trials:\n",
        "        if (trial.value is not None and \n",
        "            'fusion_type' in trial.user_attrs):\n",
        "            fusion_type = trial.user_attrs['fusion_type']\n",
        "            if fusion_type in fusion_scores:\n",
        "                fusion_scores[fusion_type].append(trial.value)\n",
        "    \n",
        "    # boxplotãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™\n",
        "    fusion_data = []\n",
        "    fusion_labels = []\n",
        "    for fusion_type in FUSION_TYPES:\n",
        "        if fusion_scores[fusion_type]:\n",
        "            fusion_data.append(fusion_scores[fusion_type])\n",
        "            fusion_labels.append(fusion_type)\n",
        "    \n",
        "    if fusion_data:\n",
        "        bp = ax.boxplot(fusion_data, patch_artist=True)\n",
        "        ax.set_xticklabels(fusion_labels)\n",
        "        # è‰²ã‚’è¨­å®š\n",
        "        colors_box = ['lightblue', 'lightgreen', 'lightyellow']\n",
        "        for patch, color in zip(bp['boxes'], colors_box):\n",
        "            patch.set_facecolor(color)\n",
        "    \n",
        "    ax.set_title(f'Fusion Types\\n{window_config}', fontsize=12, fontweight='bold')\n",
        "    ax.set_ylabel('CMI Score')\n",
        "    ax.tick_params(axis='x', rotation=45)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "# 5. å…¨ä½“çš„ãªFusionæ–¹å¼æ¯”è¼ƒ\n",
        "ax5 = fig.add_subplot(gs[1, 2])\n",
        "all_fusion_scores = {ft: [] for ft in FUSION_TYPES}\n",
        "for study in all_studies.values():\n",
        "    for trial in study.trials:\n",
        "        if (trial.value is not None and \n",
        "            'fusion_type' in trial.user_attrs):\n",
        "            fusion_type = trial.user_attrs['fusion_type']\n",
        "            if fusion_type in all_fusion_scores:\n",
        "                all_fusion_scores[fusion_type].append(trial.value)\n",
        "\n",
        "fusion_means = []\n",
        "fusion_names = []\n",
        "for fusion_type in FUSION_TYPES:\n",
        "    if all_fusion_scores[fusion_type]:\n",
        "        fusion_means.append(np.mean(all_fusion_scores[fusion_type]))\n",
        "        fusion_names.append(fusion_type)\n",
        "\n",
        "if fusion_means:\n",
        "    bars = ax5.bar(fusion_names, fusion_means, color=['lightblue', 'lightgreen', 'lightyellow'])\n",
        "    ax5.set_title('Average CMI Score\\nby Fusion Type', fontsize=12, fontweight='bold')\n",
        "    ax5.set_ylabel('Average CMI Score')\n",
        "    ax5.tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    # å€¤ã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º\n",
        "    for bar, score in zip(bars, fusion_means):\n",
        "        ax5.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
        "                f'{score:.3f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# 6. ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é‡è¦åº¦ï¼ˆå…¨ä½“ï¼‰\n",
        "ax6 = fig.add_subplot(gs[2, :2])\n",
        "if best_overall_config and best_overall_config in all_studies:\n",
        "    best_study = all_studies[best_overall_config]\n",
        "    numeric_params = ['lstm_units_1', 'lstm_units_2', 'dense_units', 'dropout_rate', 'learning_rate']\n",
        "    \n",
        "    importances = []\n",
        "    param_names = []\n",
        "    \n",
        "    for param in numeric_params:\n",
        "        param_values = [trial.params.get(param) for trial in best_study.trials \n",
        "                       if trial.value is not None and param in trial.params]\n",
        "        trial_values = [trial.value for trial in best_study.trials \n",
        "                       if trial.value is not None and param in trial.params]\n",
        "        \n",
        "        if len(param_values) > 3 and len(set(param_values)) > 1:\n",
        "            correlation = np.corrcoef(param_values, trial_values)[0, 1]\n",
        "            if not np.isnan(correlation):\n",
        "                importances.append(abs(correlation))\n",
        "                param_names.append(param)\n",
        "    \n",
        "    if importances:\n",
        "        bars = ax6.barh(param_names, importances, color='lightsteelblue')\n",
        "        ax6.set_title(f'Parameter Importance ({best_overall_config})', fontsize=12, fontweight='bold')\n",
        "        ax6.set_xlabel('Absolute Correlation with CMI Score')\n",
        "\n",
        "# 7. æœ€è‰¯è¨­å®šã‚µãƒãƒªãƒ¼\n",
        "ax7 = fig.add_subplot(gs[2, 2])\n",
        "ax7.axis('off')\n",
        "if best_overall_config:\n",
        "    best_results = optimization_results[best_overall_config]\n",
        "    attrs = best_results['best_trial_attrs']\n",
        "    \n",
        "    summary_text = f\"\"\"ğŸ† BEST CONFIGURATION\n",
        "    \n",
        "Window: {best_overall_config}\n",
        "Fusion: {attrs.get('fusion_type', 'N/A')}\n",
        "\n",
        "ğŸ“Š PERFORMANCE:\n",
        "CMI Score: {best_results['best_cmi_score']:.4f}\n",
        "Binary F1: {attrs.get('binary_f1', 0):.4f}\n",
        "Macro F1: {attrs.get('macro_f1', 0):.4f}\n",
        "Accuracy: {attrs.get('test_accuracy', 0):.4f}\n",
        "\n",
        "ğŸ”§ KEY PARAMETERS:\n",
        "LSTM Units: {best_results['best_params'].get('lstm_units_1', 'N/A')}, {best_results['best_params'].get('lstm_units_2', 'N/A')}\n",
        "Dropout: {best_results['best_params'].get('dropout_rate', 'N/A'):.2f}\n",
        "Learning Rate: {best_results['best_params'].get('learning_rate', 'N/A'):.1e}\n",
        "Batch Size: {best_results['best_params'].get('batch_size', 'N/A')}\n",
        "\"\"\"\n",
        "    ax7.text(0.05, 0.95, summary_text, transform=ax7.transAxes, fontsize=10, \n",
        "            verticalalignment='top', fontfamily='monospace',\n",
        "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\", alpha=0.7))\n",
        "\n",
        "plt.suptitle('LSTM v2 Comprehensive Hyperparameter Optimization Results', \n",
        "             fontsize=16, fontweight='bold', y=0.98)\n",
        "\n",
        "# ä¿å­˜\n",
        "plt.savefig(f'{RESULTS_DIR}/comprehensive_optimization_results.png', \n",
        "           dpi=300, bbox_inches='tight', facecolor='white')\n",
        "plt.show()\n",
        "\n",
        "print(f\"âœ… åŒ…æ‹¬çš„çµæœã‚°ãƒ©ãƒ•ã‚’ä¿å­˜: {RESULTS_DIR}/comprehensive_optimization_results.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“Š è©³ç´°çµ±è¨ˆåˆ†æ\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
            "\n",
            "ğŸ”¸ w64_s16 çµ±è¨ˆ:\n",
            "  concatenate:\n",
            "    è©¦è¡Œæ•°: 7\n",
            "    å¹³å‡CMIã‚¹ã‚³ã‚¢: 0.7299\n",
            "    æœ€å¤§CMIã‚¹ã‚³ã‚¢: 0.7682\n",
            "    æœ€å°CMIã‚¹ã‚³ã‚¢: 0.6660\n",
            "    æ¨™æº–åå·®: 0.0324\n",
            "  attention:\n",
            "    è©¦è¡Œæ•°: 22\n",
            "    å¹³å‡CMIã‚¹ã‚³ã‚¢: 0.7472\n",
            "    æœ€å¤§CMIã‚¹ã‚³ã‚¢: 0.8021\n",
            "    æœ€å°CMIã‚¹ã‚³ã‚¢: 0.5979\n",
            "    æ¨™æº–åå·®: 0.0475\n",
            "  gated:\n",
            "    è©¦è¡Œæ•°: 20\n",
            "    å¹³å‡CMIã‚¹ã‚³ã‚¢: 0.7526\n",
            "    æœ€å¤§CMIã‚¹ã‚³ã‚¢: 0.7978\n",
            "    æœ€å°CMIã‚¹ã‚³ã‚¢: 0.6410\n",
            "    æ¨™æº–åå·®: 0.0422\n",
            "\n",
            "ğŸ”¸ å…¨ä½“çµ±è¨ˆ:\n",
            "  ç·è©¦è¡Œæ•°: 50\n",
            "  æˆåŠŸè©¦è¡Œæ•°: 49\n",
            "  æˆåŠŸç‡: 98.0%\n"
          ]
        }
      ],
      "source": [
        "# ğŸ“Š è©³ç´°çµ±è¨ˆåˆ†æ\n",
        "print(\"ğŸ“Š è©³ç´°çµ±è¨ˆåˆ†æ\")\n",
        "print(\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
        "\n",
        "# ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºåˆ¥çµ±è¨ˆ\n",
        "for window_config in WINDOW_CONFIGS:\n",
        "    if window_config in all_studies:\n",
        "        study = all_studies[window_config]\n",
        "        print(f\"\\nğŸ”¸ {window_config} çµ±è¨ˆ:\")\n",
        "        \n",
        "        # Fusionæ–¹å¼åˆ¥ã«ã‚¹ã‚³ã‚¢ã‚’é›†è¨ˆ\n",
        "        fusion_scores = {ft: [] for ft in FUSION_TYPES}\n",
        "        for trial in study.trials:\n",
        "            if (trial.value is not None and \n",
        "                'fusion_type' in trial.user_attrs):\n",
        "                fusion_type = trial.user_attrs['fusion_type']\n",
        "                if fusion_type in fusion_scores:\n",
        "                    fusion_scores[fusion_type].append(trial.value)\n",
        "        \n",
        "        for fusion_type in FUSION_TYPES:\n",
        "            scores = fusion_scores[fusion_type]\n",
        "            if scores:\n",
        "                print(f\"  {fusion_type}:\")\n",
        "                print(f\"    è©¦è¡Œæ•°: {len(scores)}\")\n",
        "                print(f\"    å¹³å‡CMIã‚¹ã‚³ã‚¢: {np.mean(scores):.4f}\")\n",
        "                print(f\"    æœ€å¤§CMIã‚¹ã‚³ã‚¢: {np.max(scores):.4f}\")\n",
        "                print(f\"    æœ€å°CMIã‚¹ã‚³ã‚¢: {np.min(scores):.4f}\")\n",
        "                print(f\"    æ¨™æº–åå·®: {np.std(scores):.4f}\")\n",
        "            else:\n",
        "                print(f\"  {fusion_type}: è©¦è¡Œãªã—\")\n",
        "\n",
        "# å…¨ä½“çµ±è¨ˆ\n",
        "print(f\"\\nğŸ”¸ å…¨ä½“çµ±è¨ˆ:\")\n",
        "total_trials = sum(len(study.trials) for study in all_studies.values())\n",
        "successful_trials = sum(len([t for t in study.trials if t.value is not None]) \n",
        "                       for study in all_studies.values())\n",
        "print(f\"  ç·è©¦è¡Œæ•°: {total_trials}\")\n",
        "print(f\"  æˆåŠŸè©¦è¡Œæ•°: {successful_trials}\")\n",
        "print(f\"  æˆåŠŸç‡: {successful_trials/total_trials*100:.1f}%\" if total_trials > 0 else \"  æˆåŠŸç‡: N/A\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¯ æœ€è‰¯è¨­å®šã§ã®æœ€çµ‚å­¦ç¿’\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
            "æœ€è‰¯è¨­å®š: w64_s16\n",
            "Fusionæ–¹å¼: attention\n",
            "æœ¬ç•ªç”¨å­¦ç¿’è¨­å®šé©ç”¨æ¸ˆã¿\n",
            "Mixed precision enabled for better GPU performance\n",
            "GPUåˆ©ç”¨å¯èƒ½: 1å°\n",
            "ä½¿ç”¨GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
            "LSTM v2å­¦ç¿’ç’°å¢ƒåˆæœŸåŒ–å®Œäº†\n",
            "å®Ÿé¨“å: production_best_model\n",
            "ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®š: w64_s16\n",
            "å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: ../output/experiments/production_best_model_w64_s16\n",
            "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿: ../output/experiments/lstm_v2_w64_s16/preprocessed\n",
            "GPUåˆ©ç”¨å¯èƒ½: True\n",
            "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...\n",
            "æœ€é©åŒ–ã•ã‚ŒãŸdemographicsç‰¹å¾´é‡ã‚’ä½¿ç”¨ã—ã¾ã™\n",
            "æœ€é©åŒ–ã•ã‚ŒãŸdemographicså½¢çŠ¶: (13393, 18)\n",
            "ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†:\n",
            "  ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿: (13393, 64, 332)\n",
            "  Demographics: (13393, 18)\n",
            "  ãƒ©ãƒ™ãƒ«: (13393,)\n",
            "  ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "\n",
            "ğŸš€ æœ¬ç•ªç”¨æœ€çµ‚å­¦ç¿’é–‹å§‹...\n",
            "   ã‚¨ãƒãƒƒã‚¯æ•°: 150\n",
            "   æ—©æœŸåœæ­¢: 30 ã‚¨ãƒãƒƒã‚¯\n",
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹ (èåˆæ–¹å¼: attention)...\n",
            "ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ä¸­...\n",
            "ãƒ†ã‚¹ãƒˆã‚µã‚¤ã‚º: 0.2\n",
            "æ¤œè¨¼ã‚µã‚¤ã‚º: 0.2\n",
            "ãƒ‡ãƒ¼ã‚¿åˆ†å‰²å®Œäº†:\n",
            "  è¨“ç·´ - ã‚»ãƒ³ã‚µãƒ¼: (8571, 64, 332), Demographics: (8571, 18), ãƒ©ãƒ™ãƒ«: (8571,)\n",
            "  æ¤œè¨¼ - ã‚»ãƒ³ã‚µãƒ¼: (2143, 64, 332), Demographics: (2143, 18), ãƒ©ãƒ™ãƒ«: (2143,)\n",
            "  ãƒ†ã‚¹ãƒˆ - ã‚»ãƒ³ã‚µãƒ¼: (2679, 64, 332), Demographics: (2679, 18), ãƒ©ãƒ™ãƒ«: (2679,)\n",
            "å…¥åŠ›å½¢çŠ¶:\n",
            "  ã‚»ãƒ³ã‚µãƒ¼: (64, 332)\n",
            "  Demographics: (18,)\n",
            "  ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "GPUä¸Šã§ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆãƒ»å­¦ç¿’ã—ã¾ã™\n",
            "Mixed precision enabled for better GPU performance\n",
            "GPUåˆ©ç”¨å¯èƒ½: 1å°\n",
            "ä½¿ç”¨GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
            "LSTM v2ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†\n",
            "ã‚»ãƒ³ã‚µãƒ¼å…¥åŠ›å½¢çŠ¶: (64, 332)\n",
            "Demographicså…¥åŠ›å½¢çŠ¶: (18,)\n",
            "ã‚¯ãƒ©ã‚¹æ•°: 18\n",
            "èåˆæ–¹å¼: attention\n",
            "GPUåˆ©ç”¨å¯èƒ½: True\n",
            "LSTM v2ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ä¸­...\n",
            "ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰å®Œäº†\n",
            "ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 179,666\n",
            "\n",
            "=== ãƒ¢ãƒ‡ãƒ«ã‚µãƒãƒªãƒ¼ ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"lstm_v2_hybrid\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"lstm_v2_hybrid\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ sensor_input        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">332</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">132,160</span> â”‚ sensor_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_1           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> â”‚ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_1      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ lstm_bn_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_input  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">37,120</span> â”‚ lstm_dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">456</span> â”‚ demographics_inpâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_2           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_2      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ lstm_bn_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dense        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,120</span> â”‚ lstm_dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dropout      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sensor_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_weights   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,200</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attended_sensor     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sensor_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          â”‚                   â”‚            â”‚ attention_weightâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_projeâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,200</span> â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_fusion    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ attended_sensor[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚                   â”‚            â”‚ demographics_proâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dense        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,352</span> â”‚ attention_fusionâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dropout      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ fusion_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">882</span> â”‚ fusion_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ sensor_input        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m332\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m80\u001b[0m)    â”‚    \u001b[38;5;34m132,160\u001b[0m â”‚ sensor_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_1           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m80\u001b[0m)    â”‚        \u001b[38;5;34m320\u001b[0m â”‚ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_1      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m80\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ lstm_bn_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_input  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚     \u001b[38;5;34m37,120\u001b[0m â”‚ lstm_dropout_1[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)        â”‚        \u001b[38;5;34m456\u001b[0m â”‚ demographics_inpâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_bn_2           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m256\u001b[0m â”‚ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dropout_2      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ lstm_bn_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_denseâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)        â”‚        \u001b[38;5;34m600\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dense        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚      \u001b[38;5;34m3,120\u001b[0m â”‚ lstm_dropout_2[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_dropoâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ demographics_denâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sensor_dropout      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sensor_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_weights   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚      \u001b[38;5;34m1,200\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attended_sensor     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sensor_dropout[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mMultiply\u001b[0m)          â”‚                   â”‚            â”‚ attention_weightâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ demographics_projeâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚      \u001b[38;5;34m1,200\u001b[0m â”‚ demographics_droâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention_fusion    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ attended_sensor[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚                   â”‚            â”‚ demographics_proâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dense        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚      \u001b[38;5;34m2,352\u001b[0m â”‚ attention_fusionâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fusion_dropout      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ fusion_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (\u001b[38;5;33mDense\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        â”‚        \u001b[38;5;34m882\u001b[0m â”‚ fusion_dropout[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">179,666</span> (701.82 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m179,666\u001b[0m (701.82 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">179,378</span> (700.70 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m179,378\u001b[0m (700.70 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> (1.12 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m288\u001b[0m (1.12 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹...\n",
            "ã‚»ãƒ³ã‚µãƒ¼è¨“ç·´ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (8571, 64, 332)\n",
            "Demographicsè¨“ç·´ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (8571, 18)\n",
            "ã‚»ãƒ³ã‚µãƒ¼æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (2143, 64, 332)\n",
            "Demographicsæ¤œè¨¼ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (2143, 18)\n",
            "è¨“ç·´ãƒ©ãƒ™ãƒ«å½¢çŠ¶: (8571,)\n",
            "æ¤œè¨¼ãƒ©ãƒ™ãƒ«å½¢çŠ¶: (2143,)\n",
            "TensorBoard ãƒ­ã‚°: logs\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "45b007c2bca14f25a1543f7f076b0fbc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0epoch [00:00, ?epoch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14141c985878495d9c3d224adefdf198",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0batch [00:00, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1: val_loss improved from inf to 2.52852, saving model to ../output/experiments/production_best_model_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2: val_loss improved from 2.52852 to 2.32734, saving model to ../output/experiments/production_best_model_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3: val_loss improved from 2.32734 to 2.23067, saving model to ../output/experiments/production_best_model_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4: val_loss improved from 2.23067 to 2.16490, saving model to ../output/experiments/production_best_model_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 5: val_loss improved from 2.16490 to 2.14171, saving model to ../output/experiments/production_best_model_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 6: val_loss improved from 2.14171 to 2.11092, saving model to ../output/experiments/production_best_model_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 7: val_loss did not improve from 2.11092\n",
            "\n",
            "Epoch 8: val_loss improved from 2.11092 to 2.10255, saving model to ../output/experiments/production_best_model_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 9: val_loss improved from 2.10255 to 2.01515, saving model to ../output/experiments/production_best_model_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 10: val_loss did not improve from 2.01515\n",
            "\n",
            "Epoch 11: val_loss improved from 2.01515 to 1.98635, saving model to ../output/experiments/production_best_model_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 12: val_loss did not improve from 1.98635\n",
            "\n",
            "Epoch 13: val_loss did not improve from 1.98635\n",
            "\n",
            "Epoch 14: val_loss did not improve from 1.98635\n",
            "\n",
            "Epoch 15: val_loss improved from 1.98635 to 1.91350, saving model to ../output/experiments/production_best_model_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 16: val_loss did not improve from 1.91350\n",
            "\n",
            "Epoch 17: val_loss did not improve from 1.91350\n",
            "\n",
            "Epoch 18: val_loss did not improve from 1.91350\n",
            "\n",
            "Epoch 19: val_loss did not improve from 1.91350\n",
            "\n",
            "Epoch 20: val_loss did not improve from 1.91350\n",
            "\n",
            "Epoch 21: val_loss improved from 1.91350 to 1.89991, saving model to ../output/experiments/production_best_model_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 22: val_loss did not improve from 1.89991\n",
            "\n",
            "Epoch 23: val_loss did not improve from 1.89991\n",
            "\n",
            "Epoch 24: val_loss did not improve from 1.89991\n",
            "\n",
            "Epoch 25: val_loss did not improve from 1.89991\n",
            "\n",
            "Epoch 26: val_loss improved from 1.89991 to 1.88939, saving model to ../output/experiments/production_best_model_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 27: val_loss did not improve from 1.88939\n",
            "\n",
            "Epoch 28: val_loss did not improve from 1.88939\n",
            "\n",
            "Epoch 29: val_loss did not improve from 1.88939\n",
            "\n",
            "Epoch 30: val_loss did not improve from 1.88939\n",
            "\n",
            "Epoch 31: val_loss improved from 1.88939 to 1.88132, saving model to ../output/experiments/production_best_model_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 32: val_loss improved from 1.88132 to 1.87781, saving model to ../output/experiments/production_best_model_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 33: val_loss improved from 1.87781 to 1.84725, saving model to ../output/experiments/production_best_model_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 34: val_loss did not improve from 1.84725\n",
            "\n",
            "Epoch 35: val_loss did not improve from 1.84725\n",
            "\n",
            "Epoch 36: val_loss improved from 1.84725 to 1.83408, saving model to ../output/experiments/production_best_model_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 37: val_loss did not improve from 1.83408\n",
            "\n",
            "Epoch 38: val_loss improved from 1.83408 to 1.80600, saving model to ../output/experiments/production_best_model_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 39: val_loss did not improve from 1.80600\n",
            "\n",
            "Epoch 40: val_loss did not improve from 1.80600\n",
            "\n",
            "Epoch 41: val_loss did not improve from 1.80600\n",
            "\n",
            "Epoch 42: val_loss did not improve from 1.80600\n",
            "\n",
            "Epoch 43: val_loss did not improve from 1.80600\n",
            "\n",
            "Epoch 44: val_loss did not improve from 1.80600\n",
            "\n",
            "Epoch 45: val_loss improved from 1.80600 to 1.77423, saving model to ../output/experiments/production_best_model_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 46: val_loss did not improve from 1.77423\n",
            "\n",
            "Epoch 47: val_loss did not improve from 1.77423\n",
            "\n",
            "Epoch 48: val_loss did not improve from 1.77423\n",
            "\n",
            "Epoch 49: val_loss did not improve from 1.77423\n",
            "\n",
            "Epoch 50: val_loss did not improve from 1.77423\n",
            "\n",
            "Epoch 51: val_loss did not improve from 1.77423\n",
            "\n",
            "Epoch 52: val_loss did not improve from 1.77423\n",
            "\n",
            "Epoch 53: val_loss did not improve from 1.77423\n",
            "\n",
            "Epoch 54: val_loss did not improve from 1.77423\n",
            "\n",
            "Epoch 55: val_loss did not improve from 1.77423\n",
            "\n",
            "Epoch 56: val_loss did not improve from 1.77423\n",
            "\n",
            "Epoch 57: val_loss did not improve from 1.77423\n",
            "\n",
            "Epoch 58: val_loss did not improve from 1.77423\n",
            "\n",
            "Epoch 59: val_loss did not improve from 1.77423\n",
            "\n",
            "Epoch 60: val_loss did not improve from 1.77423\n",
            "\n",
            "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.0018012771615758538.\n",
            "\n",
            "Epoch 61: val_loss improved from 1.77423 to 1.67632, saving model to ../output/experiments/production_best_model_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 62: val_loss did not improve from 1.67632\n",
            "\n",
            "Epoch 63: val_loss did not improve from 1.67632\n",
            "\n",
            "Epoch 64: val_loss did not improve from 1.67632\n",
            "\n",
            "Epoch 65: val_loss did not improve from 1.67632\n",
            "\n",
            "Epoch 66: val_loss did not improve from 1.67632\n",
            "\n",
            "Epoch 67: val_loss did not improve from 1.67632\n",
            "\n",
            "Epoch 68: val_loss did not improve from 1.67632\n",
            "\n",
            "Epoch 69: val_loss did not improve from 1.67632\n",
            "\n",
            "Epoch 70: val_loss did not improve from 1.67632\n",
            "\n",
            "Epoch 71: val_loss improved from 1.67632 to 1.66813, saving model to ../output/experiments/production_best_model_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 72: val_loss did not improve from 1.66813\n",
            "\n",
            "Epoch 73: val_loss improved from 1.66813 to 1.66406, saving model to ../output/experiments/production_best_model_w64_s16/models/lstm_v2_hybrid_attention_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 74: val_loss did not improve from 1.66406\n",
            "\n",
            "Epoch 75: val_loss did not improve from 1.66406\n",
            "\n",
            "Epoch 76: val_loss did not improve from 1.66406\n",
            "\n",
            "Epoch 77: val_loss did not improve from 1.66406\n",
            "\n",
            "Epoch 78: val_loss did not improve from 1.66406\n",
            "\n",
            "Epoch 79: val_loss did not improve from 1.66406\n",
            "\n",
            "Epoch 80: val_loss did not improve from 1.66406\n",
            "\n",
            "Epoch 81: val_loss did not improve from 1.66406\n",
            "\n",
            "Epoch 82: val_loss did not improve from 1.66406\n",
            "\n",
            "Epoch 83: val_loss did not improve from 1.66406\n",
            "\n",
            "Epoch 84: val_loss did not improve from 1.66406\n",
            "\n",
            "Epoch 85: val_loss did not improve from 1.66406\n",
            "\n",
            "Epoch 86: val_loss did not improve from 1.66406\n",
            "\n",
            "Epoch 87: val_loss did not improve from 1.66406\n",
            "\n",
            "Epoch 88: val_loss did not improve from 1.66406\n",
            "\n",
            "Epoch 88: ReduceLROnPlateau reducing learning rate to 0.0009006385807879269.\n",
            "\n",
            "Epoch 89: val_loss did not improve from 1.66406\n",
            "\n",
            "Epoch 90: val_loss did not improve from 1.66406\n",
            "\n",
            "Epoch 91: val_loss did not improve from 1.66406\n",
            "\n",
            "Epoch 92: val_loss did not improve from 1.66406\n",
            "\n",
            "Epoch 93: val_loss did not improve from 1.66406\n",
            "\n",
            "Epoch 94: val_loss did not improve from 1.66406\n",
            "\n",
            "Epoch 95: val_loss did not improve from 1.66406\n",
            "\n",
            "Epoch 96: val_loss did not improve from 1.66406\n",
            "\n",
            "Epoch 97: val_loss did not improve from 1.66406\n",
            "\n",
            "Epoch 98: val_loss did not improve from 1.66406\n",
            "\n",
            "Epoch 99: val_loss did not improve from 1.66406\n",
            "\n",
            "Epoch 100: val_loss did not improve from 1.66406\n",
            "\n",
            "Epoch 101: val_loss did not improve from 1.66406\n",
            "\n",
            "Epoch 102: val_loss did not improve from 1.66406\n",
            "\n",
            "Epoch 103: val_loss did not improve from 1.66406\n",
            "\n",
            "Epoch 103: ReduceLROnPlateau reducing learning rate to 0.00045031929039396346.\n",
            "Epoch 103: early stopping\n",
            "Restoring model weights from the end of the best epoch: 73.\n",
            "å­¦ç¿’å®Œäº†ï¼å­¦ç¿’æ™‚é–“: 1081.90ç§’\n",
            "æœ€è‰¯æ¤œè¨¼Loss: 1.6641\n",
            "æœ€è‰¯æ¤œè¨¼Accuracy: 0.6533\n",
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ä¸­...\n",
            "ãƒ†ã‚¹ãƒˆLoss: 1.6889\n",
            "ãƒ†ã‚¹ãƒˆAccuracy: 0.6062\n",
            "F1-Score (macro): 0.5666\n",
            "F1-Score (weighted): 0.6037\n",
            "çµæœä¿å­˜ä¸­...\n",
            "å­¦ç¿’å±¥æ­´ä¿å­˜å®Œäº†: ../output/experiments/production_best_model_w64_s16/results/training_history_attention.json\n",
            "çµæœä¿å­˜å®Œäº†: ../output/experiments/production_best_model_w64_s16/results\n",
            "CMIè©•ä¾¡æŒ‡æ¨™è¨ˆç®—é–‹å§‹...\n",
            "y_true shape: (2679,), y_pred shape: (2679,)\n",
            "ãƒ©ãƒ™ãƒ«å¤‰æ›å®Œäº†: 2679 samples\n",
            "ãƒ‡ãƒ¼ã‚¿ä¸­ã®ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼: 18ç¨®é¡\n",
            "Binaryåˆ†é¡ - Target: 1558, Non-Target: 1121\n",
            "Binary F1: 0.9491\n",
            "Macro F1: 0.6366\n",
            "CMI Score: 0.7929\n",
            "Test Accuracy: 0.6062\n",
            "\n",
            "ğŸ† æœ€çµ‚æœ¬ç•ªçµæœ\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
            "ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®š: w64_s16\n",
            "Fusionæ–¹å¼: attention\n",
            "CMI Score: 0.7929\n",
            "Binary F1: 0.9491\n",
            "Macro F1: 0.6366\n",
            "Test Accuracy: 0.6062\n",
            "\n",
            "âœ… åŒ…æ‹¬çš„çµæœã‚µãƒãƒªãƒ¼ä¿å­˜: ../results/comprehensive_optimization/comprehensive_optimization_summary.json\n"
          ]
        }
      ],
      "source": [
        "# ğŸ¯ æœ€è‰¯è¨­å®šã§ã®æœ€çµ‚å­¦ç¿’ã¨æœ¬ç•ªè©•ä¾¡\n",
        "if best_overall_config and best_overall_config in optimization_results:\n",
        "    print(\"ğŸ¯ æœ€è‰¯è¨­å®šã§ã®æœ€çµ‚å­¦ç¿’\")\n",
        "    print(\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
        "    \n",
        "    best_results = optimization_results[best_overall_config]\n",
        "    best_params = best_results['best_params'].copy()\n",
        "    \n",
        "    # æœ¬ç•ªç”¨å­¦ç¿’è¨­å®šã§ä¸Šæ›¸ã\n",
        "    best_params.update({\n",
        "        'epochs': 150,  # æœ¬ç•ªç”¨ï¼šååˆ†ãªã‚¨ãƒãƒƒã‚¯æ•°\n",
        "        'patience': 30,  # æœ¬ç•ªç”¨ï¼šé•·ã‚ã®æ—©æœŸåœæ­¢\n",
        "        'reduce_lr_patience': 15,  # æœ¬ç•ªç”¨ï¼šé•·ã‚ã®å­¦ç¿’ç‡å‰Šæ¸›å¾…æ©Ÿ\n",
        "        'use_tqdm': True,  # æœ¬ç•ªç”¨ï¼šé€²æ—è¡¨ç¤ºON\n",
        "        'use_tensorboard': True  # æœ¬ç•ªç”¨ï¼šãƒ­ã‚°è¨˜éŒ²ON\n",
        "    })\n",
        "    \n",
        "    print(f\"æœ€è‰¯è¨­å®š: {best_overall_config}\")\n",
        "    print(f\"Fusionæ–¹å¼: {best_params['fusion_type']}\")\n",
        "    print(f\"æœ¬ç•ªç”¨å­¦ç¿’è¨­å®šé©ç”¨æ¸ˆã¿\")\n",
        "    \n",
        "    # æœ€çµ‚ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ä½œæˆ\n",
        "    final_trainer = LSTMv2Trainer(\n",
        "        experiment_name=\"production_best_model\",\n",
        "        window_config=best_overall_config,\n",
        "        n_demographics_features=18 if USE_OPTIMIZED_DEMOGRAPHICS else 20\n",
        "    )\n",
        "    \n",
        "    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿\n",
        "    final_data = final_trainer.load_preprocessed_data(use_optimized_demographics=USE_OPTIMIZED_DEMOGRAPHICS)\n",
        "    \n",
        "    print(f\"\\nğŸš€ æœ¬ç•ªç”¨æœ€çµ‚å­¦ç¿’é–‹å§‹...\")\n",
        "    print(f\"   ã‚¨ãƒãƒƒã‚¯æ•°: {best_params['epochs']}\")\n",
        "    print(f\"   æ—©æœŸåœæ­¢: {best_params['patience']} ã‚¨ãƒãƒƒã‚¯\")\n",
        "    \n",
        "    # æœ€çµ‚å­¦ç¿’å®Ÿè¡Œ\n",
        "    final_results = final_trainer.train_model(\n",
        "        final_data, \n",
        "        model_params=best_params, \n",
        "        fusion_type=best_params['fusion_type']\n",
        "    )\n",
        "    \n",
        "    # æœ€çµ‚è©•ä¾¡\n",
        "    final_predictions = final_results['results']['predictions']\n",
        "    # label_encoderã‚’å–å¾—\n",
        "    final_label_encoder = final_data['label_encoder'] if 'label_encoder' in final_data else None\n",
        "    \n",
        "    final_cmi_score, final_binary_f1, final_macro_f1, final_test_accuracy = calculate_cmi_score(\n",
        "        final_predictions,  # y_pred\n",
        "        final_results['test_data'][2],  # y_true\n",
        "        label_encoder=final_label_encoder,\n",
        "        verbose=True  # æœ€çµ‚è©•ä¾¡ã§ã¯è©³ç´°ãƒ­ã‚°ã‚’è¡¨ç¤º\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nğŸ† æœ€çµ‚æœ¬ç•ªçµæœ\")\n",
        "    print(f\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
        "    print(f\"ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®š: {best_overall_config}\")\n",
        "    print(f\"Fusionæ–¹å¼: {best_params['fusion_type']}\")\n",
        "    print(f\"CMI Score: {final_cmi_score:.4f}\")\n",
        "    print(f\"Binary F1: {final_binary_f1:.4f}\")\n",
        "    print(f\"Macro F1: {final_macro_f1:.4f}\")\n",
        "    print(f\"Test Accuracy: {final_test_accuracy:.4f}\")\n",
        "    \n",
        "    # åŒ…æ‹¬çš„çµæœã‚µãƒãƒªãƒ¼ä¿å­˜\n",
        "    comprehensive_summary = {\n",
        "        'experiment_info': {\n",
        "            'study_base_name': STUDY_BASE_NAME,\n",
        "            'window_configs': WINDOW_CONFIGS,\n",
        "            'fusion_types': FUSION_TYPES,\n",
        "            'trials_per_config': N_TRIALS_PER_CONFIG,\n",
        "            'use_optimized_demographics': USE_OPTIMIZED_DEMOGRAPHICS,\n",
        "            'timestamp': pd.Timestamp.now().isoformat()\n",
        "        },\n",
        "        'optimization_results': optimization_results,\n",
        "        'best_overall': {\n",
        "            'window_config': best_overall_config,\n",
        "            'cmi_score': best_overall_score,\n",
        "            'configuration': best_results\n",
        "        },\n",
        "        'final_evaluation': {\n",
        "            'cmi_score': final_cmi_score,\n",
        "            'binary_f1': final_binary_f1,\n",
        "            'macro_f1': final_macro_f1,\n",
        "            'test_accuracy': final_test_accuracy,\n",
        "            'final_params': best_params\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    # JSONä¿å­˜\n",
        "    summary_path = f'{RESULTS_DIR}/comprehensive_optimization_summary.json'\n",
        "    with open(summary_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(comprehensive_summary, f, indent=2, ensure_ascii=False)\n",
        "    \n",
        "    print(f\"\\nâœ… åŒ…æ‹¬çš„çµæœã‚µãƒãƒªãƒ¼ä¿å­˜: {summary_path}\")\n",
        "    \n",
        "else:\n",
        "    print(\"âŒ æœ€è‰¯è¨­å®šãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æœ€é©åŒ–ãŒæ­£å¸¸ã«å®Œäº†ã—ã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”§ å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
            "ãƒ¢ãƒ‡ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: The filename must end in `.weights.h5`. Received: filepath=../results/comprehensive_optimization/production_model/best_lstm_v2_model_weights.h5\n",
            "åŸºæœ¬ãƒ¢ãƒ‡ãƒ«ä¿å­˜å®Œäº†: ../results/comprehensive_optimization/production_model/best_lstm_v2_model.h5\n",
            "âœ… ãƒ¢ãƒ‡ãƒ«ä¿å­˜å®Œäº†:\n",
            "   ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«: ../results/comprehensive_optimization/production_model/best_lstm_v2_model.h5\n",
            "   è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«: ../results/comprehensive_optimization/production_model/model_config.json\n",
            "   README: ../results/comprehensive_optimization/production_model/README.md\n"
          ]
        }
      ],
      "source": [
        "# ğŸ”§ å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ã¨é…å¸ƒæº–å‚™\n",
        "if best_overall_config and 'final_results' in locals():\n",
        "    print(\"ğŸ”§ å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜\")\n",
        "    print(\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
        "    \n",
        "    # æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜\n",
        "    model_save_dir = f\"{RESULTS_DIR}/production_model\"\n",
        "    os.makedirs(model_save_dir, exist_ok=True)\n",
        "    \n",
        "    # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜\n",
        "    model_path = f\"{model_save_dir}/best_lstm_v2_model.h5\"\n",
        "    final_results['model'].save_model(model_path)\n",
        "    \n",
        "    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜\n",
        "    model_config = {\n",
        "        'window_config': best_overall_config,\n",
        "        'model_architecture': final_results['model'].get_config(),\n",
        "        'hyperparameters': best_params,\n",
        "        'performance': {\n",
        "            'cmi_score': final_cmi_score,\n",
        "            'binary_f1': final_binary_f1,\n",
        "            'macro_f1': final_macro_f1,\n",
        "            'test_accuracy': final_test_accuracy\n",
        "        },\n",
        "        'data_preprocessing': {\n",
        "            'use_optimized_demographics': USE_OPTIMIZED_DEMOGRAPHICS,\n",
        "            'n_demographics_features': 18 if USE_OPTIMIZED_DEMOGRAPHICS else 20,\n",
        "            'n_sensor_features': 332,\n",
        "            'n_classes': 18\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    config_path = f\"{model_save_dir}/model_config.json\"\n",
        "    with open(config_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(model_config, f, indent=2, ensure_ascii=False)\n",
        "    \n",
        "    # READMEä½œæˆ\n",
        "    readme_content = f\"\"\"# LSTM v2 Production Model\n",
        "\n",
        "## Model Information\n",
        "- **Model Type**: LSTM v2 Hybrid (Sensor + Demographics)\n",
        "- **Window Configuration**: {best_overall_config}\n",
        "- **Fusion Method**: {best_params['fusion_type']}\n",
        "- **CMI Score**: {final_cmi_score:.4f}\n",
        "\n",
        "## Performance Metrics\n",
        "- Binary F1 Score: {final_binary_f1:.4f}\n",
        "- Macro F1 Score: {final_macro_f1:.4f}\n",
        "- Test Accuracy: {final_test_accuracy:.4f}\n",
        "\n",
        "## Model Architecture\n",
        "- LSTM Units: {best_params.get('lstm_units_1', 'N/A')}, {best_params.get('lstm_units_2', 'N/A')}\n",
        "- Dense Units: {best_params.get('dense_units', 'N/A')}\n",
        "- Dropout Rate: {best_params.get('dropout_rate', 'N/A'):.2f}\n",
        "- Learning Rate: {best_params.get('learning_rate', 'N/A'):.1e}\n",
        "- Batch Size: {best_params.get('batch_size', 'N/A')}\n",
        "\n",
        "## Files\n",
        "- `best_lstm_v2_model.h5`: Trained model weights\n",
        "- `model_config.json`: Complete model configuration\n",
        "- `comprehensive_optimization_summary.json`: Optimization results\n",
        "\n",
        "## Usage\n",
        "```python\n",
        "from src.lstm_v2_trainer import LSTMv2Trainer\n",
        "\n",
        "# Load the trained model\n",
        "trainer = LSTMv2Trainer(\n",
        "    experiment_name=\"production\",\n",
        "    window_config=\"{best_overall_config}\",\n",
        "    n_demographics_features={18 if USE_OPTIMIZED_DEMOGRAPHICS else 20}\n",
        ")\n",
        "\n",
        "# Load model weights\n",
        "trainer.model.load_model(\"{model_path}\")\n",
        "```\n",
        "\n",
        "Generated on: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "\"\"\"\n",
        "    \n",
        "    readme_path = f\"{model_save_dir}/README.md\"\n",
        "    with open(readme_path, 'w', encoding='utf-8') as f:\n",
        "        f.write(readme_content)\n",
        "    \n",
        "    print(f\"âœ… ãƒ¢ãƒ‡ãƒ«ä¿å­˜å®Œäº†:\")\n",
        "    print(f\"   ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«: {model_path}\")\n",
        "    print(f\"   è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«: {config_path}\")\n",
        "    print(f\"   README: {readme_path}\")\n",
        "    \n",
        "else:\n",
        "    print(\"âŒ æœ€çµ‚å­¦ç¿’ãŒå®Œäº†ã—ã¦ã„ãªã„ãŸã‚ã€ãƒ¢ãƒ‡ãƒ«ä¿å­˜ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ‰ åŒ…æ‹¬çš„ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–å®Œäº†\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
            "ğŸ“‹ å®Ÿè¡Œã‚µãƒãƒªãƒ¼:\n",
            "   ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®š: 1ç¨®é¡ (w64_s16)\n",
            "   Fusionæ–¹å¼: 3ç¨®é¡ (concatenate, attention, gated)\n",
            "   è¨ˆç”»è©¦è¡Œæ•°: 50\n",
            "   å®Œäº†è©¦è¡Œæ•°: 49\n",
            "\n",
            "ğŸ† æœ€çµ‚çµæœ:\n",
            "   æœ€è‰¯è¨­å®š: w64_s16\n",
            "   æœ€è‰¯CMIã‚¹ã‚³ã‚¢: 0.8021\n",
            "   æœ¬ç•ªè©•ä¾¡CMIã‚¹ã‚³ã‚¢: 0.7929\n",
            "\n",
            "ğŸ“ ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«:\n",
            "   ğŸ“Š å¯è¦–åŒ–: ../results/comprehensive_optimization/comprehensive_optimization_results.png\n",
            "   ğŸ“„ çµæœã‚µãƒãƒªãƒ¼: ../results/comprehensive_optimization/comprehensive_optimization_summary.json\n",
            "   ğŸ¤– æœ¬ç•ªãƒ¢ãƒ‡ãƒ«: ../results/comprehensive_optimization/production_model/\n",
            "\n",
            "ğŸ’¡ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:\n",
            "   1. å¯è¦–åŒ–çµæœã‚’ç¢ºèªã—ã¦ã€ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã¨Fusionæ–¹å¼ã®å½±éŸ¿ã‚’åˆ†æ\n",
            "   2. æœ¬ç•ªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®äºˆæ¸¬ã‚’å®Ÿè¡Œ\n",
            "   3. å¿…è¦ã«å¿œã˜ã¦ã€ã•ã‚‰ãªã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã‚„æ‰‹æ³•æ”¹å–„ã‚’æ¤œè¨\n",
            "\n",
            "âœ¨ æœ€é©åŒ–å®Ÿé¨“å®Œäº†ï¼ãŠç–²ã‚Œæ§˜ã§ã—ãŸï¼\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
          ]
        }
      ],
      "source": [
        "# ğŸ‰ åŒ…æ‹¬çš„ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–å®Œäº†\n",
        "print(\"ğŸ‰ åŒ…æ‹¬çš„ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–å®Œäº†\")\n",
        "print(\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
        "\n",
        "print(\"ğŸ“‹ å®Ÿè¡Œã‚µãƒãƒªãƒ¼:\")\n",
        "print(f\"   ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®š: {len(WINDOW_CONFIGS)}ç¨®é¡ ({', '.join(WINDOW_CONFIGS)})\")\n",
        "print(f\"   Fusionæ–¹å¼: {len(FUSION_TYPES)}ç¨®é¡ ({', '.join(FUSION_TYPES)})\")\n",
        "print(f\"   è¨ˆç”»è©¦è¡Œæ•°: {N_TRIALS_PER_CONFIG * len(WINDOW_CONFIGS)}\")\n",
        "\n",
        "if all_studies:\n",
        "    total_completed = sum(len([t for t in study.trials if t.value is not None]) \n",
        "                         for study in all_studies.values())\n",
        "    print(f\"   å®Œäº†è©¦è¡Œæ•°: {total_completed}\")\n",
        "\n",
        "if best_overall_config:\n",
        "    print(f\"\\nğŸ† æœ€çµ‚çµæœ:\")\n",
        "    print(f\"   æœ€è‰¯è¨­å®š: {best_overall_config}\")\n",
        "    print(f\"   æœ€è‰¯CMIã‚¹ã‚³ã‚¢: {best_overall_score:.4f}\")\n",
        "    \n",
        "    if 'final_cmi_score' in locals():\n",
        "        print(f\"   æœ¬ç•ªè©•ä¾¡CMIã‚¹ã‚³ã‚¢: {final_cmi_score:.4f}\")\n",
        "\n",
        "print(f\"\\nğŸ“ ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«:\")\n",
        "print(f\"   ğŸ“Š å¯è¦–åŒ–: {RESULTS_DIR}/comprehensive_optimization_results.png\")\n",
        "print(f\"   ğŸ“„ çµæœã‚µãƒãƒªãƒ¼: {RESULTS_DIR}/comprehensive_optimization_summary.json\")\n",
        "if best_overall_config and 'final_results' in locals():\n",
        "    print(f\"   ğŸ¤– æœ¬ç•ªãƒ¢ãƒ‡ãƒ«: {RESULTS_DIR}/production_model/\")\n",
        "\n",
        "print(f\"\\nğŸ’¡ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:\")\n",
        "print(f\"   1. å¯è¦–åŒ–çµæœã‚’ç¢ºèªã—ã¦ã€ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã¨Fusionæ–¹å¼ã®å½±éŸ¿ã‚’åˆ†æ\")\n",
        "print(f\"   2. æœ¬ç•ªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®äºˆæ¸¬ã‚’å®Ÿè¡Œ\")\n",
        "print(f\"   3. å¿…è¦ã«å¿œã˜ã¦ã€ã•ã‚‰ãªã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã‚„æ‰‹æ³•æ”¹å–„ã‚’æ¤œè¨\")\n",
        "\n",
        "print(f\"\\nâœ¨ æœ€é©åŒ–å®Ÿé¨“å®Œäº†ï¼ãŠç–²ã‚Œæ§˜ã§ã—ãŸï¼\")\n",
        "print(\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ğŸš€ åŒ…æ‹¬çš„æœ€é©åŒ–é–‹å§‹\n",
        "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
        "\n",
        "ğŸ“Š w128_s32 ã§ã®æœ€é©åŒ–é–‹å§‹\n",
        "==================================================\n",
        "[I 2025-07-08 06:00:55,630] A new study created in RDB with name: lstm_v2_comprehensive_optimization_w128_s32\n",
        "Studyå: lstm_v2_comprehensive_optimization_w128_s32\n",
        "æ—¢å­˜è©¦è¡Œæ•°: 0\n",
        "å®Ÿè¡Œã™ã‚‹è©¦è¡Œæ•°: 50\n",
        "\n",
        "ğŸ” Trial 0 - w128_s32\n",
        "Mixed precision enabled for better GPU performance\n",
        "GPUåˆ©ç”¨å¯èƒ½: 1å°\n",
        "ä½¿ç”¨GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
        "LSTM v2å­¦ç¿’ç’°å¢ƒåˆæœŸåŒ–å®Œäº†\n",
        "å®Ÿé¨“å: trial_0_w128_s32\n",
        "ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®š: w128_s32\n",
        "å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: ../output/experiments/trial_0_w128_s32_w128_s32\n",
        "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿: ../output/experiments/lstm_v2_w128_s32/preprocessed\n",
        "GPUåˆ©ç”¨å¯èƒ½: True\n",
        "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...\n",
        "[I 2025-07-08 06:01:00,045] Trial 0 finished with value: 0.0 and parameters: {'lstm_units_1': 64, 'lstm_units_2': 64, 'dense_units': 56, 'demographics_dense_units': 24, 'fusion_dense_units': 16, 'dropout_rate': 0.15000000000000002, 'dense_dropout_rate': 0.1, 'learning_rate': 0.005399484409787433, 'batch_size': 32, 'fusion_type': 'concatenate'}. Best is trial 0 with value: 0.0.\n",
        "æœ€é©åŒ–ã•ã‚ŒãŸdemographicsç‰¹å¾´é‡ã‚’ä½¿ç”¨ã—ã¾ã™\n",
        "æœ€é©åŒ–ã•ã‚ŒãŸdemographicså½¢çŠ¶: (13393, 18)\n",
        "ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†:\n",
        "  ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿: (8673, 128, 332)\n",
        "  Demographics: (13393, 18)\n",
        "  ãƒ©ãƒ™ãƒ«: (8673,)\n",
        "  ã‚¯ãƒ©ã‚¹æ•°: 18\n",
        "âŒ Trial 0 failed: ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºãŒä¸€è‡´ã—ã¾ã›ã‚“\n",
        "\n",
        "ğŸ” Trial 1 - w128_s32\n",
        "Mixed precision enabled for better GPU performance\n",
        "GPUåˆ©ç”¨å¯èƒ½: 1å°\n",
        "ä½¿ç”¨GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
        "LSTM v2å­¦ç¿’ç’°å¢ƒåˆæœŸåŒ–å®Œäº†\n",
        "å®Ÿé¨“å: trial_1_w128_s32\n",
        "ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®š: w128_s32\n",
        "å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: ../output/experiments/trial_1_w128_s32_w128_s32\n",
        "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿: ../output/experiments/lstm_v2_w128_s32/preprocessed\n",
        "GPUåˆ©ç”¨å¯èƒ½: True\n",
        "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...\n",
        "[I 2025-07-08 06:01:05,143] Trial 1 finished with value: 0.0 and parameters: {'lstm_units_1': 48, 'lstm_units_2': 24, 'dense_units': 32, 'demographics_dense_units': 20, 'fusion_dense_units': 32, 'dropout_rate': 0.2, 'dense_dropout_rate': 0.30000000000000004, 'learning_rate': 0.00019010245319870352, 'batch_size': 64, 'fusion_type': 'concatenate'}. Best is trial 0 with value: 0.0.\n",
        "æœ€é©åŒ–ã•ã‚ŒãŸdemographicsç‰¹å¾´é‡ã‚’ä½¿ç”¨ã—ã¾ã™\n",
        "æœ€é©åŒ–ã•ã‚ŒãŸdemographicså½¢çŠ¶: (13393, 18)\n",
        "ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†:\n",
        "  ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿: (8673, 128, 332)\n",
        "  Demographics: (13393, 18)\n",
        "  ãƒ©ãƒ™ãƒ«: (8673,)\n",
        "  ã‚¯ãƒ©ã‚¹æ•°: 18\n",
        "âŒ Trial 1 failed: ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºãŒä¸€è‡´ã—ã¾ã›ã‚“\n",
        "\n",
        "ğŸ” Trial 2 - w128_s32\n",
        "Mixed precision enabled for better GPU performance\n",
        "GPUåˆ©ç”¨å¯èƒ½: 1å°\n",
        "ä½¿ç”¨GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
        "LSTM v2å­¦ç¿’ç’°å¢ƒåˆæœŸåŒ–å®Œäº†\n",
        "å®Ÿé¨“å: trial_2_w128_s32\n",
        "ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®š: w128_s32\n",
        "å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: ../output/experiments/trial_2_w128_s32_w128_s32\n",
        "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿: ../output/experiments/lstm_v2_w128_s32/preprocessed\n",
        "GPUåˆ©ç”¨å¯èƒ½: True\n",
        "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...\n",
        "[I 2025-07-08 06:01:09,597] Trial 2 finished with value: 0.0 and parameters: {'lstm_units_1': 96, 'lstm_units_2': 16, 'dense_units': 48, 'demographics_dense_units': 12, 'fusion_dense_units': 16, 'dropout_rate': 0.5, 'dense_dropout_rate': 0.4, 'learning_rate': 0.004138040112561018, 'batch_size': 64, 'fusion_type': 'gated'}. Best is trial 0 with value: 0.0.\n",
        "æœ€é©åŒ–ã•ã‚ŒãŸdemographicsç‰¹å¾´é‡ã‚’ä½¿ç”¨ã—ã¾ã™\n",
        "æœ€é©åŒ–ã•ã‚ŒãŸdemographicså½¢çŠ¶: (13393, 18)\n",
        "ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†:\n",
        "  ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿: (8673, 128, 332)\n",
        "  Demographics: (13393, 18)\n",
        "  ãƒ©ãƒ™ãƒ«: (8673,)\n",
        "  ã‚¯ãƒ©ã‚¹æ•°: 18\n",
        "âŒ Trial 2 failed: ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºãŒä¸€è‡´ã—ã¾ã›ã‚“\n",
        "\n",
        "ğŸ” Trial 3 - w128_s32\n",
        "Mixed precision enabled for better GPU performance\n",
        "GPUåˆ©ç”¨å¯èƒ½: 1å°\n",
        "ä½¿ç”¨GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
        "LSTM v2å­¦ç¿’ç’°å¢ƒåˆæœŸåŒ–å®Œäº†\n",
        "å®Ÿé¨“å: trial_3_w128_s32\n",
        "ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®š: w128_s32\n",
        "å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: ../output/experiments/trial_3_w128_s32_w128_s32\n",
        "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿: ../output/experiments/lstm_v2_w128_s32/preprocessed\n",
        "GPUåˆ©ç”¨å¯èƒ½: True\n",
        "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...\n",
        "[I 2025-07-08 06:01:14,032] Trial 3 finished with value: 0.0 and parameters: {'lstm_units_1': 32, 'lstm_units_2': 64, 'dense_units': 24, 'demographics_dense_units': 24, 'fusion_dense_units': 24, 'dropout_rate': 0.30000000000000004, 'dense_dropout_rate': 0.25, 'learning_rate': 0.00023426581058204064, 'batch_size': 16, 'fusion_type': 'gated'}. Best is trial 0 with value: 0.0.\n",
        "æœ€é©åŒ–ã•ã‚ŒãŸdemographicsç‰¹å¾´é‡ã‚’ä½¿ç”¨ã—ã¾ã™\n",
        "æœ€é©åŒ–ã•ã‚ŒãŸdemographicså½¢çŠ¶: (13393, 18)\n",
        "ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†:\n",
        "  ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿: (8673, 128, 332)\n",
        "  Demographics: (13393, 18)\n",
        "  ãƒ©ãƒ™ãƒ«: (8673,)\n",
        "  ã‚¯ãƒ©ã‚¹æ•°: 18\n",
        "âŒ Trial 3 failed: ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºãŒä¸€è‡´ã—ã¾ã›ã‚“\n",
        "\n",
        "ğŸ” Trial 4 - w128_s32\n",
        "Mixed precision enabled for better GPU performance\n",
        "GPUåˆ©ç”¨å¯èƒ½: 1å°\n",
        "ä½¿ç”¨GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
        "LSTM v2å­¦ç¿’ç’°å¢ƒåˆæœŸåŒ–å®Œäº†\n",
        "å®Ÿé¨“å: trial_4_w128_s32\n",
        "ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®š: w128_s32\n",
        "å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: ../output/experiments/trial_4_w128_s32_w128_s32\n",
        "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿: ../output/experiments/lstm_v2_w128_s32/preprocessed\n",
        "GPUåˆ©ç”¨å¯èƒ½: True\n",
        "å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...\n",
        "[W 2025-07-08 06:01:18,120] Trial 4 failed with parameters: {'lstm_units_1': 32, 'lstm_units_2': 24, 'dense_units': 16, 'demographics_dense_units': 16, 'fusion_dense_units': 24, 'dropout_rate': 0.2, 'dense_dropout_rate': 0.35, 'learning_rate': 0.0005170191786366995, 'batch_size': 32, 'fusion_type': 'gated'} because of the following error: KeyboardInterrupt().\n",
        "Traceback (most recent call last):\n",
        "  File \"/mnt/c/Users/ShunK/works/CMI_comp/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
        "    value_or_values = func(trial)\n",
        "                      ^^^^^^^^^^^\n",
        "  File \"/tmp/ipykernel_54757/3908953550.py\", line 59, in objective\n",
        "    data = trainer.load_preprocessed_data(use_optimized_demographics=USE_OPTIMIZED_DEMOGRAPHICS)\n",
        "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "  File \"/mnt/c/Users/ShunK/works/CMI_comp/notebooks/../src/lstm_v2_trainer.py\", line 124, in load_preprocessed_data\n",
        "    X_sensor_windows = pickle.load(f)\n",
        "                       ^^^^^^^^^^^^^^\n",
        "KeyboardInterrupt\n",
        "[W 2025-07-08 06:01:18,122] Trial 4 failed with value None."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
