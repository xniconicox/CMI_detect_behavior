{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# LSTM v2 ハイパーパラメータ最適化（継続版）\n",
        "\n",
        "## 概要\n",
        "- 最適化されたdemographics特徴量を使用\n",
        "- 既存の最適化結果を継続\n",
        "- CMI評価指標で最適化\n",
        "- GPU使用、混合精度対応\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-07 17:53:41.740054: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-07-07 17:53:43.243428: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1751878423.738915   39720 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1751878423.879317   39720 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1751878425.144153   39720 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1751878425.144191   39720 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1751878425.144193   39720 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1751878425.144194   39720 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-07-07 17:53:45.278988: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mixed precision enabled for better GPU performance\n",
            "GPU利用可能: 1台\n",
            "使用GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
            "ライブラリ読み込み完了\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# TensorFlowとGPU設定\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.mixed_precision import Policy\n",
        "\n",
        "# 混合精度設定\n",
        "policy = Policy('mixed_float16')\n",
        "tf.keras.mixed_precision.set_global_policy(policy)\n",
        "print(f\"Mixed precision enabled for better GPU performance\")\n",
        "\n",
        "# GPU確認\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    print(f\"GPU利用可能: {len(gpus)}台\")\n",
        "    for gpu in gpus:\n",
        "        print(f\"使用GPU: {gpu}\")\n",
        "        tf.config.experimental.set_memory_growth(gpu, True)\n",
        "else:\n",
        "    print(\"GPUが見つかりません\")\n",
        "\n",
        "# パス設定\n",
        "sys.path.append('../src')\n",
        "from lstm_v2_trainer import LSTMv2Trainer\n",
        "\n",
        "# Optuna\n",
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "from optuna.pruners import MedianPruner\n",
        "\n",
        "print(\"ライブラリ読み込み完了\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "実験名: lstm_v2_hyperopt_resume\n",
            "ウィンドウ設定: w64_s16\n",
            "出力ディレクトリ: ../output/experiments/lstm_v2_hyperopt_resume_w64_s16\n",
            "最適化されたdemographics特徴量使用: True\n"
          ]
        }
      ],
      "source": [
        "# 実験設定\n",
        "EXPERIMENT_NAME = \"lstm_v2_hyperopt_resume\"\n",
        "WINDOW_SIZE = 64\n",
        "STEP_SIZE = 16\n",
        "N_TRIALS = 50  # 継続試行数\n",
        "USE_OPTIMIZED_DEMOGRAPHICS = True  # 最適化されたdemographics特徴量を使用\n",
        "\n",
        "# 出力ディレクトリ\n",
        "output_dir = f\"../output/experiments/{EXPERIMENT_NAME}_w{WINDOW_SIZE}_s{STEP_SIZE}\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "print(f\"実験名: {EXPERIMENT_NAME}\")\n",
        "print(f\"ウィンドウ設定: w{WINDOW_SIZE}_s{STEP_SIZE}\")\n",
        "print(f\"出力ディレクトリ: {output_dir}\")\n",
        "print(f\"最適化されたdemographics特徴量使用: {USE_OPTIMIZED_DEMOGRAPHICS}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mixed precision enabled for better GPU performance\n",
            "GPU利用可能: 1台\n",
            "使用GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
            "LSTM v2学習環境初期化完了\n",
            "実験名: lstm_v2_hyperopt_resume\n",
            "ウィンドウ設定: w64_s16\n",
            "出力ディレクトリ: ../output/experiments/lstm_v2_hyperopt_resume_w64_s16\n",
            "前処理済みデータ: ../output/experiments/lstm_v2_w64_s16/preprocessed\n",
            "GPU利用可能: True\n",
            "LSTM v2学習環境初期化完了\n",
            "前処理済みデータ: ../output/experiments/lstm_v2_w64_s16/preprocessed\n",
            "GPU利用可能: True\n",
            "前処理済みデータを読み込み中...\n",
            "前処理済みデータを読み込み中...\n",
            "最適化されたdemographics特徴量を使用します\n",
            "最適化されたdemographics形状: (13393, 18)\n",
            "データ読み込み完了:\n",
            "  センサーデータ: (13393, 64, 332)\n",
            "  Demographics: (13393, 18)\n",
            "  ラベル: (13393,)\n",
            "  クラス数: 18\n",
            "データ読み込み完了:\n",
            "  センサーデータ: (13393, 64, 332)\n",
            "  Demographics: (13393, 18)\n",
            "  ラベル: (13393,)\n",
            "  クラス数: 18\n",
            "\n",
            "ジェスチャー名: ['Above ear - pull hair', 'Cheek - pinch skin', 'Drink from bottle/cup', 'Eyebrow - pull hair', 'Eyelash - pull hair', 'Feel around in tray and pull out an object', 'Forehead - pull hairline', 'Forehead - scratch', 'Glasses on/off', 'Neck - pinch skin', 'Neck - scratch', 'Pinch knee/leg skin', 'Pull air toward your face', 'Scratch knee/leg skin', 'Text on phone', 'Wave hello', 'Write name in air', 'Write name on leg']\n"
          ]
        }
      ],
      "source": [
        "# トレーナー初期化\n",
        "# LSTMv2Trainerに demographics特徴量数を指定\n",
        "window_config = f\"w{WINDOW_SIZE}_s{STEP_SIZE}\"  # \"w64_s16\"\n",
        "n_demographics_features = 18 if USE_OPTIMIZED_DEMOGRAPHICS else 20\n",
        "trainer = LSTMv2Trainer(\n",
        "    experiment_name=EXPERIMENT_NAME,\n",
        "    window_config=window_config,\n",
        "    n_demographics_features=n_demographics_features\n",
        ")\n",
        "\n",
        "print(\"LSTM v2学習環境初期化完了\")\n",
        "print(f\"前処理済みデータ: {trainer.preprocessed_dir}\")\n",
        "print(f\"GPU利用可能: {trainer.gpu_available}\")\n",
        "\n",
        "# データ読み込み\n",
        "print(\"前処理済みデータを読み込み中...\")\n",
        "data = trainer.load_preprocessed_data(use_optimized_demographics=USE_OPTIMIZED_DEMOGRAPHICS)\n",
        "\n",
        "print(f\"データ読み込み完了:\")\n",
        "print(f\"  センサーデータ: {data['X_sensor_windows'].shape}\")\n",
        "print(f\"  Demographics: {data['X_demographics_windows'].shape}\")\n",
        "print(f\"  ラベル: {data['y_windows'].shape}\")\n",
        "print(f\"  クラス数: {len(data['label_encoder'].classes_)}\")\n",
        "\n",
        "# ジェスチャー名確認\n",
        "gesture_names = data['label_encoder'].classes_\n",
        "print(f\"\\nジェスチャー名: {list(gesture_names)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CMI評価関数定義完了\n"
          ]
        }
      ],
      "source": [
        "# CMI評価関数（修正版）\n",
        "def calculate_cmi_score_fixed(y_true, y_pred, gesture_names):\n",
        "    \"\"\"\n",
        "    CMI評価指標を計算（修正版）\n",
        "    \"\"\"\n",
        "    try:\n",
        "        from sklearn.metrics import f1_score\n",
        "        import numpy as np\n",
        "        \n",
        "        # ジェスチャー名をリストに変換\n",
        "        if hasattr(gesture_names, 'tolist'):\n",
        "            gesture_names = gesture_names.tolist()\n",
        "        \n",
        "        # ターゲットジェスチャーの定義（実際のデータセットに合わせて修正）\n",
        "        target_gestures = [\n",
        "            'Above ear - pull hair',\n",
        "            'Cheek - pinch skin', \n",
        "            'Eyebrow - pull hair',\n",
        "            'Eyelash - pull hair',\n",
        "            'Forehead - pull hairline',\n",
        "            'Forehead - scratch',\n",
        "            'Neck - pinch skin',\n",
        "            'Neck - scratch'\n",
        "        ]\n",
        "        \n",
        "        # 非ターゲットジェスチャーの定義（実際のデータセットに合わせて修正）\n",
        "        non_target_gestures = [\n",
        "            'Write name on leg',\n",
        "            'Wave hello', \n",
        "            'Glasses on/off',\n",
        "            'Text on phone',\n",
        "            'Write name in air',\n",
        "            'Feel around in tray and pull out an object',\n",
        "            'Scratch knee/leg skin',\n",
        "            'Pull air toward your face',\n",
        "            'Drink from bottle/cup',\n",
        "            'Pinch knee/leg skin'\n",
        "        ]\n",
        "        \n",
        "        # ジェスチャー名の確認\n",
        "        available_targets = [g for g in target_gestures if g in gesture_names]\n",
        "        available_non_targets = [g for g in non_target_gestures if g in gesture_names]\n",
        "        \n",
        "        print(f\"利用可能ターゲット: {len(available_targets)}個\")\n",
        "        print(f\"利用可能非ターゲット: {len(available_non_targets)}個\")\n",
        "        \n",
        "        if len(available_targets) == 0 or len(available_non_targets) == 0:\n",
        "            print(\"警告: ターゲットまたは非ターゲットジェスチャーが見つかりません\")\n",
        "            return 0.0\n",
        "        \n",
        "        # ラベル→インデックスマッピング\n",
        "        label_to_idx = {name: idx for idx, name in enumerate(gesture_names)}\n",
        "        \n",
        "        # ターゲット/非ターゲットのインデックス\n",
        "        target_indices = [label_to_idx[g] for g in available_targets]\n",
        "        non_target_indices = [label_to_idx[g] for g in available_non_targets]\n",
        "        \n",
        "        # バイナリ分類用のラベル作成\n",
        "        y_binary_true = np.array([1 if y in target_indices else 0 for y in y_true])\n",
        "        y_binary_pred = np.array([1 if y in target_indices else 0 for y in y_pred])\n",
        "        \n",
        "        # Binary F1スコア（ターゲット vs 非ターゲット）\n",
        "        binary_f1 = f1_score(y_binary_true, y_binary_pred, average='binary')\n",
        "        \n",
        "        # Macro F1スコア（全ジェスチャー）\n",
        "        macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
        "        \n",
        "        # CMIスコア（平均）\n",
        "        cmi_score = (binary_f1 + macro_f1) / 2\n",
        "        \n",
        "        print(f\"Binary F1: {binary_f1:.4f}\")\n",
        "        print(f\"Macro F1: {macro_f1:.4f}\")\n",
        "        print(f\"CMI Score: {cmi_score:.4f}\")\n",
        "        \n",
        "        return cmi_score\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"CMIスコア計算エラー: {e}\")\n",
        "        return 0.0\n",
        "\n",
        "print(\"CMI評価関数定義完了\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "本格版最適化目的関数定義完了\n"
          ]
        }
      ],
      "source": [
        "# 最適化目的関数（本格版）\n",
        "def objective(trial):\n",
        "    try:\n",
        "        print(f\"\\n=== Trial {trial.number} ===\")\n",
        "        \n",
        "        # ハイパーパラメータ提案\n",
        "        params = {\n",
        "            'lstm_units_1': trial.suggest_int('lstm_units_1', 32, 128, step=16),\n",
        "            'lstm_units_2': trial.suggest_int('lstm_units_2', 16, 64, step=8),\n",
        "            'dense_units': trial.suggest_int('dense_units', 16, 64, step=8),\n",
        "            'demographics_dense_units': trial.suggest_int('demographics_dense_units', 8, 32, step=4),\n",
        "            'fusion_dense_units': trial.suggest_int('fusion_dense_units', 8, 32, step=4),\n",
        "            'dropout_rate': trial.suggest_float('dropout_rate', 0.1, 0.5, step=0.1),\n",
        "            'dense_dropout_rate': trial.suggest_float('dense_dropout_rate', 0.1, 0.4, step=0.1),\n",
        "            'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True),\n",
        "            'batch_size': trial.suggest_categorical('batch_size', [16, 32, 64]),\n",
        "            'fusion_type': trial.suggest_categorical('fusion_type', ['concatenate', 'attention', 'gated']),\n",
        "            \n",
        "            # 本格的な学習設定\n",
        "            'epochs': 100,           # 30 → 100に増加\n",
        "            'patience': 20,          # 10 → 20に増加（過学習防止）\n",
        "            'reduce_lr_patience': 10, # 5 → 10に増加（学習率減衰の猶予）\n",
        "            'use_tqdm': False,\n",
        "            'use_tensorboard': False\n",
        "        }\n",
        "        \n",
        "        print(f\"パラメータ: {params}\")\n",
        "        \n",
        "        # モデル学習\n",
        "        results = trainer.train_model(data, model_params=params, fusion_type=params['fusion_type'])\n",
        "        \n",
        "        # 結果の取得\n",
        "        if 'test_data' in results:\n",
        "            test_data = results['test_data']\n",
        "            if isinstance(test_data, tuple) and len(test_data) == 3:\n",
        "                X_sensor_test, X_demographics_test, y_test = test_data\n",
        "            else:\n",
        "                print(f\"警告: test_dataの形式が予期しないものです: {type(test_data)}\")\n",
        "                return 0.0\n",
        "        else:\n",
        "            print(\"警告: test_dataが結果に含まれていません\")\n",
        "            return 0.0\n",
        "        \n",
        "        # 予測結果の取得\n",
        "        if 'results' in results:\n",
        "            eval_results = results['results']\n",
        "            y_pred = eval_results.get('predictions')\n",
        "            if y_pred is None:\n",
        "                print(\"警告: 予測結果が見つかりません\")\n",
        "                print(f\"利用可能なキー: {list(eval_results.keys())}\")\n",
        "                return 0.0\n",
        "        else:\n",
        "            print(\"警告: 評価結果が見つかりません\")\n",
        "            print(f\"利用可能なキー: {list(results.keys())}\")\n",
        "            return 0.0\n",
        "        \n",
        "        # CMIスコア計算\n",
        "        cmi_score = calculate_cmi_score_fixed(y_test, y_pred, gesture_names)\n",
        "        \n",
        "        # 基本メトリクスも表示\n",
        "        test_accuracy = eval_results.get('test_accuracy', 0.0)\n",
        "        test_loss = eval_results.get('test_loss', 0.0)\n",
        "        f1_macro = eval_results.get('f1_macro', 0.0)\n",
        "        print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "        print(f\"Test Loss: {test_loss:.4f}\")\n",
        "        print(f\"F1 Macro: {f1_macro:.4f}\")\n",
        "        print(f\"CMI Score: {cmi_score:.4f}\")\n",
        "        \n",
        "        return cmi_score\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Trial {trial.number} エラー: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return 0.0\n",
        "\n",
        "print(\"本格版最適化目的関数定義完了\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 既存データベースファイル削除（必要な場合のみ実行）\n",
        "\n",
        "下記セルは、既存の最適化履歴を完全に削除したい場合のみ実行してください：\n",
        "\n",
        "```python\n",
        "# 既存のデータベースファイルを削除（実行注意）\n",
        "import os\n",
        "\n",
        "old_db_path = f\"{output_dir}/{EXPERIMENT_NAME}.db\"\n",
        "if os.path.exists(old_db_path):\n",
        "    os.remove(old_db_path)\n",
        "    print(f\"既存のデータベースファイルを削除しました: {old_db_path}\")\n",
        "else:\n",
        "    print(\"削除対象のデータベースファイルが見つかりません\")\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "修正後の新しいstudyを開始します\n",
            "Study名: lstm_v2_hyperopt_resume_study_fixed_20250707_175412\n",
            "Storage: sqlite:///../output/experiments/lstm_v2_hyperopt_resume_w64_s16/lstm_v2_hyperopt_resume_fixed.db\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-07 17:54:13,704] A new study created in RDB with name: lstm_v2_hyperopt_resume_study_fixed_20250707_175412\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "新規studyを作成しました\n",
            "修正前の履歴は使用せず、新しく最適化を開始します\n"
          ]
        }
      ],
      "source": [
        "# 新しい最適化を開始（修正後）\n",
        "import datetime\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "study_name = f\"{EXPERIMENT_NAME}_study_fixed_{timestamp}\"\n",
        "storage_url = f\"sqlite:///{output_dir}/{EXPERIMENT_NAME}_fixed.db\"\n",
        "\n",
        "print(f\"修正後の新しいstudyを開始します\")\n",
        "print(f\"Study名: {study_name}\")\n",
        "print(f\"Storage: {storage_url}\")\n",
        "\n",
        "# 新規study作成（強制的に新しく作成）\n",
        "study = optuna.create_study(\n",
        "    study_name=study_name,\n",
        "    storage=storage_url,\n",
        "    direction='maximize',\n",
        "    sampler=TPESampler(seed=42),\n",
        "    pruner=MedianPruner(n_startup_trials=3, n_warmup_steps=10)\n",
        ")\n",
        "print(\"新規studyを作成しました\")\n",
        "print(\"修正前の履歴は使用せず、新しく最適化を開始します\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== ハイパーパラメータ最適化開始 ===\n",
            "継続試行数: 50\n",
            "現在の試行数: 0\n",
            "\n",
            "=== Trial 0 ===\n",
            "パラメータ: {'lstm_units_1': 64, 'lstm_units_2': 64, 'dense_units': 56, 'demographics_dense_units': 24, 'fusion_dense_units': 12, 'dropout_rate': 0.1, 'dense_dropout_rate': 0.1, 'learning_rate': 0.005399484409787433, 'batch_size': 32, 'fusion_type': 'concatenate', 'epochs': 100, 'patience': 20, 'reduce_lr_patience': 10, 'use_tqdm': False, 'use_tensorboard': False}\n",
            "ハイブリッドモデル学習開始 (融合方式: concatenate)...\n",
            "データ分割中...\n",
            "テストサイズ: 0.2\n",
            "検証サイズ: 0.2\n",
            "データ分割完了:\n",
            "  訓練 - センサー: (8571, 64, 332), Demographics: (8571, 18), ラベル: (8571,)\n",
            "  検証 - センサー: (2143, 64, 332), Demographics: (2143, 18), ラベル: (2143,)\n",
            "  テスト - センサー: (2679, 64, 332), Demographics: (2679, 18), ラベル: (2679,)\n",
            "入力形状:\n",
            "  センサー: (64, 332)\n",
            "  Demographics: (18,)\n",
            "  クラス数: 18\n",
            "GPU上でモデルを作成・学習します\n",
            "Mixed precision enabled for better GPU performance\n",
            "GPU利用可能: 1台\n",
            "使用GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
            "LSTM v2ハイブリッドモデル初期化完了\n",
            "センサー入力形状: (64, 332)\n",
            "Demographics入力形状: (18,)\n",
            "クラス数: 18\n",
            "融合方式: concatenate\n",
            "GPU利用可能: True\n",
            "LSTM v2ハイブリッドモデルを構築中...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1751878454.908154   39720 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5660 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "モデル構築完了\n",
            "総パラメータ数: 141,070\n",
            "\n",
            "=== モデルサマリー ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"lstm_v2_hybrid\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"lstm_v2_hybrid\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ sensor_input        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">332</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">101,632</span> │ sensor_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_bn_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_dropout_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_bn_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ lstm_dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ demographics_input  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_bn_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ demographics_dense… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">456</span> │ demographics_inp… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_dropout_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_bn_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ demographics_dropo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ demographics_den… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ sensor_dense        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,640</span> │ lstm_dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ demographics_dense… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> │ demographics_dro… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ sensor_dropout      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sensor_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ demographics_dropo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ demographics_den… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ feature_fusion      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sensor_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ demographics_dro… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ fusion_dense        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">972</span> │ feature_fusion[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ fusion_dropout      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ fusion_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">234</span> │ fusion_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ sensor_input        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m332\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │    \u001b[38;5;34m101,632\u001b[0m │ sensor_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_bn_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m256\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_dropout_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ lstm_bn_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m33,024\u001b[0m │ lstm_dropout_1[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ demographics_input  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_bn_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m256\u001b[0m │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ demographics_dense… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)        │        \u001b[38;5;34m456\u001b[0m │ demographics_inp… │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_dropout_2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ lstm_bn_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ demographics_dropo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ demographics_den… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ sensor_dense        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        │      \u001b[38;5;34m3,640\u001b[0m │ lstm_dropout_2[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ demographics_dense… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)        │        \u001b[38;5;34m600\u001b[0m │ demographics_dro… │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ sensor_dropout      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ sensor_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ demographics_dropo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ demographics_den… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ feature_fusion      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ sensor_dropout[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ demographics_dro… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ fusion_dense        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)        │        \u001b[38;5;34m972\u001b[0m │ feature_fusion[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ fusion_dropout      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ fusion_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        │        \u001b[38;5;34m234\u001b[0m │ fusion_dropout[\u001b[38;5;34m0\u001b[0m… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">141,070</span> (551.05 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m141,070\u001b[0m (551.05 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">140,814</span> (550.05 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m140,814\u001b[0m (550.05 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ハイブリッドモデル学習開始...\n",
            "センサー訓練データ形状: (8571, 64, 332)\n",
            "Demographics訓練データ形状: (8571, 18)\n",
            "センサー検証データ形状: (2143, 64, 332)\n",
            "Demographics検証データ形状: (2143, 18)\n",
            "訓練ラベル形状: (8571,)\n",
            "検証ラベル形状: (2143,)\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-07 17:54:20.498547: E tensorflow/core/util/util.cc:131] oneDNN supports DT_HALF only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n",
            "I0000 00:00:1751878461.345130   40174 cuda_dnn.cc:529] Loaded cuDNN version 90501\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.1550 - loss: 2.7878\n",
            "Epoch 1: val_loss improved from inf to 2.39926, saving model to ../output/experiments/lstm_v2_hyperopt_resume_w64_s16/models/lstm_v2_hybrid_concatenate_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 43ms/step - accuracy: 0.1551 - loss: 2.7871 - val_accuracy: 0.2576 - val_loss: 2.3993 - learning_rate: 0.0054\n",
            "Epoch 2/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2572 - loss: 2.3918\n",
            "Epoch 2: val_loss improved from 2.39926 to 2.37131, saving model to ../output/experiments/lstm_v2_hyperopt_resume_w64_s16/models/lstm_v2_hybrid_concatenate_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.2573 - loss: 2.3918 - val_accuracy: 0.2744 - val_loss: 2.3713 - learning_rate: 0.0054\n",
            "Epoch 3/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2928 - loss: 2.3560\n",
            "Epoch 3: val_loss improved from 2.37131 to 2.24220, saving model to ../output/experiments/lstm_v2_hyperopt_resume_w64_s16/models/lstm_v2_hybrid_concatenate_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.2928 - loss: 2.3560 - val_accuracy: 0.3234 - val_loss: 2.2422 - learning_rate: 0.0054\n",
            "Epoch 4/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.3127 - loss: 2.3493\n",
            "Epoch 4: val_loss did not improve from 2.24220\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.3126 - loss: 2.3493 - val_accuracy: 0.2930 - val_loss: 2.3769 - learning_rate: 0.0054\n",
            "Epoch 5/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3035 - loss: 2.3640\n",
            "Epoch 5: val_loss did not improve from 2.24220\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.3035 - loss: 2.3638 - val_accuracy: 0.3346 - val_loss: 2.3021 - learning_rate: 0.0054\n",
            "Epoch 6/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3263 - loss: 2.3022\n",
            "Epoch 6: val_loss did not improve from 2.24220\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.3263 - loss: 2.3023 - val_accuracy: 0.3308 - val_loss: 2.3027 - learning_rate: 0.0054\n",
            "Epoch 7/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3284 - loss: 2.3233\n",
            "Epoch 7: val_loss did not improve from 2.24220\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.3283 - loss: 2.3234 - val_accuracy: 0.3444 - val_loss: 2.2915 - learning_rate: 0.0054\n",
            "Epoch 8/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3229 - loss: 2.3614\n",
            "Epoch 8: val_loss did not improve from 2.24220\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.3229 - loss: 2.3615 - val_accuracy: 0.3462 - val_loss: 2.3087 - learning_rate: 0.0054\n",
            "Epoch 9/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3343 - loss: 2.3570\n",
            "Epoch 9: val_loss did not improve from 2.24220\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.3343 - loss: 2.3571 - val_accuracy: 0.3439 - val_loss: 2.3514 - learning_rate: 0.0054\n",
            "Epoch 10/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.3508 - loss: 2.3507\n",
            "Epoch 10: val_loss did not improve from 2.24220\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.3508 - loss: 2.3507 - val_accuracy: 0.3392 - val_loss: 2.4118 - learning_rate: 0.0054\n",
            "Epoch 11/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3478 - loss: 2.3316\n",
            "Epoch 11: val_loss did not improve from 2.24220\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.3478 - loss: 2.3317 - val_accuracy: 0.3588 - val_loss: 2.3471 - learning_rate: 0.0054\n",
            "Epoch 12/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3568 - loss: 2.3385\n",
            "Epoch 12: val_loss did not improve from 2.24220\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.3569 - loss: 2.3385 - val_accuracy: 0.3500 - val_loss: 2.3475 - learning_rate: 0.0054\n",
            "Epoch 13/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.3559 - loss: 2.3717\n",
            "Epoch 13: val_loss did not improve from 2.24220\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.002699742093682289.\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.3559 - loss: 2.3717 - val_accuracy: 0.3700 - val_loss: 2.2954 - learning_rate: 0.0054\n",
            "Epoch 14/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.3834 - loss: 2.2700\n",
            "Epoch 14: val_loss improved from 2.24220 to 2.17029, saving model to ../output/experiments/lstm_v2_hyperopt_resume_w64_s16/models/lstm_v2_hybrid_concatenate_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.3834 - loss: 2.2699 - val_accuracy: 0.3822 - val_loss: 2.1703 - learning_rate: 0.0027\n",
            "Epoch 15/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4086 - loss: 2.1657\n",
            "Epoch 15: val_loss improved from 2.17029 to 2.13781, saving model to ../output/experiments/lstm_v2_hyperopt_resume_w64_s16/models/lstm_v2_hybrid_concatenate_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.4085 - loss: 2.1656 - val_accuracy: 0.3971 - val_loss: 2.1378 - learning_rate: 0.0027\n",
            "Epoch 16/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4108 - loss: 2.0970\n",
            "Epoch 16: val_loss improved from 2.13781 to 2.08033, saving model to ../output/experiments/lstm_v2_hyperopt_resume_w64_s16/models/lstm_v2_hybrid_concatenate_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.4108 - loss: 2.0969 - val_accuracy: 0.3985 - val_loss: 2.0803 - learning_rate: 0.0027\n",
            "Epoch 17/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4390 - loss: 2.0181\n",
            "Epoch 17: val_loss improved from 2.08033 to 2.02341, saving model to ../output/experiments/lstm_v2_hyperopt_resume_w64_s16/models/lstm_v2_hybrid_concatenate_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.4390 - loss: 2.0182 - val_accuracy: 0.4232 - val_loss: 2.0234 - learning_rate: 0.0027\n",
            "Epoch 18/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4396 - loss: 1.9930\n",
            "Epoch 18: val_loss improved from 2.02341 to 1.99187, saving model to ../output/experiments/lstm_v2_hyperopt_resume_w64_s16/models/lstm_v2_hybrid_concatenate_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.4395 - loss: 1.9930 - val_accuracy: 0.4344 - val_loss: 1.9919 - learning_rate: 0.0027\n",
            "Epoch 19/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4410 - loss: 1.9259\n",
            "Epoch 19: val_loss did not improve from 1.99187\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.4410 - loss: 1.9260 - val_accuracy: 0.4358 - val_loss: 1.9922 - learning_rate: 0.0027\n",
            "Epoch 20/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4495 - loss: 1.9343\n",
            "Epoch 20: val_loss did not improve from 1.99187\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.4495 - loss: 1.9344 - val_accuracy: 0.4307 - val_loss: 2.0073 - learning_rate: 0.0027\n",
            "Epoch 21/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4567 - loss: 1.9134\n",
            "Epoch 21: val_loss improved from 1.99187 to 1.95760, saving model to ../output/experiments/lstm_v2_hyperopt_resume_w64_s16/models/lstm_v2_hybrid_concatenate_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.4567 - loss: 1.9133 - val_accuracy: 0.4424 - val_loss: 1.9576 - learning_rate: 0.0027\n",
            "Epoch 22/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4693 - loss: 1.8468\n",
            "Epoch 22: val_loss did not improve from 1.95760\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.4693 - loss: 1.8469 - val_accuracy: 0.4321 - val_loss: 1.9990 - learning_rate: 0.0027\n",
            "Epoch 23/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4808 - loss: 1.8346\n",
            "Epoch 23: val_loss improved from 1.95760 to 1.90271, saving model to ../output/experiments/lstm_v2_hyperopt_resume_w64_s16/models/lstm_v2_hybrid_concatenate_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.4808 - loss: 1.8345 - val_accuracy: 0.4708 - val_loss: 1.9027 - learning_rate: 0.0027\n",
            "Epoch 24/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4814 - loss: 1.7869\n",
            "Epoch 24: val_loss improved from 1.90271 to 1.89069, saving model to ../output/experiments/lstm_v2_hyperopt_resume_w64_s16/models/lstm_v2_hybrid_concatenate_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.4814 - loss: 1.7870 - val_accuracy: 0.4666 - val_loss: 1.8907 - learning_rate: 0.0027\n",
            "Epoch 25/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4981 - loss: 1.7705\n",
            "Epoch 25: val_loss improved from 1.89069 to 1.87133, saving model to ../output/experiments/lstm_v2_hyperopt_resume_w64_s16/models/lstm_v2_hybrid_concatenate_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.4980 - loss: 1.7705 - val_accuracy: 0.4783 - val_loss: 1.8713 - learning_rate: 0.0027\n",
            "Epoch 26/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5007 - loss: 1.7290\n",
            "Epoch 26: val_loss improved from 1.87133 to 1.85563, saving model to ../output/experiments/lstm_v2_hyperopt_resume_w64_s16/models/lstm_v2_hybrid_concatenate_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.5007 - loss: 1.7290 - val_accuracy: 0.4900 - val_loss: 1.8556 - learning_rate: 0.0027\n",
            "Epoch 27/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5159 - loss: 1.6955\n",
            "Epoch 27: val_loss improved from 1.85563 to 1.85332, saving model to ../output/experiments/lstm_v2_hyperopt_resume_w64_s16/models/lstm_v2_hybrid_concatenate_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.5159 - loss: 1.6956 - val_accuracy: 0.4792 - val_loss: 1.8533 - learning_rate: 0.0027\n",
            "Epoch 28/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5103 - loss: 1.7194\n",
            "Epoch 28: val_loss improved from 1.85332 to 1.85043, saving model to ../output/experiments/lstm_v2_hyperopt_resume_w64_s16/models/lstm_v2_hybrid_concatenate_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.5103 - loss: 1.7194 - val_accuracy: 0.4746 - val_loss: 1.8504 - learning_rate: 0.0027\n",
            "Epoch 29/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5131 - loss: 1.7036\n",
            "Epoch 29: val_loss did not improve from 1.85043\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.5131 - loss: 1.7036 - val_accuracy: 0.4559 - val_loss: 1.9016 - learning_rate: 0.0027\n",
            "Epoch 30/100\n",
            "\u001b[1m267/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5187 - loss: 1.6861\n",
            "Epoch 30: val_loss improved from 1.85043 to 1.79589, saving model to ../output/experiments/lstm_v2_hyperopt_resume_w64_s16/models/lstm_v2_hybrid_concatenate_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5187 - loss: 1.6862 - val_accuracy: 0.5016 - val_loss: 1.7959 - learning_rate: 0.0027\n",
            "Epoch 31/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5440 - loss: 1.6363\n",
            "Epoch 31: val_loss did not improve from 1.79589\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.5440 - loss: 1.6364 - val_accuracy: 0.4722 - val_loss: 1.8235 - learning_rate: 0.0027\n",
            "Epoch 32/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5282 - loss: 1.6721\n",
            "Epoch 32: val_loss did not improve from 1.79589\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.5282 - loss: 1.6722 - val_accuracy: 0.4918 - val_loss: 1.8564 - learning_rate: 0.0027\n",
            "Epoch 33/100\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5510 - loss: 1.6036\n",
            "Epoch 33: val_loss improved from 1.79589 to 1.76698, saving model to ../output/experiments/lstm_v2_hyperopt_resume_w64_s16/models/lstm_v2_hybrid_concatenate_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.5510 - loss: 1.6038 - val_accuracy: 0.5002 - val_loss: 1.7670 - learning_rate: 0.0027\n",
            "Epoch 34/100\n",
            "\u001b[1m265/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5537 - loss: 1.6256"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[W 2025-07-07 18:00:19,212] Trial 0 failed with parameters: {'lstm_units_1': 64, 'lstm_units_2': 64, 'dense_units': 56, 'demographics_dense_units': 24, 'fusion_dense_units': 12, 'dropout_rate': 0.1, 'dense_dropout_rate': 0.1, 'learning_rate': 0.005399484409787433, 'batch_size': 32, 'fusion_type': 'concatenate'} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"/mnt/c/Users/ShunK/works/CMI_comp/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_39720/3372237157.py\", line 30, in objective\n",
            "    results = trainer.train_model(data, model_params=params, fusion_type=params['fusion_type'])\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/mnt/c/Users/ShunK/works/CMI_comp/notebooks/../src/lstm_v2_trainer.py\", line 328, in train_model\n",
            "    history = model.train(\n",
            "              ^^^^^^^^^^^^\n",
            "  File \"/mnt/c/Users/ShunK/works/CMI_comp/notebooks/../src/lstm_v2_model.py\", line 377, in train\n",
            "    self.history = self.model.fit(\n",
            "                   ^^^^^^^^^^^^^^^\n",
            "  File \"/mnt/c/Users/ShunK/works/CMI_comp/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/mnt/c/Users/ShunK/works/CMI_comp/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n",
            "    logs = self.train_function(iterator)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/mnt/c/Users/ShunK/works/CMI_comp/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n",
            "    opt_outputs = multi_step_on_iterator(iterator)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/mnt/c/Users/ShunK/works/CMI_comp/.venv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/mnt/c/Users/ShunK/works/CMI_comp/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 833, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/mnt/c/Users/ShunK/works/CMI_comp/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 878, in _call\n",
            "    results = tracing_compilation.call_function(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/mnt/c/Users/ShunK/works/CMI_comp/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 139, in call_function\n",
            "    return function._call_flat(  # pylint: disable=protected-access\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/mnt/c/Users/ShunK/works/CMI_comp/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\", line 1322, in _call_flat\n",
            "    return self._inference_function.call_preflattened(args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/mnt/c/Users/ShunK/works/CMI_comp/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 216, in call_preflattened\n",
            "    flat_outputs = self.call_flat(*args)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/mnt/c/Users/ShunK/works/CMI_comp/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 251, in call_flat\n",
            "    outputs = self._bound_context.call_function(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/mnt/c/Users/ShunK/works/CMI_comp/.venv/lib/python3.11/site-packages/tensorflow/python/eager/context.py\", line 1688, in call_function\n",
            "    outputs = execute.execute(\n",
            "              ^^^^^^^^^^^^^^^^\n",
            "  File \"/mnt/c/Users/ShunK/works/CMI_comp/.venv/lib/python3.11/site-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
            "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "[W 2025-07-07 18:00:19,245] Trial 0 failed with value None.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "最適化が中断されました\n",
            "現在までの試行数: 1\n",
            "\n",
            "最適化処理完了\n"
          ]
        }
      ],
      "source": [
        "# 最適化実行\n",
        "print(f\"\\n=== ハイパーパラメータ最適化開始 ===\")\n",
        "print(f\"継続試行数: {N_TRIALS}\")\n",
        "print(f\"現在の試行数: {len(study.trials)}\")\n",
        "\n",
        "try:\n",
        "    study.optimize(objective, n_trials=N_TRIALS)\n",
        "    \n",
        "    # 最適化結果の保存\n",
        "    print(\"\\n=== 最適化完了 ===\")\n",
        "    print(f\"総試行数: {len(study.trials)}\")\n",
        "    \n",
        "    # 完了した試行のみ取得\n",
        "    completed_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
        "    \n",
        "    if completed_trials:\n",
        "        best_trial = study.best_trial\n",
        "        print(f\"最高スコア: {best_trial.value:.4f}\")\n",
        "        print(f\"最高スコア試行: {best_trial.number}\")\n",
        "        print(f\"最適パラメータ: {best_trial.params}\")\n",
        "        \n",
        "        # 結果をJSONで保存\n",
        "        results = {\n",
        "            'experiment_name': EXPERIMENT_NAME,\n",
        "            'n_trials': len(study.trials),\n",
        "            'n_completed_trials': len(completed_trials),\n",
        "            'best_trial': best_trial.number,\n",
        "            'best_cmi_score': best_trial.value,\n",
        "            'best_params': best_trial.params,\n",
        "            'use_optimized_demographics': USE_OPTIMIZED_DEMOGRAPHICS,\n",
        "            'timestamp': datetime.now().isoformat()\n",
        "        }\n",
        "        \n",
        "        results_file = f\"{output_dir}/optimization_results.json\"\n",
        "        with open(results_file, 'w') as f:\n",
        "            json.dump(results, f, indent=2)\n",
        "        \n",
        "        print(f\"結果保存: {results_file}\")\n",
        "    else:\n",
        "        print(\"完了した試行がありません\")\n",
        "        \n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\n最適化が中断されました\")\n",
        "    print(f\"現在までの試行数: {len(study.trials)}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"最適化エラー: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "print(\"\\n最適化処理完了\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
