"""
ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
w64_s16ã¨w128_s32ã®å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
"""
import pickle
import numpy as np
import pandas as pd
from pathlib import Path
from src.utils.config_utils import load_config

def load_w64_s16_data():
    """
    w64_s16ã®å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
    
    Returns:
        tuple: (sensor_data, demographics_data, labels)
    """
    config = load_config()
    data_dir = Path(config["output_dir"]) / "lstm_v2_w64_s16" / "preprocessed"
    
    print(f"ğŸ“ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
    
    try:
        # ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        with open(data_dir / "X_sensor_windows.pkl", "rb") as f:
            sensor_data = pickle.load(f)
        print(f"âœ… ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿: {sensor_data.shape}")
        
        # Demographicsãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        with open(data_dir / "X_demographics_windows.pkl", "rb") as f:
            demographics_data = pickle.load(f)
        print(f"âœ… Demographics: {demographics_data.shape}")
        
        # ãƒ©ãƒ™ãƒ«ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        with open(data_dir / "y_windows.pkl", "rb") as f:
            labels = pickle.load(f)
        print(f"âœ… ãƒ©ãƒ™ãƒ«: {labels.shape}")
        
        # ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
        assert sensor_data.shape[0] == demographics_data.shape[0] == labels.shape[0], \
            f"ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºä¸ä¸€è‡´: sensor={sensor_data.shape[0]}, demographics={demographics_data.shape[0]}, labels={labels.shape[0]}"
        
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯å®Œäº†")
        print(f"ğŸ“Š å…¨ã‚µãƒ³ãƒ—ãƒ«æ•°: {sensor_data.shape[0]}")
        print(f"ğŸªŸ ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º: {sensor_data.shape[1]}")
        print(f"ğŸ”¢ ç‰¹å¾´é‡æ•°: {sensor_data.shape[2]}")
        print(f"ğŸ‘¥ Demographicsç‰¹å¾´é‡æ•°: {demographics_data.shape[1]}")
        
        return sensor_data, demographics_data, labels
        
    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        print(f"ğŸ” ãƒ‘ã‚¹ç¢ºèª: {data_dir.exists()}")
        if data_dir.exists():
            files = list(data_dir.glob("*.pkl"))
            print(f"ğŸ“ åˆ©ç”¨å¯èƒ½ãƒ•ã‚¡ã‚¤ãƒ«: {[f.name for f in files]}")
        raise

"""
w128_s32ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã‚¨ãƒ©ãƒ¼ä¿®æ­£ç”¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
"""
import pickle
import numpy as np
import pandas as pd
from pathlib import Path

def load_w128_s32_data():
    """
    w128_s32ã®æ­£ã—ã„å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
    
    Returns:
        tuple: (X_sensor, X_demographics, y, meta_info)
    """
    config = load_config()
    preprocessed_path = Path(config["output_dir"]) / "lstm_v2_w128_s32" / "preprocessed"
    
    print(f"ğŸ“ å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹: {preprocessed_path}")
    
    try:
        # ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        with open(preprocessed_path / "X_sensor_windows.pkl", "rb") as f:
            X_sensor = pickle.load(f)
        print(f"âœ… ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿: {X_sensor.shape}")
        
        # Demographicsãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        with open(preprocessed_path / "X_demographics_windows.pkl", "rb") as f:
            X_demographics = pickle.load(f)
        print(f"âœ… Demographics: {X_demographics.shape}")
        
        # ãƒ©ãƒ™ãƒ«ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        with open(preprocessed_path / "y_windows.pkl", "rb") as f:
            y = pickle.load(f)
        print(f"âœ… ãƒ©ãƒ™ãƒ«: {y.shape}")
        
        # è¨­å®šæƒ…å ±èª­ã¿è¾¼ã¿
        with open(preprocessed_path / "config.pkl", "rb") as f:
            config = pickle.load(f)
        
        # ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼èª­ã¿è¾¼ã¿
        with open(preprocessed_path / "sensor_scaler.pkl", "rb") as f:
            sensor_scaler = pickle.load(f)
            
        with open(preprocessed_path / "demographics_scaler.pkl", "rb") as f:
            demographics_scaler = pickle.load(f)
            
        # ãƒ©ãƒ™ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼èª­ã¿è¾¼ã¿
        with open(preprocessed_path / "label_encoder.pkl", "rb") as f:
            label_encoder = pickle.load(f)
        
        # ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
        assert X_sensor.shape[0] == X_demographics.shape[0] == y.shape[0], \
            f"ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºä¸ä¸€è‡´: sensor={X_sensor.shape[0]}, demographics={X_demographics.shape[0]}, labels={y.shape[0]}"
        
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯å®Œäº†")
        print(f"ğŸ“Š å…¨ã‚µãƒ³ãƒ—ãƒ«æ•°: {X_sensor.shape[0]}")
        print(f"ğŸªŸ ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º: {X_sensor.shape[1]}")
        print(f"ğŸ”¢ ç‰¹å¾´é‡æ•°: {X_sensor.shape[2]}")
        print(f"ğŸ‘¥ Demographicsç‰¹å¾´é‡æ•°: {X_demographics.shape[1]}")
        print(f"ğŸ·ï¸ ã‚¯ãƒ©ã‚¹æ•°: {len(label_encoder.classes_)}")
        
        meta_info = {
            'config': config,
            'sensor_scaler': sensor_scaler,
            'demographics_scaler': demographics_scaler,
            'label_encoder': label_encoder,
            'window_size': X_sensor.shape[1],
            'n_features': X_sensor.shape[2],
            'n_demographics': X_demographics.shape[1],
            'n_classes': len(label_encoder.classes_),
            'n_samples': X_sensor.shape[0]
        }
        
        return X_sensor, X_demographics, y, meta_info
        
    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        print(f"ğŸ” ãƒ‘ã‚¹ç¢ºèª: {preprocessed_path.exists()}")
        if preprocessed_path.exists():
            files = list(preprocessed_path.glob("*.pkl"))
            print(f"ğŸ“ åˆ©ç”¨å¯èƒ½ãƒ•ã‚¡ã‚¤ãƒ«: {[f.name for f in files]}")
        raise

def validate_data_consistency(X_sensor, X_demographics, y):
    """ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ã‚’æ¤œè¨¼"""
    print("ğŸ” ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§æ¤œè¨¼ä¸­...")
    
    # ã‚µãƒ³ãƒ—ãƒ«æ•°ãƒã‚§ãƒƒã‚¯
    n_sensor = X_sensor.shape[0]
    n_demo = X_demographics.shape[0] 
    n_labels = y.shape[0]
    
    print(f"ã‚»ãƒ³ã‚µãƒ¼ã‚µãƒ³ãƒ—ãƒ«æ•°: {n_sensor}")
    print(f"Demographicsã‚µãƒ³ãƒ—ãƒ«æ•°: {n_demo}")
    print(f"ãƒ©ãƒ™ãƒ«ã‚µãƒ³ãƒ—ãƒ«æ•°: {n_labels}")
    
    if n_sensor == n_demo == n_labels:
        print("âœ… å…¨ãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒä¸€è‡´")
        return True
    else:
        print("âŒ ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒä¸ä¸€è‡´")
        return False

def create_data_dict(X_sensor, X_demographics, y, meta_info=None):
    """å­¦ç¿’ç”¨ã®ãƒ‡ãƒ¼ã‚¿è¾æ›¸ã‚’ä½œæˆï¼ˆLSTMv2Trainer.train_modeläº’æ›ï¼‰"""
    data_dict = {
        'X_sensor_windows': X_sensor,  # ä¿®æ­£: æ­£ã—ã„ã‚­ãƒ¼åã‚’ä½¿ç”¨
        'X_demographics_windows': X_demographics,  # ä¿®æ­£: æ­£ã—ã„ã‚­ãƒ¼åã‚’ä½¿ç”¨
        'y_windows': y
    }
    
    # meta_infoãŒæä¾›ã•ã‚ŒãŸå ´åˆã¯è¿½åŠ æƒ…å ±ã‚’å«ã‚ã‚‹
    if meta_info is not None:
        data_dict.update({
            'sensor_scaler': meta_info['sensor_scaler'],
            'demographics_scaler': meta_info['demographics_scaler'],
            'label_encoder': meta_info['label_encoder'],
            'config': meta_info['config']
        })
    
    return data_dict

if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    try:
        # w128_s32ãƒ‡ãƒ¼ã‚¿ãƒ†ã‚¹ãƒˆ
        print("\nğŸ” w128_s32ãƒ‡ãƒ¼ã‚¿ãƒ†ã‚¹ãƒˆ:")
        X_sensor, X_demographics, y, meta_info = load_w128_s32_data()
        if validate_data_consistency(X_sensor, X_demographics, y):
            data_dict = create_data_dict(X_sensor, X_demographics, y, meta_info)
            print("âœ… w128_s32ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ")
        else:
            print("âŒ ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã‚¨ãƒ©ãƒ¼")
            
        # w64_s16ãƒ‡ãƒ¼ã‚¿ãƒ†ã‚¹ãƒˆ
        print("\nğŸ” w64_s16ãƒ‡ãƒ¼ã‚¿ãƒ†ã‚¹ãƒˆ:")
        sensor_data, demographics_data, labels = load_w64_s16_data()
        if validate_data_consistency(sensor_data, demographics_data, labels):
            print("âœ… w64_s16ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ")
        else:
            print("âŒ ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã‚¨ãƒ©ãƒ¼")
            
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}") 