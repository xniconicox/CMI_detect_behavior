#!/usr/bin/env python3
"""
æå‡ºç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ›´æ–°ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
æœ€æ–°ã®å­¦ç¿’çµæœã‚’ä½¿ç”¨ã—ã¦æå‡ºç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°
"""

import os
import json
import shutil
from pathlib import Path
import glob
from datetime import datetime

def find_latest_results():
    """æœ€æ–°ã®å­¦ç¿’çµæœã‚’æ¤œç´¢"""
    results_dir = Path("/mnt/c/Users/ShunK/works/CMI_comp/results/lstm_v2")
    
    # çµæœãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
    result_files = glob.glob(str(results_dir / "final_results_*.json"))
    
    if not result_files:
        raise FileNotFoundError("å­¦ç¿’çµæœãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    # æœ€æ–°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—é †ï¼‰
    latest_file = max(result_files, key=os.path.getmtime)
    
    with open(latest_file, 'r') as f:
        results = json.load(f)
    
    print(f"æœ€æ–°ã®å­¦ç¿’çµæœ: {latest_file}")
    print(f"CMIã‚¹ã‚³ã‚¢: {results['final_cmi_score']:.4f}")
    print(f"ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—: {results['timestamp']}")
    
    return results

def update_submission_files(results):
    """æå‡ºç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°"""
    submission_dir = Path("/mnt/c/Users/ShunK/works/CMI_comp/submissions/lstm_v2")
    timestamp = results['timestamp']
    
    print(f"\nğŸ“ æå‡ºç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ›´æ–°ä¸­: {submission_dir}")
    
    # 1. ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
    model_files_to_copy = [
        ("model_path", f"final_model_{timestamp}.keras")
    ]
    
    # é‡ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’ä¿®æ­£
    weights_path = f"/mnt/c/Users/ShunK/works/CMI_comp/results/lstm_v2/checkpoints/final_model_{timestamp}.weights.h5"
    if os.path.exists(weights_path):
        model_files_to_copy.append(("weights_file", f"final_model_{timestamp}.weights.h5"))
        results["weights_file"] = weights_path
    
    for key, filename in model_files_to_copy:
        if key in results:
            source_path = Path(results[key])
            if source_path.exists():
                dest_path = submission_dir / filename
                shutil.copy2(source_path, dest_path)
                print(f"âœ… ã‚³ãƒ”ãƒ¼å®Œäº†: {filename}")
            else:
                print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {source_path}")
    
    # 2. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
    config_data = {
        "model_info": {
            "timestamp": timestamp,
            "cmi_score": results['final_cmi_score'],
            "binary_f1": results['binary_f1'],
            "macro_f1": results['macro_f1'],
            "test_accuracy": results['test_accuracy'],
            "window_config": results['window_config'],
            "epochs_trained": results['epochs_trained']
        },
        "model_params": results['model_params'],
        "best_params": results['best_params'],
        "file_paths": {
            "model_file": f"final_model_{timestamp}.keras",
            "weights_file": f"final_model_{timestamp}.weights.h5",
            "architecture_file": f"final_model_{timestamp}_architecture.json"
        }
    }
    
    config_path = submission_dir / "model_config.json"
    with open(config_path, 'w', encoding='utf-8') as f:
        json.dump(config_data, f, indent=2, ensure_ascii=False)
    print(f"âœ… è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ: model_config.json")
    
    # 3. ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
    # .kerasãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰.jsonãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
    model_path = results['model_path']
    if model_path.endswith('.keras'):
        architecture_source = Path(model_path.replace('.keras', '_architecture.json'))
    else:
        architecture_source = Path(model_path.replace('.h5', '_architecture.json'))
    
    if architecture_source.exists():
        architecture_dest = submission_dir / f"final_model_{timestamp}_architecture.json"
        shutil.copy2(architecture_source, architecture_dest)
        print(f"âœ… ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ”ãƒ¼: {architecture_dest.name}")
    else:
        print(f"âš ï¸ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {architecture_source}")
    
    # 4. READMEã‚’æ›´æ–°
    update_readme(submission_dir, results)
    
    # 5. æ¨è«–ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’æ›´æ–°
    update_inference_script(submission_dir, results)
    
    print(f"\nğŸ‰ æå‡ºç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ›´æ–°å®Œäº†!")
    return config_data

def update_readme(submission_dir, results):
    """READMEãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°"""
    readme_path = submission_dir / "README.md"
    timestamp = results['timestamp']
    
    readme_content = f"""# CMI 2025 LSTM v2 Submission

## ãƒ¢ãƒ‡ãƒ«æƒ…å ±
- **ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—**: {timestamp}
- **CMIã‚¹ã‚³ã‚¢**: {results['final_cmi_score']:.4f}
- **Binary F1**: {results['binary_f1']:.4f}
- **Macro F1**: {results['macro_f1']:.4f}
- **ãƒ†ã‚¹ãƒˆç²¾åº¦**: {results['test_accuracy']:.4f}
- **å­¦ç¿’ã‚¨ãƒãƒƒã‚¯æ•°**: {results['epochs_trained']}
- **ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®š**: {results['window_config']}

## ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
- **èåˆæ–¹å¼**: {results['model_params']['fusion_type']}
- **LSTM Units**: {results['model_params']['lstm_units_1']} â†’ {results['model_params']['lstm_units_2']}
- **Dense Units**: {results['model_params']['dense_units']}
- **Demographics Dense Units**: {results['model_params']['demographics_dense_units']}
- **Fusion Dense Units**: {results['model_params']['fusion_dense_units']}
- **Dropout Rate**: {results['model_params']['dropout_rate']}
- **Learning Rate**: {results['model_params']['learning_rate']}
- **Batch Size**: {results['model_params']['batch_size']}

## ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ
- `final_model_{timestamp}.keras` - ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«
- `final_model_{timestamp}.weights.h5` - ãƒ¢ãƒ‡ãƒ«é‡ã¿
- `final_model_{timestamp}_architecture.json` - ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
- `model_config.json` - è¨­å®šæƒ…å ±
- `model_inference.py` - æ¨è«–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
- `submit_final_model.py` - æå‡ºç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

## ä½¿ç”¨æ–¹æ³•

### æ¨è«–å®Ÿè¡Œ
```bash
python model_inference.py --input_data path/to/test_data.csv --output predictions.csv
```

### æå‡ºç”¨ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
```bash
python submit_final_model.py
```

## æ€§èƒ½è©³ç´°
- æœ€é©åŒ–æ™‚ã‚¹ã‚³ã‚¢: {results['optimization_score']:.4f}
- å­¦ç¿’å®Œäº†æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## æ³¨æ„äº‹é …
- ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯150ã‚¨ãƒãƒƒã‚¯ã§å­¦ç¿’ã•ã‚Œã¾ã—ãŸ
- æœ€é©ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ Optuna ã«ã‚ˆã‚‹æœ€é©åŒ–çµæœã‚’ä½¿ç”¨
- GPUç’°å¢ƒã§ã®å­¦ç¿’ã‚’æ¨å¥¨ã—ã¾ã™
"""
    
    with open(readme_path, 'w', encoding='utf-8') as f:
        f.write(readme_content)
    
    print(f"âœ… READMEæ›´æ–°å®Œäº†")

def update_inference_script(submission_dir, results):
    """æ¨è«–ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’æ›´æ–°"""
    inference_script = submission_dir / "model_inference.py"
    timestamp = results['timestamp']
    
    # æ—¢å­˜ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’èª­ã¿è¾¼ã¿
    if inference_script.exists():
        with open(inference_script, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æ›´æ–°
        content = content.replace(
            'final_model_', 
            f'final_model_{timestamp}'
        )
        
        # è¨­å®šã‚’æ›´æ–°
        model_config_section = f'''
# ãƒ¢ãƒ‡ãƒ«è¨­å®šï¼ˆè‡ªå‹•ç”Ÿæˆï¼‰
MODEL_CONFIG = {{
    "timestamp": "{timestamp}",
    "cmi_score": {results['final_cmi_score']},
    "model_file": "final_model_{timestamp}.keras",
    "weights_file": "final_model_{timestamp}.weights.h5",
    "window_config": "{results['window_config']}",
    "model_params": {json.dumps(results['model_params'], indent=4)}
}}
'''
        
        # æ—¢å­˜ã®è¨­å®šã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç½®æ›
        import re
        pattern = r'# ãƒ¢ãƒ‡ãƒ«è¨­å®š.*?^MODEL_CONFIG = \{.*?\}$'
        if re.search(pattern, content, re.MULTILINE | re.DOTALL):
            content = re.sub(pattern, model_config_section.strip(), content, flags=re.MULTILINE | re.DOTALL)
        else:
            # è¨­å®šã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯å…ˆé ­ã«è¿½åŠ 
            content = model_config_section + '\n\n' + content
        
        with open(inference_script, 'w', encoding='utf-8') as f:
            f.write(content)
        
        print(f"âœ… æ¨è«–ã‚¹ã‚¯ãƒªãƒ—ãƒˆæ›´æ–°å®Œäº†")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸš€ æå‡ºç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ›´æ–°é–‹å§‹")
    print("=" * 60)
    
    try:
        # æœ€æ–°ã®å­¦ç¿’çµæœã‚’æ¤œç´¢
        results = find_latest_results()
        
        # æå‡ºç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°
        config_data = update_submission_files(results)
        
        print("\nğŸ“Š æ›´æ–°ã‚µãƒãƒªãƒ¼:")
        print(f"  - CMIã‚¹ã‚³ã‚¢: {results['final_cmi_score']:.4f}")
        print(f"  - ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—: {results['timestamp']}")
        print(f"  - ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«: final_model_{results['timestamp']}.keras")
        print(f"  - é‡ã¿ãƒ•ã‚¡ã‚¤ãƒ«: final_model_{results['timestamp']}.weights.h5")
        
        print(f"\nâœ… æå‡ºç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ›´æ–°å®Œäº†!")
        print(f"ğŸ“ æå‡ºãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: /mnt/c/Users/ShunK/works/CMI_comp/submissions/lstm_v2")
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 