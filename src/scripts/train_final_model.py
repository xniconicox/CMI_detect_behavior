#!/usr/bin/env python3
"""
æœ€çµ‚ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
w64_s16ã®æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦æå‡ºç”¨ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’
"""

import os
import json
import datetime
import tensorflow as tf
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import sys

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’è¿½åŠ 
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.append(project_root)

from data.data_loader_fix import load_w64_s16_data, validate_data_consistency, create_data_dict
from trainers.lstm_v2_trainer import LSTMv2Trainer
from utils.cmi_evaluation import calculate_cmi_score

def load_best_config():
    """æœ€é©è¨­å®šã‚’èª­ã¿è¾¼ã¿"""
    config_path = os.path.join('/mnt/c/Users/ShunK/works/CMI_comp/results/final_model', 'best_config.json')
    with open(config_path, 'r') as f:
        return json.load(f)

def prepare_final_model_directory():
    """æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™"""
    model_dir = os.path.join('/mnt/c/Users/ShunK/works/CMI_comp/results/lstm_v2')
    os.makedirs(model_dir, exist_ok=True)
    os.makedirs(os.path.join(model_dir, 'checkpoints'), exist_ok=True)
    os.makedirs(os.path.join(model_dir, 'logs'), exist_ok=True)
    return model_dir

def train_final_model():
    """æœ€çµ‚ãƒ¢ãƒ‡ãƒ«å­¦ç¿’"""
    print("ğŸ† æœ€çµ‚ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹")
    print("=" * 80)
    
    # æœ€é©è¨­å®šèª­ã¿è¾¼ã¿
    best_config = load_best_config()
    best_params = best_config['best_params']
    
    print(f"ğŸ¯ æœ€é©ã‚¹ã‚³ã‚¢: {best_config['best_score']:.4f}")
    print(f"ğŸ”§ æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: Trial {best_config['best_trial']}")
    
    # ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ä½œæˆï¼ˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã®ãŸã‚ï¼‰
    print("\nğŸ—ï¸ ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼åˆæœŸåŒ–ä¸­...")
    trainer = LSTMv2Trainer(
        experiment_name="final_model",
        window_config="w64_s16",
        n_demographics_features=18  # æœ€é©åŒ–ã•ã‚ŒãŸdemographicsç‰¹å¾´é‡æ•°
    )
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    print("\nğŸ“Š ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
    data_dict = trainer.load_preprocessed_data(use_optimized_demographics=True)
    
    # ãƒ‡ãƒ¼ã‚¿ä¸€è²«æ€§æ¤œè¨¼
    print("âœ… ãƒ‡ãƒ¼ã‚¿ä¸€è²«æ€§æ¤œè¨¼ä¸­...")
    validate_data_consistency(data_dict['X_sensor_windows'], data_dict['X_demographics_windows'], data_dict['y_windows'])
    
    # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
    print("ğŸ”€ ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ä¸­...")
    indices = np.arange(len(data_dict['X_sensor_windows']))
    train_indices, test_indices = train_test_split(
        indices, test_size=0.2, random_state=42, stratify=data_dict['y_windows']
    )
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¤‰æ›
    fusion_types = ['concatenate', 'attention', 'gated']
    model_params = {
        'lstm_units_1': int(best_params['lstm_units_1']),
        'lstm_units_2': int(best_params['lstm_units_2']),
        'dense_units': int(best_params['dense_units']),
        'dropout_rate': float(best_params['dropout_rate']),
        'dense_dropout_rate': float(best_params['dense_dropout_rate']),
        'fusion_type': fusion_types[int(best_params['fusion_type'])],
        'fusion_dense_units': int(best_params['fusion_dense_units']),
        'demographics_dense_units': int(best_params['demographics_dense_units']),
        'learning_rate': float(best_params['learning_rate']),
        'batch_size': int(best_params['batch_size']),
        'epochs': 150,
        'patience': 25,
        'reduce_lr_patience': 10,
        'use_tqdm': True,
        'use_tensorboard': True
    }
    
    print(f"\nğŸ”§ ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
    for key, value in model_params.items():
        print(f"   {key}: {value}")
    
    # æ—¢å­˜ã®trainerã‚’ä½¿ç”¨ï¼ˆé‡è¤‡ä½œæˆã‚’å‰Šé™¤ï¼‰
    
    # ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™
    model_dir = prepare_final_model_directory()
    
    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—è¨­å®š
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    checkpoint_path = f"{model_dir}/checkpoints/final_model_{timestamp}.h5"
    
    # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ï¼ˆ150ã‚¨ãƒãƒƒã‚¯ï¼‰
    print(f"\nğŸš€ æœ€çµ‚ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹ (150ã‚¨ãƒãƒƒã‚¯)")
    print(f"ğŸ’¾ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ: {checkpoint_path}")
    
    result = trainer.train_model(
        data_dict,
        model_params=model_params,
        fusion_type=model_params['fusion_type']
    )
    
    # æœ€çµ‚è©•ä¾¡ï¼ˆtrain_modelã®æˆ»ã‚Šå€¤ã‹ã‚‰å–å¾—ï¼‰
    print("\nğŸ“Š æœ€çµ‚è©•ä¾¡å®Ÿè¡Œä¸­...")
    test_results = result['results']
    
    # CMIã‚¹ã‚³ã‚¢ã‚’æ‰‹å‹•ã§è¨ˆç®—
    try:
        from utils.cmi_evaluation import calculate_cmi_score
        test_data = result['test_data']
        X_sensor_test, X_demographics_test, y_test = test_data
        
        # äºˆæ¸¬å®Ÿè¡Œ
        predictions = result['model'].predict(X_sensor_test, X_demographics_test)
        predicted_classes = np.argmax(predictions, axis=1)
        
        # CMIã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆlabel_encoderã‚’æ¸¡ã™ï¼‰
        label_encoder = data_dict.get('label_encoder', None)
        cmi_result = calculate_cmi_score(predicted_classes, y_test, label_encoder=label_encoder, verbose=True)
        cmi_score, binary_f1, macro_f1, test_accuracy = cmi_result
        
    except Exception as e:
        print(f"CMIã‚¹ã‚³ã‚¢è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
        # F1-macroã‚¹ã‚³ã‚¢ã‚’CMIã‚¹ã‚³ã‚¢ã®ä»£æ›¿ã¨ã—ã¦ä½¿ç”¨
        cmi_score = test_results.get('f1_macro', 0.0)
        binary_f1 = 0.0
        macro_f1 = test_results.get('f1_macro', 0.0)
        test_accuracy = test_results.get('test_accuracy', 0.0)
    
    print(f"\nğŸ† æœ€çµ‚çµæœ:")
    print(f"   CMIã‚¹ã‚³ã‚¢: {cmi_score:.4f}")
    print(f"   Binary F1: {binary_f1:.4f}")
    print(f"   Macro F1: {macro_f1:.4f}")
    print(f"   ãƒ†ã‚¹ãƒˆç²¾åº¦: {test_accuracy:.4f}")
    print(f"   æœ€é©åŒ–æ™‚ã‚¹ã‚³ã‚¢: {best_config['best_score']:.4f}")
    
    # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    final_model_path = f"{model_dir}/final_model_{timestamp}.h5"
    result['model'].save_model(final_model_path)
    
    # å­¦ç¿’å±¥æ­´ä¿å­˜
    history_path = f"{model_dir}/training_history_{timestamp}.json"
    result['model'].save_training_history(history_path)
    
    # å­¦ç¿’çµæœä¿å­˜
    final_results = {
        'final_cmi_score': cmi_score,
        'binary_f1': binary_f1,
        'macro_f1': macro_f1,
        'test_accuracy': test_accuracy,
        'optimization_score': best_config['best_score'],
        'model_path': final_model_path,
        'checkpoint_path': checkpoint_path,
        'history_path': history_path,
        'timestamp': timestamp,
        'epochs_trained': model_params['epochs'],
        'best_params': best_params,
        'model_params': model_params,
        'window_config': 'w64_s16'
    }
    
    results_path = f"{model_dir}/final_results_{timestamp}.json"
    with open(results_path, 'w') as f:
        json.dump(final_results, f, indent=2)
    
    print(f"\nğŸ’¾ ä¿å­˜å®Œäº†:")
    print(f"   ãƒ¢ãƒ‡ãƒ«: {final_model_path}")
    print(f"   å­¦ç¿’å±¥æ­´: {history_path}")
    print(f"   çµæœ: {results_path}")
    
    return final_results

if __name__ == "__main__":
    try:
        results = train_final_model()
        print("\nğŸ‰ æœ€çµ‚ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å®Œäº†!")
        print("ğŸš€ æå‡ºæº–å‚™å®Œäº†!")
        
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
        import traceback
        traceback.print_exc() 