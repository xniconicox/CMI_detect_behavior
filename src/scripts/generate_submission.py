#!/usr/bin/env python3
"""
æå‡ºç”¨äºˆæ¸¬ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦äºˆæ¸¬ã‚’è¡Œã„ã€æå‡ºç”¨CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
"""

import os
import json
import glob
import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.preprocessing import StandardScaler
import sys

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’è¿½åŠ 
sys.path.append('src')

from data_loader_fix import load_w64_s16_data, validate_data_consistency, create_data_dict
from models.lstm_v2_trainer import LSTMv2Trainer

def load_latest_model():
    """æœ€æ–°ã®æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
    model_dir = 'results/final_model'
    
    # æœ€æ–°ã®çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
    result_files = glob.glob(f"{model_dir}/final_results_*.json")
    if not result_files:
        raise FileNotFoundError("æœ€çµ‚çµæœãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    latest_result_file = max(result_files, key=os.path.getctime)
    
    with open(latest_result_file, 'r') as f:
        results = json.load(f)
    
    print(f"ğŸ† æœ€æ–°ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿: {latest_result_file}")
    print(f"ğŸ“Š CMIã‚¹ã‚³ã‚¢: {results['final_cmi_score']:.4f}")
    print(f"ğŸ—“ï¸ ä½œæˆæ—¥æ™‚: {results['timestamp']}")
    
    return results

def load_test_data():
    """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
    print("\nğŸ“Š ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹ã‚’ç¢ºèª
    test_sensor_path = 'data/processed/test_sensor_data_w64_s16.npy'
    test_demographics_path = 'data/processed/test_demographics_data_w64_s16.npy'
    
    if not os.path.exists(test_sensor_path) or not os.path.exists(test_demographics_path):
        print("âŒ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print("ğŸ“ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹:")
        print(f"   ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿: {test_sensor_path}")
        print(f"   äººå£çµ±è¨ˆãƒ‡ãƒ¼ã‚¿: {test_demographics_path}")
        return None, None
    
    test_sensor_data = np.load(test_sensor_path)
    test_demographics_data = np.load(test_demographics_path)
    
    print(f"âœ… ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†")
    print(f"   ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿: {test_sensor_data.shape}")
    print(f"   äººå£çµ±è¨ˆãƒ‡ãƒ¼ã‚¿: {test_demographics_data.shape}")
    
    return test_sensor_data, test_demographics_data

def create_test_data_dict(sensor_data, demographics_data):
    """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿è¾æ›¸ã‚’ä½œæˆ"""
    return {
        'sensor_data': sensor_data,
        'demographics_data': demographics_data,
        'labels': None  # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«ã¯ãƒ©ãƒ™ãƒ«ãŒãªã„
    }

def generate_predictions(model_results):
    """äºˆæ¸¬ã‚’ç”Ÿæˆ"""
    print("\nğŸ”® äºˆæ¸¬ç”Ÿæˆä¸­...")
    
    # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
    model_path = model_results['model_path']
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {model_path}")
    
    model = tf.keras.models.load_model(model_path)
    print(f"ğŸ—ï¸ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: {model_path}")
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    test_sensor_data, test_demographics_data = load_test_data()
    
    if test_sensor_data is None or test_demographics_data is None:
        print("âŒ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ")
        return None
    
    # äºˆæ¸¬å®Ÿè¡Œ
    print("\nğŸš€ äºˆæ¸¬å®Ÿè¡Œä¸­...")
    
    # ãƒãƒƒãƒã‚µã‚¤ã‚ºè¨­å®š
    batch_size = model_results['model_params']['batch_size']
    
    # äºˆæ¸¬
    predictions = model.predict(
        [test_sensor_data, test_demographics_data],
        batch_size=batch_size,
        verbose=1
    )
    
    # äºˆæ¸¬çµæœã‚’0-1ã®ç¯„å›²ã«å¤‰æ›ï¼ˆã‚·ã‚°ãƒ¢ã‚¤ãƒ‰å‡ºåŠ›ã®å ´åˆï¼‰
    predictions = predictions.flatten()
    
    print(f"âœ… äºˆæ¸¬å®Œäº†")
    print(f"   äºˆæ¸¬æ•°: {len(predictions)}")
    print(f"   äºˆæ¸¬å€¤ç¯„å›²: [{predictions.min():.4f}, {predictions.max():.4f}]")
    
    return predictions

def create_submission_file(predictions, model_results):
    """æå‡ºç”¨CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
    print("\nğŸ“ æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆä¸­...")
    
    # æå‡ºç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    submission_dir = 'results/submission'
    os.makedirs(submission_dir, exist_ok=True)
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®IDã‚’å–å¾—ï¼ˆä»®å®šï¼šé€£ç•ªï¼‰
    test_ids = np.arange(len(predictions))
    
    # DataFrameä½œæˆ
    submission_df = pd.DataFrame({
        'id': test_ids,
        'prediction': predictions
    })
    
    # ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ
    timestamp = model_results['timestamp']
    cmi_score = model_results['final_cmi_score']
    submission_filename = f"submission_{timestamp}_cmi{cmi_score:.4f}.csv"
    submission_path = os.path.join(submission_dir, submission_filename)
    
    # CSVä¿å­˜
    submission_df.to_csv(submission_path, index=False)
    
    print(f"âœ… æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆå®Œäº†: {submission_path}")
    print(f"ğŸ“Š æå‡ºãƒ‡ãƒ¼ã‚¿:")
    print(f"   ãƒ‡ãƒ¼ã‚¿æ•°: {len(submission_df)}")
    print(f"   äºˆæ¸¬å€¤çµ±è¨ˆ:")
    print(f"     å¹³å‡: {predictions.mean():.4f}")
    print(f"     æ¨™æº–åå·®: {predictions.std():.4f}")
    print(f"     æœ€å°å€¤: {predictions.min():.4f}")
    print(f"     æœ€å¤§å€¤: {predictions.max():.4f}")
    
    # æå‡ºæƒ…å ±ã‚’ä¿å­˜
    submission_info = {
        'submission_file': submission_path,
        'model_path': model_results['model_path'],
        'cmi_score': cmi_score,
        'timestamp': timestamp,
        'prediction_stats': {
            'count': len(predictions),
            'mean': float(predictions.mean()),
            'std': float(predictions.std()),
            'min': float(predictions.min()),
            'max': float(predictions.max())
        }
    }
    
    info_path = os.path.join(submission_dir, f"submission_info_{timestamp}.json")
    with open(info_path, 'w') as f:
        json.dump(submission_info, f, indent=2)
    
    print(f"ğŸ“‹ æå‡ºæƒ…å ±ä¿å­˜: {info_path}")
    
    return submission_path

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ğŸš€ æå‡ºç”¨äºˆæ¸¬ç”Ÿæˆé–‹å§‹")
    print("=" * 80)
    
    try:
        # æœ€æ–°ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        model_results = load_latest_model()
        
        # äºˆæ¸¬ç”Ÿæˆ
        predictions = generate_predictions(model_results)
        
        if predictions is None:
            print("âŒ äºˆæ¸¬ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            return
        
        # æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        submission_path = create_submission_file(predictions, model_results)
        
        print(f"\nğŸ‰ æå‡ºæº–å‚™å®Œäº†!")
        print(f"ğŸ“ æå‡ºãƒ•ã‚¡ã‚¤ãƒ«: {submission_path}")
        print(f"ğŸ† ãƒ¢ãƒ‡ãƒ«ã‚¹ã‚³ã‚¢: {model_results['final_cmi_score']:.4f}")
        
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 